[ { "title": "Ubuntu設定靜態路由", "url": "/posts/Ubuntu%E8%A8%AD%E5%AE%9A%E9%9D%9C%E6%85%8B%E8%B7%AF%E7%94%B1/", "categories": "", "tags": "", "date": "2024-10-17 17:31:00 +0800", "snippet": "用nmtui設定https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/configuring-static-routes_configuring-and-managing-networking#proc_configuring-a-static-route-by-using-nmtui_configuring-static-routes" }, { "title": "Gstreamer使用筆記", "url": "/posts/Gstreamer%E4%BD%BF%E7%94%A8%E7%AD%86%E8%A8%98/", "categories": "", "tags": "", "date": "2024-10-17 17:31:00 +0800", "snippet": "關閉程式前發送EOS事件給pipeline的方法// 發送EOS訊號讓filesink可以正常結束gst_element_send_event(appCtx[i]-&gt;pipeline.pipeline, gst_event_new_eos());msg = gst_bus_timed_pop_filtered(GST_ELEMENT_BUS (appCtx[i]-&gt;pipeline.pipeline), GST_CLOCK_TIME_NONE, (GstMessageType) (GST_MESSAGE_ERROR | GST_MESSAGE_EOS));//gst_bus_timed_pop_filtered 是synchronously取得訊號，如果沒有訊號會一直等待並把執行續卡住gst_element_set_state (appCtx[i]-&gt;pipeline.pipeline, GST_STATE_NULL);g_main_loop_quit (main_loop);https://gstreamer.freedesktop.org/documentation/gstreamer/gstelement.html#gst_element_get_statehttps://gstreamer-devel.narkive.com/g1omJFAj/gst-devel-graceful-exit-shutdown-of-a-pipeline#post3https://stackoverflow.com/questions/38170733/gstreamer-not-flushing-to-the-filesink範例https://gitlab.freedesktop.org/freedesktop/snippets/-/snippets/1760https://gist.github.com/CaptainOnly/f88cbb6ac5fdeae80200fbb3f7be695c" }, { "title": "Ubuntu新增ssh使用者", "url": "/posts/Ubuntu%E6%96%B0%E5%A2%9Essh%E4%BD%BF%E7%94%A8%E8%80%85/", "categories": "", "tags": "", "date": "2024-10-16 17:31:00 +0800", "snippet": "打開ssh登錄日誌nano /etc/ssh/sshd_config" }, { "title": "Glib使用筆記", "url": "/posts/Glib%E4%BD%BF%E7%94%A8%E7%AD%86%E8%A8%98/", "categories": "", "tags": "", "date": "2024-10-16 17:31:00 +0800", "snippet": "如果硬碟沒有分割區，可以用以下指令擴大硬碟區域:https://unix.stackexchange.com/questions/643026/how-to-resize-a-disk-without-partition# resize2fs /dev/[DISK_ID][PARTITION_NUMBER]resize2fs /dev/sdchttps://tech.sars.tw/posts/gcp-linux-enlarge-disk-size/https://www.tecmint.com/parted-command-create-linux-partitions/https://godleon.github.io/blog/Linux/Linux-extend-lvm-from-unused-space/LVM說明https://linux.vbird.org/linux_basic_train/centos8/unit14.php" }, { "title": "Ubuntu使用未分割的硬碟區域", "url": "/posts/Ubuntu%E4%BD%BF%E7%94%A8%E6%9C%AA%E5%88%86%E5%89%B2%E7%9A%84%E7%A1%AC%E7%A2%9F%E5%8D%80%E5%9F%9F/", "categories": "", "tags": "", "date": "2024-10-07 17:31:00 +0800", "snippet": "如果硬碟沒有分割區，可以用以下指令擴大硬碟區域:https://unix.stackexchange.com/questions/643026/how-to-resize-a-disk-without-partition# resize2fs /dev/[DISK_ID][PARTITION_NUMBER]resize2fs /dev/sdchttps://tech.sars.tw/posts/gcp-linux-enlarge-disk-size/https://www.tecmint.com/parted-command-create-linux-partitions/https://godleon.github.io/blog/Linux/Linux-extend-lvm-from-unused-space/LVM說明https://linux.vbird.org/linux_basic_train/centos8/unit14.php" }, { "title": "用systemd製作服務", "url": "/posts/%E7%94%A8systemd%E8%A3%BD%E4%BD%9C%E6%9C%8D%E5%8B%99/", "categories": "", "tags": "", "date": "2024-08-28 17:31:00 +0800", "snippet": "可以用symble link的方式，將服務檔放到/etc/systemd/system/目錄下，讓systemd管理服務。更改service檔後，需執行以下指令，讓systemd重新載入設定檔:sudo systemctl daemon-reloadsudo systemctl enable appnamesudo systemctl start appname移除服務:systemctl stop [servicename]systemctl disable [servicename]rm /your/service/locations/[servicename]# and symlinks that might be relatedrm /your/service/locations/[servicename] systemctl daemon-reloadsystemctl reset-failed參考:製作fastapi服務設定檔重載symbolic link移除服務" }, { "title": "Python執行tensorrt-engine", "url": "/posts/Python%E5%9F%B7%E8%A1%8Ctensorrt-engine/", "categories": "", "tags": "", "date": "2024-07-18 17:31:00 +0800", "snippet": "載入Region_TRT plugin必須要載入libnvinfer_plugin，可以用python的trt.init_libnvinfer_plugins載入，TRT_LOGGER = trt.Logger(trt.Logger.ERROR)trt.init_libnvinfer_plugins(TRT_LOGGER,\"\")https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/infer/Plugin/IPluginRegistry.html#tensorrt.init_libnvinfer_plugins印出目前已經載入的pluginPLUGIN_CREATORS = trt.get_plugin_registry().plugin_creator_listfor plugin_creator in PLUGIN_CREATORS: print(plugin_creator.name)參考並修改:https://developer.nvidia.com/zh-cn/blog/tensorrt-custom-layer-cn/tensorrt Region layer 說明書https://docs.nvidia.com/deeplearning/tensorrt/api/c_api/structnvinfer1_1_1plugin_1_1_region_parameters.html#ad2c6bba4f07221add9b6d9abf0a4e312inference範例參考:https://leimao.github.io/blog/TensorRT-Python-Inference/" }, { "title": "VScode-C語言除錯技巧", "url": "/posts/VSCode-GDB-C%E8%AA%9E%E8%A8%80%E9%99%A4%E9%8C%AF%E6%8A%80%E5%B7%A7/", "categories": "", "tags": "", "date": "2024-07-15 17:31:00 +0800", "snippet": "VScode(float[5])v_anchors查看大小為5的float array參考:https://github.com/microsoft/vscode-cpptools/issues/688#issuecomment-299262784https://stackoverflow.com/questions/52721440/how-to-expand-an-array-while-debugging-in-visual-studio-codeGDB列印位址//變數c的位址p&amp;chttps://stackoverflow.com/questions/43861731/gdb-print-the-value-of-memory-address列印位址的內容(gdb) p *(struct node *) 0x00000000004004fchttps://stackoverflow.com/questions/43861731/gdb-print-the-value-of-memory-addresssegmentation fault 除錯 gdb run 並且帶入執行參數gdb –args executablename arg1 arg2 arg3(gdb) runhttps://stackoverflow.com/questions/6121094/how-do-i-run-a-program-with-commandline-arguments-using-gdb-within-a-bash-script https://www.cnblogs.com/realjimmy/p/12850884.html" }, { "title": "2024-07-10-VScode-Makefile-Debug", "url": "/posts/VScode-Makefile-Debug/", "categories": "", "tags": "", "date": "2024-07-10 17:31:00 +0800", "snippet": "參考:https://hackernoon.com/how-to-set-up-c-debugging-in-vscode-using-a-makefile" }, { "title": "製作Linux-Deamon", "url": "/posts/%E8%A3%BD%E4%BD%9CLinux-Deamon/", "categories": "", "tags": "", "date": "2024-07-05 17:31:00 +0800", "snippet": "參考:https://lloydrochester.com/post/c/unix-daemon-example/https://www.freedesktop.org/software/systemd/man/latest/daemon.htmlhttps://stackoverflow.com/questions/17954432/creating-a-daemon-in-linux/17955149#17955149" }, { "title": "vscode編譯cuda程式", "url": "/posts/vscode%E7%B7%A8%E8%AD%AFcuda%E7%A8%8B%E5%BC%8F/", "categories": "", "tags": "", "date": "2024-06-05 17:31:00 +0800", "snippet": "clangd cuda 設定https://www.youtube.com/watch?v=gN3XeFwZ4ng範例下載https://github.com/NVIDIA/cuda-samples/tree/v12.4非常單的cuda 程式撰寫https://developer.nvidia.com/blog/even-easier-introduction-cuda/Nsight Visual Studio Code Editionhttps://marketplace.visualstudio.com/items?itemName=NVIDIA.nsight-vscode-edition程式撰寫https://www.olcf.ornl.gov/cuda-training-series/https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning/https://paulrichmond.shef.ac.uk/teaching/COM4521/" }, { "title": "Wireshark擷取封包", "url": "/posts/Wireshark%E6%93%B7%E5%8F%96%E5%B0%81%E5%8C%85/", "categories": "", "tags": "", "date": "2024-05-29 17:31:00 +0800", "snippet": "http://www.cs.nccu.edu.tw/~jang/teaching/CompNet_files/Wireshark-%E5%9F%BA%E7%A4%8E%E6%95%99%E5%AD%B8.pdf" }, { "title": "Windows-NTP校時", "url": "/posts/Windows-NTP%E6%A0%A1%E6%99%82/", "categories": "", "tags": "", "date": "2024-05-24 17:31:00 +0800", "snippet": "w32tm有兩個地方可以設定，一個是registry，一個是policy(GPO)registry可以用regedit開啟，位於HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\W32Timepolicy用gpedit.msc可以開啟，位於Computer Configuration\\Policies\\Administrative Templates\\System\\Windows Time Service下面指令測試是否可以連線到NTP serverw32tm /stripchart /computer:time.windows.com /samples:5 下面指令可以設定NTP server w32tm /config /manualpeerlist:NTP.iead.local /syncfromflags:manual /updatew32tm /query /configuration確認看到以下訊息，(本機)代表是從registry讀取的設定，(原則)代表是從 policy(GPO) 讀取的設定NtpServer (本機)DllName: C:\\Windows\\SYSTEM32\\w32time.DLL (本機)Enabled: 1 (原則)InputProvider: 0 (本機)AllowNonstandardModeCombinations: 1 (本機)執行 regedit執行IBM重點參考文章https://www.dell.com/support/kbdoc/zh-cn/000134430/windows-time-service-%E6%95%85%E9%9A%9C-%E5%A4%84%E7%90%86https://www.ravenswoodtechnology.com/network-time-protocol-configurations-a-deeper-dive/https://www.ravenswoodtechnology.com/in-sync-proper-time-configuration-in-ad/https://superuser.com/questions/451018/how-can-i-query-an-ntp-server-under-windowshttps://www.renanrodrigues.com/post/how-to-configure-ntp-server-in-active-directory-step-by-stepWindows作為NTP serverhttps://support.hanwhavision.com/hc/en-us/articles/26570683589529-How-to-Setup-an-NTP-Server-on-Windows-10" }, { "title": "Ubuntu安裝軟體遇到Hash-mismatch錯誤", "url": "/posts/Ubuntu%E5%AE%89%E8%A3%9D%E8%BB%9F%E9%AB%94%E9%81%87%E5%88%B0Hash-mismatch%E9%8C%AF%E8%AA%A4/", "categories": "", "tags": "", "date": "2024-04-19 17:31:00 +0800", "snippet": " 如果是在wsl，檢查一下nameserver設定，確認DNS伺服器有沒有正確設定。https://geekdudes.wordpress.com/2022/11/16/windows-subsistem-for-linux-make-etc-resolv-conf-changes-permanent/ 在網路很糟的情況下可以重複apt update，有mismatch的部分會慢慢被校正。 更改鏡像網站https://note.drx.tw/2012/01/mirror.html https://blog.miniasp.com/post/2019/02/19/Ubuntu-apt-update-hash-sum-mismatch#google_vignette" }, { "title": "Deepstream開發環境設定", "url": "/posts/Deepstream%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E5%AE%9A/", "categories": "", "tags": "", "date": "2024-04-19 17:31:00 +0800", "snippet": "Setup Deepstream C development enviornment with CMake and VSCode2024/07/05更新安裝C/C++、CMake 、CMake Tools extensionC/C++的IntelliSense直接選compile_commands.jsonhttps://code.visualstudio.com/docs/cpp/configure-intellisenselaunch.json{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"(gdb) Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${command:cmake.launchTargetPath}\", \"args\": [\"-c\", \"licenceplate_nvmultiurisrcbin.txt\"], \"stopAtEntry\": false, \"cwd\": \"${workspaceFolder}\", \"environment\": [], \"externalConsole\": false, \"MIMode\": \"gdb\", \"setupCommands\": [ { \"description\": \"Enable pretty-printing for gdb\", \"text\": \"-enable-pretty-printing\", \"ignoreFailures\": true }, { \"description\": \"Set Disassembly Flavor to Intel\", \"text\": \"-gdb-set disassembly-flavor intel\", \"ignoreFailures\": true } ] } ]}查看char *完整內容https://stackoverflow.com/questions/52721440/how-to-expand-an-array-while-debugging-in-visual-studio-code2024/07/05前舊方法Prequirements CMake &gt; 3.25```bashsudo apt-get updatesudo apt-get install ca-certificates gpg wgettest -f /usr/share/doc/kitware-archive-keyring/copyright ||wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2&gt;/dev/null | gpg –dearmor - | sudo tee /usr/share/keyrings/kitware-archive-keyring.gpg &gt;/dev/nullFor Ubuntu Jammy Jellyfish (22.04):echo ‘deb [signed-by=/usr/share/keyrings/kitware-archive-keyring.gpg] https://apt.kitware.com/ubuntu/ jammy main’ | sudo tee /etc/apt/sources.list.d/kitware.list &gt;/dev/nullsudo apt-get updateFor Ubuntu Focal Fossa (20.04):echo ‘deb [signed-by=/usr/share/keyrings/kitware-archive-keyring.gpg] https://apt.kitware.com/ubuntu/ focal main’ | sudo tee /etc/apt/sources.list.d/kitware.list &gt;/dev/nullsudo apt-get updatetest -f /usr/share/doc/kitware-archive-keyring/copyright ||sudo rm /usr/share/keyrings/kitware-archive-keyring.gpgsudo apt-get install kitware-archive-keyringsudo apt-get install cmake* VSCode* clangd```bashsudo apt-get install clangd-12 package to run this example sudo apt-get install libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev \\ libgstrtspserver-1.0-dev libx11-dev libjson-glib-dev libyaml-cpp-dev Setup VSCode for development install VSCode extension CodeLLDB、clangd 、CMake 、CMake Tools Note: Do not install C/C++ extension pack from Microsoft copy deepstream-test5 to your workspacedeepstream-test5 is a complete example to modify deepstream-app，this will take the advantage of the module design of deepstream-app. You can add probe to customize the app. It have good config parser and error handling, those will save many effort.Following our workspace is in the copy of deepstream-test5 folder.cp -r /opt/nvidia/deepstream/deepstream/apps/sample_apps/deepstream-test5/* /path/to/your/workspace create launch.json and task.jsoncreate launch.json and task.json for compile and debugtasks.json use CMake to build{ \"version\": \"2.0.0\", \"tasks\": [ { \"type\": \"cmake\", \"label\": \"CMake: build\", \"command\": \"build\", \"targets\": [ \"all\" ], \"group\": \"build\", \"problemMatcher\": [], \"detail\": \"CMake template build task\" } ]}launch.json call task in task json to build{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"lldb\", \"request\": \"launch\", \"name\": \"Debug\", \"program\": \"${workspaceFolder}/deepstream-test5\",//the path of the executable file deepstream-test5 \"args\": [\"-c\", \"configs/test5_config_file_src_infer.txt\"],//arg for deepstream-test5 \"cwd\": \"${workspaceFolder}\",//指定工作目錄 \"preLaunchTask\": \"CMake: build\" } ]}create settings.json for clangd to read compile_commands.json. clangd can generate code navigator.{ \"cmake.sourceDirectory\": \"${workspaceFolder}\", \"cmake.generator\": \"Unix Makefiles\", \"clangd.arguments\": [ \"--compile-commands-dir=${workspaceFolder}/build\", \"--background-index\", \"-j=8\", \"--query-driver=/usr/bin/clang++\", \"--clang-tidy\", \"--clang-tidy-checks=performance-*,bugprone-*\", \"--all-scopes-completion\", \"--completion-style=detailed\", \"--function-arg-placeholders\", \"--header-insertion=iwyu\", \"--pch-storage=memory\", ],} Create CMAKELists.txt Create CMakeLists.txt under the workspace folder, CMake will help you find CUDA and nvcc, no more CUDA_VER env variable needed even in jetson.In this example，we need to compile deepstream-app first and use the object file in our project.So we use ExternalProject_Add to do this.We need to change the permission for deepstream-app source folder in order to compile the deepstream-app.sudo chmod -R 777 /opt/nvidia/deepstream/deepstream/sources/apps/cmake_minimum_required(VERSION 3.25)project(deepstream-test5 LANGUAGES C CXX) #project(deepstream-test5 LANGUAGES CUDA C CXX)set(CMAKE_CXX_STANDARD 14)set (CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR})set(CMAKE_EXPORT_COMPILE_COMMANDS ON)set(CMAKE_BUILD_TYPE Debug)find_package(PkgConfig REQUIRED)pkg_check_modules(PKGS REQUIRED uuid x11 gstreamer-video-1.0 json-glib-1.0 gstreamer-1.0 gstreamer-rtsp-server-1.0 yaml-cpp)find_package(CUDAToolkit)message(\"CUDA_VER is ${CUDAToolkit_VERSION_MAJOR}.${CUDAToolkit_VERSION_MINOR}\")if(NOT DEFINED CMAKE_CUDA_STANDARD) set(CMAKE_CUDA_STANDARD 11) set(CMAKE_CUDA_STANDARD_REQUIRED True)endif()SET(DEEPSTREAMAPP /opt/nvidia/deepstream/deepstream/sources/apps)include(ExternalProject)ExternalProject_Add(deepstreamapp SOURCE_DIR ${DEEPSTREAMAPP}/sample_apps/deepstream-app CONFIGURE_COMMAND \"\" INSTALL_COMMAND \"\" DOWNLOAD_COMMAND \"\" BUILD_COMMAND export CUDA_VER=${CUDAToolkit_VERSION_MAJOR}.${CUDAToolkit_VERSION_MINOR} &amp;&amp; make BUILD_IN_SOURCE true)file(GLOB_RECURSE DEEPSTREAMAPPCOMMONOBJ \"/opt/nvidia/deepstream/deepstream/sources/apps/apps-common/src/*.o\")file(GLOB_RECURSE DEEPSTREAMAPPOBJ \"/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-app/*.o\")list(REMOVE_ITEM DEEPSTREAMAPPOBJ \"/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-app/deepstream_app_main.o\")message(DEEPSTREAMAPPCOMMONOBJ=\"${DEEPSTREAMAPPCOMMONOBJ}\")message(DEEPSTREAMAPPOBJ=\"${DEEPSTREAMAPPOBJ}\")SET(OBJS ${DEEPSTREAMAPPCOMMONOBJ} ${DEEPSTREAMAPPOBJ} /opt/nvidia/deepstream/deepstream/sources/apps/apps-common/src/deepstream_config_file_parser.o ) SET_SOURCE_FILES_PROPERTIES( ${OBJS} PROPERTIES EXTERNAL_OBJECT true GENERATED true)add_executable(${PROJECT_NAME} ${OBJS} deepstream_utc.c deepstream_test5_app_main.c)target_include_directories(${PROJECT_NAME} PRIVATE ${PKGS_INCLUDE_DIRS} ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES} /opt/nvidia/deepstream/deepstream/sources/apps/apps-common/includes /opt/nvidia/deepstream/deepstream/sources/includes /opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-app ${CMAKE_CURRENT_SOURCE_DIR}/cparse ${CMAKE_CURRENT_SOURCE_DIR})target_link_libraries(${PROJECT_NAME} PRIVATE ${PKGS_LIBRARIES} CUDA::cuda_driver nvds_utils nvdsgst_helper m nvdsgst_meta nvds_meta stdc++ nvbufsurface nvbufsurftransform nvds_batch_jpegenc uuid jpeg png nvds_yml_parser nvdsgst_smartrecord nvds_msgbroker nvdsgst_customhelper pthread PRIVATE CUDA::cudart)target_link_directories(${PROJECT_NAME} PRIVATE /opt/nvidia/deepstream/deepstream/lib/)target_link_options(${PROJECT_NAME} PRIVATE -Wl,-rpath,/opt/nvidia/deepstream/deepstream/lib/) build projectclick the build button in VSCode and select the gcc compiler. start debug and make a breakpoint code navigation example projecthttps://github.com/jenhaoyang/deepstream-startup " }, { "title": "CUDA編譯經驗", "url": "/posts/CUDA%E7%B7%A8%E8%AD%AF%E7%B6%93%E9%A9%97/", "categories": "", "tags": "", "date": "2024-04-19 17:31:00 +0800", "snippet": " 取得compute capability編譯CUDA提供的example並且執行deviceQuery程式，注意example要下載正確的CUDA版本 Cuda Error (209): cudaLaunchKernel returned cudaErrorNoKernelImageForDevice https://stackoverflow.com/questions/62901027/cuda-error-209-cudalaunchkernel-returned-cudaerrornokernelimagefordevice 關於compute capability更進一步的說明https://stackoverflow.com/questions/35656294/cuda-how-to-use-arch-and-code-and-sm-vs-compute/35657430#35657430 正確取得CUDA errorhttps://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api 參考https://stackoverflow.com/questions/62901027/cuda-error-209-cudalaunchkernel-returned-cudaerrornokernelimagefordevice" }, { "title": "update-alternatives管理軟體版本", "url": "/posts/update-alternatives%E7%AE%A1%E7%90%86%E8%BB%9F%E9%AB%94%E7%89%88%E6%9C%AC/", "categories": "", "tags": "", "date": "2024-04-17 17:31:00 +0800", "snippet": "update-alternatives --display cudaupdate-alternatives --config cuda參考:https://www.baeldung.com/linux/update-alternatives-commandhttps://then.tw/switch-gcc-versions-with-update-alternatives/" }, { "title": "用bash讓程式壞掉的時候自動重啟", "url": "/posts/%E7%94%A8bash%E8%AE%93%E7%A8%8B%E5%BC%8F%E5%A3%9E%E6%8E%89%E7%9A%84%E6%99%82%E5%80%99%E8%87%AA%E5%8B%95%E9%87%8D%E5%95%9F/", "categories": "", "tags": "", "date": "2024-04-17 17:31:00 +0800", "snippet": "until myserver; do echo \"Server 'myserver' crashed with exit code $?. Respawning..\" &gt;&amp;2 sleep 1done參考:https://stackoverflow.com/a/697064/22299707" }, { "title": "nohup使用教學", "url": "/posts/nohup%E4%BD%BF%E7%94%A8%E6%95%99%E5%AD%B8/", "categories": "", "tags": "", "date": "2024-04-17 17:31:00 +0800", "snippet": "nohup command &gt;logfile.txt 2&gt;&amp;1 &amp;參考https://blog.csdn.net/xiaojin21cen/article/details/88991768" }, { "title": "ssh經過跳板機的連線方式", "url": "/posts/ssh%E7%B6%93%E9%81%8E%E8%B7%B3%E6%9D%BF%E6%A9%9F%E7%9A%84%E9%80%A3%E7%B7%9A%E6%96%B9%E5%BC%8F-copy/", "categories": "", "tags": "", "date": "2024-03-12 17:31:00 +0800", "snippet": "Host Target HostName 192.168.8.71 User user1 ProxyJump JumpServerHost JumpServer HostName 192.168.8.149 User jumpuser參考https://city.shaform.com/zh/2017/10/28/ssh-proxycommand/" }, { "title": "Ubuntu22遠端桌面設定", "url": "/posts/Ubuntu22%E9%81%A0%E7%AB%AF%E6%A1%8C%E9%9D%A2%E8%A8%AD%E5%AE%9A/", "categories": "", "tags": "", "date": "2024-03-12 17:31:00 +0800", "snippet": "xrdp設定https://vegastack.com/tutorials/how-to-install-xrdp-server-on-ubuntu-22-04/https://dic.vbird.tw/linux_server/unit06.php注意 如果安裝Ubuntu的時候就已經是安裝Desktop版本，就不需要另外安裝xfce 使用遠端桌面的時候，要登入的帳號不可以在遠端的電腦已經登入，因此必須要把AutoLogin關閉" }, { "title": "apt離線安裝套件的方法", "url": "/posts/apt%E9%9B%A2%E7%B7%9A%E5%AE%89%E8%A3%9D%E5%A5%97%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95/", "categories": "", "tags": "", "date": "2024-02-26 17:31:00 +0800", "snippet": "apt-offlinehttps://unix.stackexchange.com/questions/694346/transfering-and-offline-installing-net-tools-in-an-ubuntu-server-with-no-internehttps://gist.github.com/ycku/fa3110bce427cf2c1f1ca4a680d594e8#apt-installoffline$ sudo apt-offline set install.sig --install-packages apache2 libapache2-mod-phponline$ apt-offline get install.sig --threads 5 --bundle install.zipoffline$ sudo apt-offline install install.zipoffline$ sudo apt-get install apache2 libapache2-mod-php" }, { "title": "讓docker pull回復上次失敗的下載", "url": "/posts/%E8%AE%93docker-pull%E5%9B%9E%E5%BE%A9%E4%B8%8A%E6%AC%A1%E5%A4%B1%E6%95%97%E7%9A%84%E4%B8%8B%E8%BC%89/", "categories": "", "tags": "", "date": "2024-02-19 17:31:00 +0800", "snippet": "解決方法https://github.com/docker/for-linux/issues/1187#issuecomment-1570501567sudo mkdir /etc/dockersudo gedit /etc/docker/daemon.json加入這個屬性{ \"features\": {\"containerd-snapshotter\": true}}sudo systemctl restart docker自動重新下載docker imagewhile ! docker pull nvcr.io/nvidia/deepstream:6.4-gc-triton-devel; do sleep .1; done &amp;&amp; echo OK" }, { "title": "串流相關知識", "url": "/posts/%E4%B8%B2%E6%B5%81%E7%9B%B8%E9%97%9C%E7%9F%A5%E8%AD%98/", "categories": "", "tags": "", "date": "2024-02-01 17:31:00 +0800", "snippet": "RTP/RTCP跟TCP和UDP一樣為傳輸層協議規範RFC3350RTCP (RTP Control Protocol)專門用來處理服務品質(Qos)RTP可以選擇用UDP或是TCP來進行傳輸https://mark-lin.com/posts/20180912/(主要)http://albert-oma.blogspot.com/2012/05/rtp.htmlbps(bit Per Second)位元率 (bps) = 採樣率(hz) x 採樣大小(bit) x 通道編碼將raw檔轉換壓縮聲音編碼例如MP3和AAC色彩顏色編碼RGB與YUV影像編碼H26X和VPX主流有H264和VP8封裝將聲音和影像編碼後的結果放進容器的過程容器用來盛裝編碼，一種編碼可以放進各種容器，例如MP3編碼可以放進.mp3、.mp4、.avi容器裡面網路協議https://www.jianshu.com/p/9f3e879a4c9c" }, { "title": "2024-01-23-CMake編譯OpenCV-Python", "url": "/posts/CMake%E7%B7%A8%E8%AD%AFOpenCV-Python/", "categories": "", "tags": "", "date": "2024-01-20 17:31:00 +0800", "snippet": "Here is the minimal steps.Here is my enviornment Windows 10 Visual Studio Build Tools 2019 CMake 3.29.0-rc1 (use default install setting) Gstreamer:(Use default install setting)MSVC 64-bit (VS 2019, Release CRT)1.22.10 runtime installer1.22.10 development installer Python3.8.10For example, my gstreamer is install in D disk by default. Add System Environment Variable GSTREAMER_ROOT_X86_64 value D:\\gstreamer\\1.0\\msvc_x86_64gstreamer doc Add enviornment variable GST_PLUGIN_PATH value D:\\gstreamer\\1.0\\msvc_x86_64\\lib\\gstreamer-1.0 Add Path enviornment variable value D:\\gstreamer\\1.0\\msvc_x86_64\\bin re-login the computer create a Python venv and use it pip install --verbose --no-binary opencv-python opencv-python os.add_dll_directory() Shoud be add to code since from Python 3.8+, Python will NOT search DLL from PATH enviornment variable.ref test codeimport osos.add_dll_directory(\"D:\\\\gstreamer\\\\1.0\\\\msvc_x86_64\\\\bin\")import cv2gst = 'rtspsrc location=rtsp://192.168.8.57/live1s3.sdp timeout= 30000 ! decodebin ! videoconvert ! video/x-raw,format=BGR ! appsink drop=1'cap = cv2.VideoCapture(gst,cv2.CAP_GSTREAMER)while(cap.isOpened()): ret, frame = cap.read() if not ret: break cv2.imshow('frame', frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): breakcv2.destroyAllWindows()cap.release()安裝cmake(不一定要裝)安裝msvc2019 build tool安裝python3.8.10設定GSTREAMER_ROOT_X86_64環境變數gstreamer doc&lt;gstreamer資料夾&gt;\\1.0\\msvc_x86_64直接安裝source distributions版本的opencv-python(opencv 4.3.0之後的版本)pip install --verbose --no-binary opencv-python opencv-pythonGST_PLUGIN_PATH或是GST_PLUGIN_SYSTEM_PATH(不一定要加)gstreamer預設尋找plugin的順序如下 %HOMEDRIVE%%HOMEFOLDER%/.gstreamer-1.0/plugins C:\\gstreamer\\1.0\\x86\\lib\\gstreamer-1.0 \\..\\lib\\gstreamer-1.0 %GST_PLUGIN_PATH%&lt;gstreamer資料夾&gt;\\1.0\\msvc_x86_64\\lib\\gstreamer-1.0gstreamer docPath變數&lt;gstreamer資料夾&gt;\\1.0\\msvc_x86_64\\bin載入時手動加入dll路徑os.add_dll_directory()ref測試import osos.add_dll_directory(\"D:\\\\gstreamer\\\\1.0\\\\msvc_x86_64\\\\bin\")import cv2gst = 'rtspsrc location=rtsp://192.168.8.57/live1s3.sdp timeout= 30000 ! decodebin ! videoconvert ! video/x-raw,format=BGR ! appsink drop=1'cap = cv2.VideoCapture(gst,cv2.CAP_GSTREAMER)while(cap.isOpened()): ret, frame = cap.read() if not ret: break cv2.imshow('frame', frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): breakcv2.destroyAllWindows()cap.release()gstreamer載入時錯誤檢查 用 Dependencies 軟體檢查dll缺少哪一些東西 plugin找不到的錯誤可能是找不到plugin的dll本身，或是找不到plugin所需要的dll安裝CUDACUDA 設定從4.0之後CUDA相關的功能被移到opencv_contrib，必須要編一opencv_contrib才能啟用CUDA功能 set CMAKE_ARGS=\"-DWITH_CUDA=ON\" pip install –verbose –no-binary opencv-contrib-python opencv-contrib-python(選擇性)G-APIG-API說明https://github.com/opencv/opencv/wiki/Graph-API" }, { "title": "2024-01-20-Elasticsearch-客製化搜尋條件", "url": "/posts/Elasticsearch-%E5%AE%A2%E8%A3%BD%E5%8C%96%E6%90%9C%E5%B0%8B%E6%A2%9D%E4%BB%B6-copy/", "categories": "", "tags": "", "date": "2024-01-20 17:31:00 +0800", "snippet": "Painless Scripthttps://www.elastic.co/guide/en/elasticsearch/painless/current/painless-walkthrough.html只選擇夜間的資料https://stackoverflow.com/a/35596907{ \"query\": { \"bool\": { \"filter\": [ { \"range\": { \"OccurrenceTime\": { \"gte\": \"2023-12-01\", \"lt\": \"2024-01-20\" } } }, { \"script\": { \"script\": \"doc.OccurrenceTime.value.hour &gt;= 10 &amp;&amp; doc.OccurrenceTime.value.hour &lt;= 21\" } } ] } }}" }, { "title": "製作Python-package", "url": "/posts/%E8%A3%BD%E4%BD%9CPython-package/", "categories": "", "tags": "", "date": "2024-01-10 17:31:00 +0800", "snippet": "參考製作Python-package" }, { "title": "c 執行錯誤經驗", "url": "/posts/linux%E5%AF%86%E7%A2%BC%E8%B3%87%E5%AE%89%E8%A8%AD%E5%AE%9A/", "categories": "", "tags": "", "date": "2024-01-04 17:31:00 +0800", "snippet": "參考https://cynthiachuang.github.io/Enforce-Password-Policies-and-Force-User-to-Change-Password-in-Linux/" }, { "title": "c程式找不到函示庫 ld錯誤 函示庫各種雜症", "url": "/posts/c%E7%A8%8B%E5%BC%8F%E6%89%BE%E4%B8%8D%E5%88%B0%E5%87%BD%E7%A4%BA%E5%BA%AB-ld%E9%8C%AF%E8%AA%A4-%E5%87%BD%E7%A4%BA%E5%BA%AB%E5%90%84%E7%A8%AE%E9%9B%9C%E7%97%87/", "categories": "", "tags": "", "date": "2024-01-04 17:31:00 +0800", "snippet": "signal SIGSEGV: address not mapped to object (fault address: 0x20)static function不需要被呼叫就有可能發生錯誤dlopen無法載入函示庫https://stackoverflow.com/a/2991677/22299707 用ldd -r 列出所以找不到的函式庫像這樣 linux-vdso.so.1 (0x00007ffcfd376000) libjson-glib-1.0.so.0 =&gt; /lib/x86_64-linux-gnu/libjson-glib-1.0.so.0 (0x00007f210d72c000) .....undefined symbol: descriptor_table_google_2fprotobuf_2ftimestamp_2eproto (./libnvds_msgconv.so)undefined symbol: _ZN6google8protobuf7Message17CopyWithSizeCheckEPS1_RKS1_ (./libnvds_msgconv.so)..... 用c++filt顯示函式庫名稱，還原函數名稱 c++filt _ZN6google8protobuf7Message17CopyWithSizeCheckEPS1_RKS1_ " }, { "title": "演算法練習筆記", "url": "/posts/%E6%BC%94%E7%AE%97%E6%B3%95%E7%B7%B4%E7%BF%92%E7%AD%86%E8%A8%98/", "categories": "", "tags": "", "date": "2023-12-19 17:31:00 +0800", "snippet": " 注意題目裡的線索 例如題目如果出現”寫一個在伺服器長時間重複運作的程式”，你可以想看看快取是不是可以派上用場 寫出測試範例 要特別注意自己寫出來的範例是不是特例 嘗試暴力解 優化Check Permutation: Given two strings, write a method to decide if one is a permutation of the other. p.90def check_permutation(s1, s2): if len(s1) != len(s2): return False sd1 = {} for i in s1: if sd1.get(i): sd1[i] = sd1[i] + 1 else: sd1[i] = 1 for j in s2: if sd1.get(j): if sd1.get(j) &gt; 0: sd1[i] = sd1[i] - 1 else: return False else: return False return True samples dad, bda abc, bca sss, sss sas, ssa abcd, abc bbba, bbbbURLify: Write a method to replace all spaces in a string with ‘%20’. You may assume that the string has sufficient space at the end to hold the additional characters, and that you are given the “true” length of the string. (Note: If implementing in Java, please use a character array so that you can perform this operation in place.) 錯誤1:忘記回傳值Palindrome Permutation: Given a string, write a function to check if it is a permutation of a palin-drome. A palindrome is a word or phrase that is the same forwards and backwards. A permutation is a rearrangement of letters. The palindrome does not need to be limited to just dictionary words.import copydef palindrome(input): input = input.lower() char_dict = {} for c in input: if c != \" \": if char_dict.get(c): char_dict.pop(c) else: char_dict[c] = 1 if len(char_dict) &gt; 1: return False return True錯誤1: 沒有考慮到大小寫問題One Away: There are three types of edits that can be performed on strings: insert a character, remove a character, or replace a character. Given two strings, write a function to check if they are one edit (or zero edits) away.def one_edit(str_a, str_b): if len(str_a) - len(str_b) == -1: for c in str_a: if c not in str_b: return False elif len(str_a) - len(str_b) == 1: for c in str_b: if c not in str_a: return False elif len(str_a) - len(str_b) == 0: counter = 0 for c in str_a: if c not in str_b: counter +=1 if counter &gt; 1: return False else: return False return True" }, { "title": "systemd相關", "url": "/posts/systemd%E7%9B%B8%E9%97%9C/", "categories": "", "tags": "", "date": "2023-11-02 17:31:00 +0800", "snippet": "移除服務systemctl stop [servicename]systemctl disable [servicename]sudo trash /etc/systemd/system/[servicename]sudo trash /etc/systemd/system/[servicename] # and symlinks that might be relatedsudo trash /usr/lib/systemd/system/[servicename] sudo trash /usr/lib/systemd/system/[servicename] # and symlinks that might be relatedsystemctl daemon-reloadsystemctl reset-failedbashhttps://superuser.com/a/936976" }, { "title": "Ubuntu好用套件", "url": "/posts/Ubuntu%E5%A5%BD%E7%94%A8%E5%A5%97%E4%BB%B6/", "categories": "", "tags": "", "date": "2023-11-01 17:31:00 +0800", "snippet": "資源監視器btophttps://github.com/aristocratos/bpytop#installation" }, { "title": "Kafka疑難雜症", "url": "/posts/Kafka%E7%96%91%E9%9B%A3%E9%9B%9C%E7%97%87/", "categories": "", "tags": "", "date": "2023-11-01 17:31:00 +0800", "snippet": "服務無法啟動，Kafka Broker doesn’t find cluster id移除meta.properties.參考:https://stackoverflow.com/questions/59592518/kafka-broker-doesnt-find-cluster-id-and-creates-new-one-after-docker-restart" }, { "title": "CMake疑難雜症", "url": "/posts/CMake%E7%96%91%E9%9B%A3%E9%9B%9C%E7%97%87/", "categories": "", "tags": "", "date": "2023-11-01 17:31:00 +0800", "snippet": "Failed to detect a default CUDA architecture或是CMAKE_CUDA_ARCHITECTURES must be non-empty if set直接告訴CMake nvcc的位置，注意舊的build資料夾要先清掉-DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.7/bin/nvcchttps://www.cnblogs.com/metaz/p/16919028.htmlVS code設定cmake的環境變數在setting.json加入\"cmake.environment\": {\"CUDA_VER\":\"11.7\"}，說明書:https://github.com/microsoft/vscode-cmake-tools/blob/main/docs/cmake-presets.md#ignored-settingsCMake presets: https://dominikberner.ch/cmake-presets-best-practices/CMake 系統環境變數設置https://www.scivision.dev/cmake-environment-variable-scope/libcuda.so.1 not found使用find_package(CUDAToolkit)並且在target_link_libraries 加入CUDA::cuda_driverCMake find_package() 用法CMake有許多尋找套件的module，例如FindCUDAToolkit，下面連結條列各種find_package()能使用的modulehttps://cmake.org/cmake/help/latest/manual/cmake-modules.7.html#manual:cmake-modules(7)" }, { "title": "apt相關問題", "url": "/posts/apt%E7%9B%B8%E9%97%9C%E5%95%8F%E9%A1%8C/", "categories": "", "tags": "", "date": "2023-10-27 17:31:00 +0800", "snippet": "apt找不到key或重複套件，刪掉有問題的apt keysudo rm /etc/apt/sources.list.d/*cuda*查看所有可以安裝的版本apt-cache madison cudahttps://askubuntu.com/questions/447/how-can-i-see-all-versions-of-a-package-that-are-available-in-the-archive刪除apt key 顯示所有keyapt-key list顯示結果如下```bash/etc/apt/trusted.gpg——————–pub rsa4096 2022-05-05 [SCEA] 8298 D919 610D E70B 90CE DAAE EE38 2EF7 8230 7095uid [ unknown] TensorRT svc_tensorrt@nvidia.com/etc/apt/trusted.gpg.d/flexiondotorg_ubuntu_nvtop.gpgpub rsa1024 2011-03-16 [SC] 824A 27DD 09DE DA33 BF78 3596 2EA8 F357 93D8 809Auid [ unknown] Launchpad PPA for Martin Wimpress/etc/apt/trusted.gpg.d/graphics-drivers_ubuntu_ppa.gpgpub rsa4096 2015-08-12 [SC] 2388 FF3B E10A 76F6 38F8 0723 FCAE 110B 1118 213Cuid [ unknown] Launchpad PPA for Graphics Drivers Team* 刪掉key以下面為例，key ID就是最後8碼`82307095`，`sudo apt-key del 82307095`就可以刪除/etc/apt/trusted.gpg——————–pub rsa4096 2022-05-05 [SCEA] 8298 D919 610D E70B 90CE DAAE EE38 2EF7 8230 7095uid [ unknown] TensorRT svc_tensorrt@nvidia.com# 解決Unmet dependencies問題* 用`dpkg -P package-name`來移除有問題的套件，他會顯示不能移除的原因，然後依序移除即可* 直接用dpkg安裝套件，如果有缺少的相依套件，之後使用apt install就會顯示`E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).`錯誤，必須要手動解決相依性問提# apt install使用local repo參考: https://wiki.debian.org/DebianRepository/Setup?action=show&amp;redirect=DebianRepository%2FHowTo%2FTrivialRepository#trivialArchiveQuick instructions to create a trivial local archive with apt-ftparchiveWe use /var/lib/mydebs as the example locationCreate the directorymkdir -p /var/lib/mydebsEvery time you put new files in the directory, you’ll have to scan the directory and update:cd /var/lib/mydebs apt-ftparchive packages . &gt; Packages apt-ftparchive release . &gt; ReleaseAdd this line to /etc/apt/sources.listdeb [allow-insecure=yes] file:/var/lib/mydebs ./Now you can install the package normally. If apt-get asks “Install these packages without verification?”, answer “Y” to install. That’s because this local repository is not signed.apt-get update apt-get install mydeb# 刪除apt gpg key 和repohttps://itslinuxfoss.com/delete-repository-and-gpg-key-ubuntu/#2# 查看套件版本`dpkg-query -W tensorrt`# 用apt 查看可安裝的版本`apt-cache policy &lt;package name&gt;`例如```bash$ apt-cache policy gpartedgparted: Installed: 0.16.1-1 Candidate: 0.16.1-1 Version table: *** 0.16.1-1 0 500 http://ubuntu.inode.at/ubuntu/ saucy/main amd64 Packages 100 /var/lib/dpkg/status安裝指定版本sudo apt-get install &lt;package name&gt;=&lt;version&gt;例如上面的例子$ sudo apt-get install gparted=0.16.1-1Reading package lists... DoneBuilding dependency tree Reading state information... Donegparted is already the newest version.0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded." }, { "title": "CodeInterview", "url": "/posts/CodeInterview/", "categories": "", "tags": "", "date": "2023-10-10 17:31:00 +0800", "snippet": "BigO 時間複雜度相加還是相乘相加 Add the Runtimes: 0 (A + B) 1 for (int a : arrA) { 2 print(a); 3 } 4 5 for (int b : arrB) { 6 print(b) ; 7 } 相乘:Multiply the Runtimes: O(A* B) 1 for (int a : arrA) { 2 for (int b : arrB) { 3 print(a + \" , \" + b); 4 } 5 } 遞迴的時間複雜度" }, { "title": "多媒體伺服器mediaserver", "url": "/posts/%E5%A4%9A%E5%AA%92%E9%AB%94%E4%BC%BA%E6%9C%8D%E5%99%A8mediaserver/", "categories": "", "tags": "", "date": "2023-10-07 17:31:00 +0800", "snippet": "" }, { "title": "Ubuntu root資料夾滿了", "url": "/posts/Ubuntu-root%E8%B3%87%E6%96%99%E5%A4%BE%E6%BB%BF%E4%BA%86/", "categories": "", "tags": "", "date": "2023-10-05 17:31:00 +0800", "snippet": "安裝ncdu檢查是哪一個資料夾滿了sudo apt install ncdu" }, { "title": "行人屬性辨識", "url": "/posts/%E8%A1%8C%E4%BA%BA%E5%B1%AC%E6%80%A7%E8%BE%A8%E8%AD%98/", "categories": "", "tags": "", "date": "2023-09-22 17:31:00 +0800", "snippet": "參考:https://cynthiachuang.github.io/Survey-Pedestrian-Attribute-Recognition/Pedestrian-Attribute-Recognition-Paper-Listhttps://github.com/2014gaokao/pedestrian-attribute-recognition-with-GCNhttps://github.com/valencebond/Rethinking_of_PAR/blob/master/infer.pyhttps://github.com/cxh0519/VTBhttps://github.com/dangweili/pedestrian-attribute-recognition-pytorch" }, { "title": "樹梅派傳真機", "url": "/posts/%E6%A8%B9%E6%A2%85%E6%B4%BE%E5%82%B3%E7%9C%9F%E6%A9%9F/", "categories": "", "tags": "", "date": "2023-09-21 17:31:00 +0800", "snippet": "尋找hardware modemhttps://www.instructables.com/Install-Modem-USB-Device-in-Raspberry-Pi/可參考的資料https://gist.github.com/nstarke/509dab2c91a0bb30e5fa65b922840ce0看起來像linux的驅動程式https://github.com/torvalds/linux/blob/42dc814987c1feb6410904e58cfd4c36c4146150/drivers/usb/class/cdc-acm.c#L1773CDC ACMhttps://michael.stapelberg.ch/posts/2021-04-27-linux-usb-virtual-serial-cdc-acm/" }, { "title": "印出requests內容", "url": "/posts/%E5%8D%B0%E5%87%BArequests%E5%85%A7%E5%AE%B9/", "categories": "", "tags": "", "date": "2023-09-21 17:31:00 +0800", "snippet": "import httpimport requestsdef patch_send(): old_send = http.client.HTTPConnection.send def new_send(self, data): print(f'{\"-\"*9} BEGIN REQUEST {\"-\"*9}') print(data.decode('utf-8').strip()) print(f'{\"-\"*10} END REQUEST {\"-\"*10}') return old_send(self, data) http.client.HTTPConnection.send = new_sendpatch_send()requests.get(\"http://secariolabs.com\")https://secariolabs.com/logging-raw-http-requests-in-python/" }, { "title": "自動尋找最適合的apt-mirror", "url": "/posts/%E8%87%AA%E5%8B%95%E5%B0%8B%E6%89%BE%E6%9C%80%E9%81%A9%E5%90%88%E7%9A%84apt-mirror/", "categories": "", "tags": "", "date": "2023-08-23 17:31:00 +0800", "snippet": "apt-mirror-updatersudo pip3 install apt-mirror-updatersudo apt-mirror-updater --auto-change-mirrorhttps://askubuntu.com/a/1093473" }, { "title": "Docker無法更新apt套件", "url": "/posts/Docker%E7%84%A1%E6%B3%95%E6%9B%B4%E6%96%B0apt%E5%A5%97%E4%BB%B6/", "categories": "", "tags": "", "date": "2023-08-17 17:31:00 +0800", "snippet": "Docker build的時候遇到Hash Sum mismatch解法:在dockerfile apt-get update之前建立一個/etc/apt/apt.conf.d/99fixbadproxy 文件如下RUN echo \"Acquire::http::Pipeline-Depth 0;\" &gt;&gt; /etc/apt/apt.conf.d/99fixbadproxy RUN echo \"Acquire::http::No-Cache true;\" &gt;&gt; /etc/apt/apt.conf.d/99fixbadproxy RUN echo \"Acquire::BrokenProxy true;\" &gt;&gt; /etc/apt/apt.conf.d/99fixbadproxy RUN apt-get update" }, { "title": "申請憑證", "url": "/posts/%E7%94%B3%E8%AB%8B%E6%86%91%E8%AD%89/", "categories": "", "tags": "", "date": "2023-07-27 17:31:00 +0800", "snippet": "CSR說明https://haway.30cm.gg/ssl-key-csr-crt-pem/https://docs.gandi.net/zh-hant/ssl/common_operations/csr.htmlLinux 產生CSR 檔#用openssl查看憑證檔內容憑證可能有不同格式，可以用這兩種指令查看openssl x509 -inform pem -noout -text -in 'cerfile.cer';openssl x509 -inform der -noout -text -in 'cerfile.cer';https://serverfault.com/a/215617憑證格式轉換不同格式的憑證可以互相轉換格式，例如降二進位DER格式轉換成PEM格式可以用下面兩個指令達成openssl x509 -inform DER -in &lt;path-to-cer-file&gt; -out &lt;path-to-crt-file&gt; openssl x509 -in &lt;path-to-crt-file&gt; -out &lt;path-to-pem-file&gt; -outform PEM範例:openssl x509 -inform DER -in C:\\Certificates\\AnyCert.cer -out C:\\Certificates\\AnyCertCrt.crt openssl x509 -in C:\\Certificates\\AnyCertCrt.crt -out C:\\Certificates\\AnyCertInPem.pem -outform PEM編碼格式說明與憑證講解:https://blog.miniasp.com/post/2018/04/21/PKI-Digital-Certificate-Format-Convertion-Noteshttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/unified-infrastructure-management/20-1/upgrading/ca-uim-upgrade-step-3-deploy-the-upgrade/upgrade-uim-server/secure-hub-and-robot-ca-uim-9-sp1/Convert-Files-to–pem-Format.html" }, { "title": "gdb pretty print", "url": "/posts/gdb-pretty-print/", "categories": "開發工具", "tags": "cpp", "date": "2023-07-15 17:31:00 +0800", "snippet": "STL Support Toolshttps://sourceware.org/gdb/wiki/STLSupportstl-views-1.0.3.gdbsource {full_path}stl-views-1.0.3.gdbYou can also put the command source stl-views-1.0.3.gdb in ~/.gdbinit - and then you’ll have it automatically every time you launch gdb.https://stackoverflow.com/a/2463250" }, { "title": "Dive into DeepLearning", "url": "/posts/DiveIntoDeepLearning/", "categories": "深度學習", "tags": "book", "date": "2023-07-05 16:50:00 +0800", "snippet": "數學符號說明$z = g \\circ f $就是z(x) = g(f(x))，也就是$y = f(x), z = g(y)$https://math.stackexchange.com/a/1092727$x \\in R$ : x是一個(一維)實數純量，例如$x =-2$ 或 $x=42$$x \\in R^{n*d}$Ch22.5 Automatic Diff erentiation現代的深度學習都有提供automatic differentiation(autograd)和backpropagation的功能，下面將介紹如何使用2.5.2 Backward for Non-Scalar Variables為什麼要先sum()之後才backpropagation?cs231nhttp://cs231n.stanford.edu/handouts/derivatives.pdf Scalar in Scalar out: 利用chain rule就可以計算backpropagation當函式為$f, g : R \\rightarrow R$且$z = (g \\circ f)(x)$則$\\frac{\\partial z}{\\partial x}=\\frac{\\partial z}{\\partial y}\\frac{\\partial y}{\\partial x}$。這告訴我們我們移動x一點點$\\Delta_x$則y移動的量如下\\(\\Delta_y=\\frac{\\partial y}{\\partial x}\\Delta_x\\)，而z移動的量為\\(\\frac{\\partial z}{\\partial y}\\Delta_y=\\frac{\\partial z}{\\partial y}\\frac{\\partial y}{\\partial x}\\Delta_x\\) Vector in, scalar out: 利用Gradient可以計算backpropagation當函式為$f : R^N \\rightarrow R$且$x \\in R^N$也就是說x是一個vector，而$\\nabla_xf(x) \\in R^N$，也就是Gradient的結果也是一個vector。繼續利用前面chain rule的概念\\(x\\rightarrow x+\\Delta_x \\Rightarrow y \\rightarrow \\approx y+\\frac{\\partial y}{\\partial x} \\cdot \\Delta_x\\)不過現在的狀況$x$, $\\Delta_x$, \\frac{\\partial y}{\\partial x} 都是vector，而兩個vector的內積剛好是scalar Vector in, Vector out現在函式$f:R^N \\rightarrow R^M$ Jacobianlinear mapmatrix代表了linear map，而determinant代表linear map之後面積放大的倍率，而負的determinant代表座標方向反轉 微分不應該單純的想成斜率，積分也不應該單純想成面積。而是用另以種角度來想，微分代表在某一個點上，把它放很大來看之後他的線性映射是如何(linear map) 對二維函式來說，Jacobian matrix就是在(a, b)附近的linear maphttps://youtu.be/wCZ1VEmVjVo https://youtu.be/CfW845LNObMhttps://angeloyeo.github.io/2020/07/24/Jacobian_en.htmlCH77.2.1 The Cross-Correlation Operation經過Cross-Correlation Operation後，輸出的tensor尺寸為$(n_h − k_h + 1 ) × (n_w − k_w + 1 )$7.2.2 Convolutional LayersConvolutional Layers就是經過Cross-Correlation Operation之後的tensor對每一個element都加上一個bias。Conv的kernel如同前面MLP的權重，初始化的時候我們是用亂數初始化7.2.3 Object Edge Detection in Images已知一個人工製作的邊緣偵測器kernel為[1, -1]可以偵測垂直線，等一下會嘗試讓電腦自己學習出這個kernel7.2.4 Learning a Kernel接下來我們要常識讓電腦自動學習kernel，為了簡單起見bias為0。(為什麼先sum再backward?)(https://www.youtube.com/watch?v=Q7KekwUricc)(https://dlvu.github.io/)以下程式可以自動學習kernel# Construct a two-dimensional convolutional layer with 1 output channel and a# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias hereimport torchfrom torch import nnfrom conv import corr2dX = torch.tensor([[1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.]])Y = torch.tensor([[ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.], [ 0., 1., 0., 0., 0., -1., 0.]])X = X.reshape((1, 1, 6, 8))Y = Y.reshape((1, 1, 6, 7))lr = 3e-2 # Learning rateconv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)for i in range(10): Y_hat = conv2d(X) l = (Y_hat - Y) ** 2 conv2d.zero_grad() l.sum().backward() # Update the kernel conv2d.weight.data[:] -= lr * conv2d.weight.grad if (i + 1) % 2 == 0: print(f'epoch {i + 1}, loss {l.sum():.3f}')print(conv2d.weight.data.reshape((1, 2)))PyTorch Lazy modules的用途:可以避免寫死in_features，對於動態的in_features來說比較方便https://jarvislabs.ai/blogs/PyTorch-lazy-modules/7.2.5 Cross-Correlation and Convolution再Deeplearning 使用的Convolution計算方式其實真正的名稱是Cross-Correlation，但是由於Cross-Correlation和Convolution的差別只在於kernerl上下和左右都互換，但對於traing的結果影響不大，所以依然稱為Convolution7.2.6 Feature Map and Receptive Fieldconvolutional layer的輸出稱為Feature Map。receptive field則是影響輸出結果之前的所有元素。()7.3 Padding and Stride單純使用conv會使得後面layer的input快速變小。Padding可以解決這個狀況，相反的Stride則是用來快速讓輸入變小。7.3.1 Paddingpadding和kernel關係的公式如下，假設row padding $p_h$, column padding $p_w$:\\((n_h − k_h + p_h + 1 ) × (n_w − k_w + p_w + 1 )\\)我們可以藉由$p_h=k_h-1$和$p_w=k_w-1$讓輸入和輸出的長寬一樣。如果$k$為奇數，則padding剛好可以填充到兩側，如果$k$為偶數則兩側的padding數量有一邊會多一個。7.3.2 Stride當高的stride為$s_h$寬的stride為$s_w$，則輸出為\\(\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor\\)7.4 Multiple Input and Multiple Output Channels7.4.1 Multiple Input Channels當輸入的channel數量大於1的時候，每一個channel會需要至少一個kernel。假設現在輸入有3個channel，每一個channel分別對一個kernel之後相加結果就是輸出。def corr2d_multi_in(X, K): # Iterate through the 0th dimension (channel) of K first, then add them up return sum(d2l.corr2d(x, k) for x, k in zip(X, K))X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])corr2d_multi_in(X, K)# tensor([[ 56., 72.],# [104., 120.]])7.4.2 Multiple Output Channels為了讓神經網路學到更多feature，我們嘗試讓同一層conv layer的kernel為三維而且第三個維度和輸入的channel數一樣$c_i\\times k_h \\times k_w$，例如輸入為3個channel，我們就設計kernel的第三個維度為3。由於每一組kernel最後的輸出都是一個channel。所以最後輸出的channel數就是kernel的組數。因此 convolution layer的維度就變成$c_o \\times c_i \\times k_h \\times k_w$ stack()在這裡會把沿著指定的dimension把tensor堆疊 def corr2d_multi_in_out(X, K): # Iterate through the 0th dimension of K, and each time, perform # cross-correlation operations with input X. All of the results are # stacked together return torch.stack([corr2d_multi_in(X, k) for k in K], 0)K = torch.stack((K, K + 1, K + 2), 0)K.shape#torch.Size([3, 2, 2, 2])corr2d_multi_in_out(X, K)# tensor([[[ 56., 72.],# [104., 120.]],# [[ 76., 100.],# [148., 172.]],# [[ 96., 128.],# [192., 224.]]]) 7.4.3 1 × 1 Convolutional Layer1 × 1 Convolutional Layer唯一能夠影像的就是channel這個維度。1 × 1 Convolutional Layer可以視為在每一個單獨的像素位置上的channel的fully conection layer。並且將channel數由$c_i$轉換成$c_o$。7.5 PoolingPooling讓我們可以專注在影像比較大的區域而不會因為影像中細微的變化就影響輸出結果。7.5.1 Maximum Pooling and Average Pooling池化層沒有任何參數，將window所有元素平均為Average Pooling，取出最大值則為Maximum Pooling。7.5.2 Padding and Stride跟conv layer一樣pooling也有padding和Stride，而由於pooling主要目的是從一個區域擷取資訊，所以深度學習框架預設將Stride的大小設定跟pooling window一樣大，不過我們還是可以自行修改大小。7.5.3 Multiple Channels不同於conv layer，pooling對每一個channel是分開處理的，而不像conv layer會把其他channel的結果相加。因此pooling的輸入和輸出channel數目是一樣的。7.6 Convolutional Neural Networks (LeNet)接下來介紹LeNet7.6.1 LeNet下面是LeNet的Pytorch實作，這裡使用了Xavier initializationdef init_cnn(module): #@save \"\"\"Initialize weights for CNNs.\"\"\" if type(module) == nn.Linear or type(module) == nn.Conv2d: nn.init.xavier_uniform_(module.weight)class LeNet(d2l.Classifier): #@save \"\"\"The LeNet-5 model.\"\"\" def __init__(self, lr=0.1, num_classes=10): super().__init__() self.save_hyperparameters() self.net = nn.Sequential( nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(), nn.LazyLinear(120), nn.Sigmoid(), nn.LazyLinear(84), nn.Sigmoid(), nn.LazyLinear(num_classes))7.6.2 Training雖然CNN的參數比較少，但是計算量並不少，用GPU計算更適合。8 Modern Convolutional Neural Networks8.1 Deep Convolutional Neural Networks (AlexNet)硬體運算速度的提升增加了CNN可行性。8.1.1 Representation Learning有一派的研究員相信圖片中的feature是可以讓電腦自己學習得到的。AlexNet在地層layer所學到的kernel跟傳統機器學習手工製作的feature很像。推動CNN兩大因素別是”資料”和”電腦硬體”，過去的資料集都很小而且電腦運算速度很慢。8.1.2 AlenNetAlexNet把sigmoid activation function改成ReLU activtion function。ReLU activation function，讓模型訓練變得更加容易。因為如果初始化的參數很接近0或1，sigmoid activation function的輸出值會很接近0，這使的反向傳播幾乎沒有作用。而ReLU activation function卻不會有這種情形。AlexNet在訓練的時候也大量的利用圖片擴增的技巧，這使得訓練結果不會overfitting。8.1.4 DiscussionAlexNet弱點是他最後的兩個layer佔用了非常大量的記憶體和運算，這對需要高速運算的場景非常不利。另外一個可以注意的點是即使AlexNet的參數量遠大於資料及照片總數，AlexNet也幾乎沒有Overfitting。這是因為有用到現代化的正規化方法如Dropout。8.2 Networks Using Blocks (VGG)神經網絡架構的設計日益抽象化，研究人員從思考個別神經元逐漸轉向整個層面，然後到塊狀結構，即層的重複模式。十年後，這已經進一步發展到研究人員使用完整的訓練模型，將它們重新應用於不同但相關的任務。這種大型 pretrained models通常被稱為foundation models 。這種Blocks的概念最早出現在VGG network，使用迴圈和子程序，可以在任何現代深度學習框架中輕鬆地在代碼中實現這些重複的結構。8.2.1 VGG BlocksCNNs的基本構建塊是以下順序的序列：（i）帶填充的卷積層以保持解析度，（ii）如ReLU之類的非線性激活函數，（iii）如最大池化之類的池化層以減小解析度。這種方法的一個問題是空間解析度下降得相當迅速。特別是，這在所有維度（d）用完之前，對於網絡在卷積層上存在著 $log_2d$的硬限制。例如，在ImageNet的情況下，以這種方式不可能有超過8個卷積層。Simonyan和Zisserman（2014）的關鍵想法是使用連續的小卷層來取代一個大卷積層，例如兩個3x3的卷積層其實涵蓋的像素跟一個5x5一樣大，經過觀察利用連續小的卷積層的效果跟直接用一個大卷積層的效果相似。堆疊3×3的卷積後來成為後來的深度網絡的黃金標準，直到最近由Liu等人（2022）重新審查了這個設計決策。 VGG的構造:一連串的$3 \\times 3$kernel且padding為1的conv layer最後接著一個$2 \\times 2$ stride為2的max-pooling。下面程式實作一個VGG block，以$3 \\times 3$kernel的數量num_convs和輸出channel數量out_channels作為參數。def vgg_block(num_convs, out_channels): layers = [] for _ in range(num_convs): layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1)) layers.append(nn.ReLU()) layers.append(nn.MaxPool2d(kernel_size=2,stride=2)) return nn.Sequential(*layers)8.2.2 VGG NetworkVGG Network可以拆成兩個部分，前半段是多個conv layer和pooling layer組成，後半段是fully connected layer所組成。下面程式定義了VGG network，在這裡我們利用for迴圈將多個VGG block組合成VGG netowrkclass VGG(d2l.Classifier): def __init__(self, arch, lr=0.1, num_classes=10): super().__init__() self.save_hyperparameters() conv_blks = [] for (num_convs, out_channels) in arch: conv_blks.append(vgg_block(num_convs, out_channels)) self.net = nn.Sequential( *conv_blks, nn.Flatten(), nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5), nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5), nn.LazyLinear(num_classes)) self.net.apply(d2l.init_cnn)8.3 Network in Network (NiN)VGG, LeNet, VGG都有一個共通的缺點。 fully connected layer有非常大的參數量。 fully connected layer沒辦法放在模型最後面以外的地方。Network in Network解決了上面兩個問題。他利用了像面兩個方式解決。 利用$1 \\times 1$ conv layer來取代fully connected layer 在模型的最後面使用global average poolingNiN的好處是沒有fully connected layer因此參數量大大減少。 8.3.1 NiN Blocks 由一個conv layer加上兩個$1 \\times 1$ conv layer組成 8.4 Multi-Branch Networks (GoogLeNet)GoogLeNet可以說是第一個將模型拆解成三個部位stem, body, head的模型。8.4.1 Inception BlocksInception Blocks跟前面模型不一樣的是一個block有三個分支8.5 Batch NormalizationBatch Normalization是一個能夠有效加速深度模型收斂的方法，與 residual blocks可以讓模型深度達到一百層。8.5.1 Training Deep NetworksBatch normalization 可以被套用在單一個layer或是所有layer，如此一來對每一層的input都先做一次 normalization(也就是平均為0標準差為1)。注意到如果我們套用batch normalization在minibatches為一的狀況下，我們不會學到任何東西，因為所有的 hidden unit都會變成0。因此使用Batch normalization的時候batch size的大小變成十分重要。Batch normalization中scale parameter 和shift parameter是透過模型學習而得。8.5.2 Batch Normalization LayersCH9 Recurrent Neural Network(RNN)在這之前我們的資料長度都是固定的，在這章將要學習如何讓模型學習長度不固定的序列資料。RNN利用recurrent connection讓模型可以學習序列化的資料，可以把他想成一個迴授迴路9.1 序列化資料在此之前我們的特徵向量長度是固定的，而序列化資料的特徵向量是以時間排序而且長度不固定的資料。" }, { "title": "vscode-C開發環境", "url": "/posts/vscode-C%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83/", "categories": "環境設定與部屬", "tags": "vscode", "date": "2023-07-05 16:50:00 +0800", "snippet": "安裝llvm clang lldb用apt 安裝sudo apt install llvm clangd-12 lldb liblldb-dev安裝vscode套件CodeLLDB、clangd 、CMake 、CMake Tools製作launch.json和task.jsontasks.json可以製作利用cmake來build的工作，範例如下{ \"version\": \"2.0.0\", \"tasks\": [ { \"type\": \"cmake\", \"label\": \"CMake: build\", \"command\": \"build\", \"targets\": [ \"all\" ], \"group\": \"build\", \"problemMatcher\": [], \"detail\": \"CMake template build task\" } ]}而launch.json可以呼叫task.json裡面的工作，只需要在preLaunchTask中指定，範例如下{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"lldb\", \"request\": \"launch\", \"name\": \"Debug\", \"program\": \"${workspaceFolder}/ds61-v2-nvmultiurisrcbin/deepstream-nvmultiurisrcbin\",//指定執行檔的路徑 \"args\": [\"-c\", \"source4_1080p_dec_parallel_infer.yml\"],//執行執行檔的參數，可以為空 \"cwd\": \"${workspaceFolder}/ds61-v2-nvmultiurisrcbin\",//指定工作目錄 \"preLaunchTask\": \"CMake: build\" } ]}codelldb在launch.json可以用的參數如下https://github.com/vadimcn/codelldb/blob/master/MANUAL.md設定settings.json要設定路徑讓clangd讀取cmake產出的compile_commands.json{ \"cmake.sourceDirectory\": \"/home/adlink/deepstream/ds61-v2-nvmultiurisrcbin\", \"cmake.generator\": \"Unix Makefiles\", \"clangd.arguments\": [ \"--compile-commands-dir=${workspaceFolder}/ds61-v2-nvmultiurisrcbin/build\", // 在后台自动分析文件（基于complie_commands) \"--background-index\", // 同时开启的任务数量 \"-j=8\", // \"--folding-ranges\" // 告诉clangd用那个clang进行编译，路径参考which clang++的路径 \"--query-driver=/usr/bin/clang++\", // clang-tidy功能 \"--clang-tidy\", \"--clang-tidy-checks=performance-*,bugprone-*\", // 全局补全（会自动补充头文件） \"--all-scopes-completion\", // 更详细的补全内容 \"--completion-style=detailed\", \"--function-arg-placeholders\", // 补充头文件的形式 \"--header-insertion=iwyu\", // pch优化的位置 \"--pch-storage=memory\", ],}記得要將檔案編譯成debug模式參考文章https://blog.csdn.net/witton/article/details/130944663https://code.visualstudio.com/docs/editor/variables-referencelldb安裝https://blog.csdn.net/witton/article/details/130944663推薦套件Clangd https://clangd.llvm.org/LLDBccls https://github.com/MaskRay/cclsGDBFrontend https://github.com/rohanrhu/gdb-frontendllvm-vs-code-extensions.vscode-clangd: c++ language serverusernamehw.errorlens: inline error messages, very nicetwxs.cmake: cmake coloring, not perfect but better than nothingPKief.material-icon-theme: colors 🤗https://www.reddit.com/r/cpp/comments/wrav6e/what_is_the_best_c_extensions_for_vs_code/" }, { "title": "CMake常用指令", "url": "/posts/cmake%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/", "categories": "環境設定與部屬", "tags": "cmake", "date": "2023-07-05 16:50:00 +0800", "snippet": "CMake文件符號的意思Square Brackets [ ]Angle Brackets &lt; &gt;https://stackoverflow.com/a/23242584/22299707建置cmake -S . -B buildcmake --build build -j 8Linux下用pkg_check_modules尋找套件cmake_minimum_required(VERSION 3.15)project(fy-version)set(CMAKE_C_STANDARD 11)find_package (PkgConfig REQUIRED)pkg_check_modules(FYAML IMPORTED_TARGET libfyaml)if (FYAML_FOUND) include_directories(${FYAML_INCLUDE_DIRS}) link_directories(${FYAML_LIBRARY_DIRS}) list(APPEND LINK_LIB_LIST ${FYAML_LIBRARIES}) message(STATUS \"found library:${FYAML_LIBRARIES}\")endif ()# 建立執行檔add_executable(fy-version yaml_reader.c)target_link_libraries(${PROJECT_NAME} PkgConfig::FYAML)https://cmake.org/cmake/help/latest/module/FindPkgConfig.htmlhttps://stackoverflow.com/questions/42634710/how-to-use-pkg-config-in-cmake-jucihttps://blog.csdn.net/zhizhengguan/article/details/111826697Debug模式編譯set(CMAKE_BUILD_TYPE Debug)引用CUDADeclare\tCUDA as\ta LANGUAGE in your projectproject(GTC LANGUAGES CUDA CXX) 連接library利用FindCUDAToolkit(cmake版本&gt;3.17) find_package(CUDAToolkit)add_executable( binary_linking_to_cudart my_cpp_file_using_cudart.cpp)target_link_libraries(binary_linking_to_cudart PRIVATE CUDA::cudart) 利用FindCUDAToolkit https://cliutils.gitlab.io/modern-cmake/chapters/packages/CUDA.htmlhttps://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9444-build-systems-exploring-modern-cmake-cuda-v2.pdfcmake 加入編譯好的.o檔SET(OBJS ${CMAKE_CURRENT_SOURCE_DIR}/libs/obj.o)ADD_EXECUTABLE(myProgram ${OBJS} &lt;other-sources&gt;)SET_SOURCE_FILES_PROPERTIES( ${OBJS} PROPERTIES EXTERNAL_OBJECT true GENERATED true)https://stackoverflow.com/a/38610428編譯不是cmake的專案或函式庫ExternalProject_Add(Qt DOWNLOAD_DIR ${CMAKE_CURRENT_BINARY_DIR} URL ${qt_file} UPDATE_COMMAND \"\" SOURCE_DIR ${qt_source} BUILD_IN_SOURCE 1 CONFIGURE_COMMAND ${qt_configure} BUILD_COMMAND ${qt_build} INSTALL_COMMAND \"${qt_install}\" )https://stackoverflow.com/a/3493578/22299707編譯專案外的makefile專案資料夾以下指令可以在外部資料夾下make指令include(ExternalProject)ExternalProject_Add(deepstreamapp SOURCE_DIR ${DEEPSTREAMAPP}/sample_apps/deepstream-app # This is not likely to be CMAKE_CURRENT_LIST_DIR CONFIGURE_COMMAND \"\" INSTALL_COMMAND \"\" DOWNLOAD_COMMAND \"\" BUILD_COMMAND make BUILD_IN_SOURCE true)接下來可以用以下指令找出所有編譯好的.o檔並且加到專案內file(GLOB_RECURSE DEEPSTREAMAPPCONFIGPARSER \"/opt/nvidia/deepstream/deepstream/sources/apps/apps-common/src/deepstream-yaml/*.o\")SET(OBJS ${DEEPSTREAMAPPCONFIGPARSER}) SET_SOURCE_FILES_PROPERTIES( ${OBJS} PROPERTIES EXTERNAL_OBJECT true GENERATED true)add_executable(${PROJECT_NAME} ${OBJS} main.cpp)參考:https://discourse.cmake.org/t/external-project-using-makefile/2692/5增加函式庫https://cmake.org/cmake/help/latest/guide/tutorial/Adding%20a%20Library.html#step-2-adding-a-librarytarget_include_directories() 和 target_link_libraries()" }, { "title": "git刪除歷史中的大檔案", "url": "/posts/git%E5%88%AA%E9%99%A4%E6%AD%B7%E5%8F%B2%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%AA%94%E6%A1%88/", "categories": "開發工具", "tags": "git", "date": "2023-06-30 12:28:00 +0800", "snippet": "列出歷史中的大檔案git rev-list --objects --all | git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' | sed -n 's/^blob //p' | sort --numeric-sort --key=2 | cut -c 1-12,41- | $(command -v gnumfmt || echo numfmt) --field=2 --to=iec-i --suffix=B --padding=7 --round=nearesthttps://stackoverflow.com/questions/10622179/how-to-find-identify-large-commits-in-git-history刪除大檔案https://stackoverflow.com/questions/2100907/how-to-remove-delete-a-large-file-from-commit-history-in-the-git-repositoryhttps://rtyley.github.io/bfg-repo-cleaner/遇到protect branch--no-blob-protectionhttps://stackoverflow.com/a/47421624遇到 [remote rejected] 錯誤https://stackoverflow.com/a/74373146" }, { "title": "演算法讀書筆記", "url": "/posts/%E6%BC%94%E7%AE%97%E6%B3%95/", "categories": "攝影機設定", "tags": "peopleflow", "date": "2023-06-26 12:28:00 +0800", "snippet": "CH1MergeSort: divide-and-conquer經典範例輸入: 一個沒有規則的數字陣列。輸出: 排序好的數字陣列MergeSort是divide-and-conquer方法的展現。recursive divide-and-conquer algorithm是不斷的利用遞迴把問題拆變小，直到問題不能在拆分後再把結果合併回來。對於array把問題變小的方式最直覺就是把array拆兩半，拆到最後再慢慢把array合併回來。下面是MergeSort的PseudocodeInput: array A of n distinct integers.Output: array with the same integers, sorted fromsmallest to largest.// ignoring base casesC := recursively sort ﬁrst half of AD := recursively sort second half of Areturn Merge (C,D)這段程式碼有幾點可以注意 base cases: 也就是沒辦法再分割，沒辦法再繼續遞迴，返回它自身就是他的回傳值。 Pseudocode不包含實作細節，例如如果輸入是奇數個元素的狀況下，我們可以將多出的一個element放入一半被拆分的array。Pseudocode只記錄概念上的運作方式，並不會加入任何和個別程式語言有關的實作細節。在上面的Pseudocode還有一個Merge函式，下面是關於Merge函式的Pseudocode。想法是將排序好的C和D array依序再排序成新的排序過的array。MergeInput: sorted arrays C and D (length n/2 each).Output: sorted array B (length n).Simplifying assumption: n is even.1 i := 12 j := 13 for k := 1 to n do4 if C[i] &lt; D[j] then5 B[k] := C[i] // populate output array6 i := i + 1 // increment i7 else // D[j] &lt; C[i]8 B[k] := D[j]9 j := j + 11.5 MergeSort: The Analysis計算演算法速度的方式就是計算這個演算法總共需要執行多少次最基礎的計算。也就是計算Running Time1.5.1 Running Time of MergeLemma 1.1 (Running Time of Merge) 對於合併兩個長度為$l/2$的array的，合併最多只會用到6l步(可從前面Merge的Pseudocode推論。)1.5.2 Running Time of MergeSortTheorem 1.2 (Running Time of MergeSort) : 對於每個長度$n\\geq 1$的array， MergeSort的Merge步驟最多執行$6nlog_2n+6n$個步驟1.5.3 Proof of Theorem 1.2從recursion tree 可以看到，每多一個遞迴level，工作被分割的總數就是兩倍，但是工作的array長度是上一個level的一半。因此level-j的subproblems為$2^j$，而level-j地array長度為$n/{2^j}$。根據上一節的結論，對於每個長度$n\\geq 1$的array， MergeSort最多執行$6nlog_2n+6n$個步驟。如果我們只看level-j遞迴呼叫以外的工作，就只剩下Merge步驟，因此每個level的運算步驟總共為$6n/2^j$於是我們可以得到level-j所有的運算步驟總數為$2^j \\cdot \\frac{6n}{2^j}=6n$而MergeSort總共會有$log_x^n+1$個level，因此整個MergeSort總共的步驟為$6nlog_2n+6n$1.6 Guiding Principles for the Analysis of Algorithms我們在計算演算法速度的時候會有三個原則，以下逐一介紹。因為在有些時候為了簡化計算，我們會做出一些取設，但是為了讓數學分析依然能夠預測演算法的速度，因此我們才用到下面三個原則。Principle #1: Worst-Case Analysis在前面推導的結果$6nlog_2n+6n$是不管n是什麼數字這個公式都能夠使用。也就是我們沒有對n做任何的假設。這種分析法稱為Worst-Case Analysis，因為這個演算法最慢的計算時間依然符合這個公式。除了Worst-Case Analysis之外還有average-case analysis和 analysis of benchmark instances可以使用，但是這兩個使用的時候必須非常清楚所處理的問題的條件。Principle #2: Big-Picture Analysis在運行時間界限中，我們不應過於關注小的常數因子或低階項。參考Algorithms Illuminated" }, { "title": "計算攝影機所需的頻寬", "url": "/posts/%E8%A8%88%E7%AE%97%E6%94%9D%E5%BD%B1%E6%A9%9F%E6%89%80%E9%9C%80%E7%9A%84%E9%A0%BB%E5%AF%AC/", "categories": "攝影機設定", "tags": "peopleflow", "date": "2023-06-18 12:28:00 +0800", "snippet": "頻寬計算公式https://www.mistralsolutions.com/articles/video-surveillance-bandwidth-requirements-calculation-utilization/" }, { "title": "git忽略已經追蹤的檔案", "url": "/posts/git%E5%BF%BD%E7%95%A5%E5%B7%B2%E7%B6%93%E8%BF%BD%E8%B9%A4%E7%9A%84%E6%AA%94%E6%A1%88-copy/", "categories": "開發工具", "tags": "git", "date": "2023-06-17 12:28:00 +0800", "snippet": "git update-index –assume-unchangedhttps://blog.hsdn.net/1624.htmlgit rmhttps://stackoverflow.com/a/2047477" }, { "title": "Windows下使用tracetcp", "url": "/posts/Windows%E4%B8%8B%E4%BD%BF%E7%94%A8tracetcp/", "categories": "網路工具", "tags": "tool", "date": "2023-06-16 12:28:00 +0800", "snippet": "1.安裝wincap2.安裝tracetcphttps://github.com/0xcafed00d/tracetcphttps://blog.csdn.net/sj349781478/article/details/116704310" }, { "title": "deepstream-tracker參數調整", "url": "/posts/deepstream-tracker%E5%8F%83%E6%95%B8%E8%AA%BF%E6%95%B4/", "categories": "深度學習工具", "tags": "deepstream", "date": "2023-06-15 12:28:00 +0800", "snippet": "Accuracy-Performance Tradeoffs下面這些參數的調整將會影響到準確度和效能。Visual Feature Types and Feature SizesVisual feature types useColorNames useHogFeature sizes featureImgSizeLevel searchRegionPaddingScale" }, { "title": "Linux下的Docker更改image儲存位置", "url": "/posts/Linux%E4%B8%8B%E7%9A%84Docker%E6%9B%B4%E6%94%B9image%E5%84%B2%E5%AD%98%E4%BD%8D%E7%BD%AE/", "categories": "", "tags": "", "date": "2023-06-14 10:54:00 +0800", "snippet": "官方方法修改/etc/docker/daemon.json加入下面設定{ \"data-root\": \"/mnt/docker-data\"}重新啟動docker servicesudo systemctl stop docker.servicesudo systemctl start docker.service確認路徑已經修改docker info | grep \"Docker Root Dir\"https://docs.docker.com/config/daemon/#daemon-data-directory步驟參考(Docker更新後原本設定的位置會被改回去，不推薦)https://linuxconfig.org/how-to-move-docker-s-default-var-lib-docker-to-another-directory-on-ubuntu-debian-linux" }, { "title": "Linux使用SOCKS5-proxy上網", "url": "/posts/Linux%E4%BD%BF%E7%94%A8SOCKS5-proxy%E4%B8%8A%E7%B6%B2/", "categories": "", "tags": "", "date": "2023-06-09 10:54:00 +0800", "snippet": "簡介這裡將介紹一個只需要使用SSH連線到一台可以連到對網網路的主機，就可以讓防火牆內的主機上網的方法圖片說明利用ssh連接到可以上網的機器ssh -D 4444 -q -C -N user@ma.ttias.be檢查SOCKS是否開通了https://superuser.com/questions/303251/how-to-check-if-a-socks5-proxy-works以下指令可以檢查開通的portnetstat -tlnp假設我們在4444port開SOCKS proxy，如果有成功開啟SOCKS proxy，應該會看到下面這行tcp 0 0 127.0.0.1:4444 0.0.0.0:* LISTEN 安裝Proxychains4https://blog.csdn.net/leishupei/article/details/120736869sudo apt-get install proxychains4設定Proxychains4https://feifei.tw/proxychains4/sudo nano /usr/local/etc/proxychains.conf設定檔位置https://askubuntu.com/a/1477936proxy_dns 的功能不要關掉手動設定DNS serverexport DNS_SERVER=8.8.8.8https://github.com/rofl0r/proxychains-ng/issues/178#issuecomment-347439800測試apt指令proxychains4 sudo apt install zipdocker pull 無法使用proxychains4的解法sudo nano /etc/systemd/system/docker.service.d/proxy.conf[Service]Environment=\"HTTP_PROXY=socks5://127.0.0.1:9050\"Environment=\"HTTPS_PROXY=socks5://127.0.0.1:9050\"sudo systemctl daemon-reloadsudo systemctl restart dockerhttps://markvanlent.dev/2022/05/10/pulling-docker-images-via-a-socks5-proxy/" }, { "title": "TAO設定和訓練", "url": "/posts/TAO%E8%A8%AD%E5%AE%9A%E5%92%8C%E8%A8%93%E7%B7%B4/", "categories": "TAO", "tags": "tao", "date": "2023-05-31 17:28:00 +0800", "snippet": "安裝和設定https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_quick_start_guide.html#run-sample-jupyter-notebooksJupyter notebook改成暗色系pip install jupyterthemesjt -t monokai -f fira -fs 10 -nf ptsans -nfs 11 -N -kl -cursw 2 -cursc r -cellw 95% -T重新啟動jupyter notebookhttps://www.kaggle.com/getting-started/97540#983780" }, { "title": "elasticsearch API", "url": "/posts/elasticsearch-API/", "categories": "ELK", "tags": "elk", "date": "2023-05-24 17:28:00 +0800", "snippet": "search使用keyword使得搜尋條件必須完全符合GET people-2023.04/_search{ \"query\": { \"bool\": { \"must\": [ { \"range\": { \"@timestamp\": { \"gt\" : \"2023-04-08T10:22:28Z\", \"lt\" : \"2023-04-08T10:22:44Z\" } } }, { \"match\": { \"StreamID.keyword\": \"eb2baea2-d52c-434c-af44-256c0301f4df\" } } ] } } }deletePOST poc/_delete_by_query{ \"query\":{ \"range\":{ \"@timestamp\":{ \"gt\" : \"2018-05-04T23:04:00Z\" } } }}" }, { "title": "樹梅派學習Liunx", "url": "/posts/%E6%A8%B9%E6%A2%85%E6%B4%BE%E5%AD%B8%E7%BF%92Liunx/", "categories": "樹梅派", "tags": "樹梅派", "date": "2023-05-11 17:28:00 +0800", "snippet": "CH1 樹梅派不適合做real-time的應用 樹梅派不適合作為production的應用，如果要做成production的應用，可以考慮BeagleBone 其他參考資源: www.elinux.org www.exploringrpi.com www.derekmolloy.ie 建議購買的配件 USB to Serial UART TTL 3.3 V (for Finding Problems)線，可以用於透過USB就可以使用command line控制樹梅派 " }, { "title": "設定watchdog", "url": "/posts/Jetson%E8%A8%AD%E5%AE%9Awatchdog/", "categories": "Jetson", "tags": "環境設定與部屬", "date": "2023-05-09 17:28:00 +0800", "snippet": "測試watchdogL4T已經預設有watchdog，可以透過下面指令測試，他預設的機制是如果有人讀取/dev/watchdog這個檔案，他就會開始倒數計時，如果有人寫入檔案，則timer重置，下面指令將會讓watchgod重啟系統。sudo tail -f /dev/watchdog如果要避免重啟就必須寫入/dev/watchdog檔。或是結束tail -fhttps://forums.developer.nvidia.com/t/configuring-watchdog-timer-on-tx1/44361/2?u=jenhao參考:官方文件下載區https://developer.nvidia.com/embedded/downloads" }, { "title": "logstash設定教學", "url": "/posts/logstash%E8%A8%AD%E5%AE%9A%E6%95%99%E5%AD%B8/", "categories": "ELK", "tags": "環境設定與部屬", "date": "2023-05-09 17:28:00 +0800", "snippet": "設定檔編寫logstash基本元素input, filter, 和 output，每個元素可能一個或多個建立一個基本的pipeline下面建立一個基本的pipeline，從stdin讀取資料，然後輸出到stdout。我們將建立一個first-pipeline.conf並且放在C:\\ELK\\logstash-7.17.3\\logstash-7.17.3(與bin同一個資料夾)# The # character at the beginning of a line indicates a comment. Use# comments to describe your configuration.input {stdin { }}# The filter part of this file is commented out to indicate that it is# optional.# filter {## }output {stdout {}}檢查pipeline語法打開powershell，利用以下指令檢查pipeline語法，注意要確認沒有任何錯誤，因為檢查程式如果找不到檔案位置最後也會顯示檢查OK。我們在C:\\ELK\\logstash-7.17.3\\logstash-7.17.3輸入以下指令bin/logstash -f first-pipeline1.conf --config.test_and_exit輸出如下Using LS_JAVA_HOME defined java: C:\\ELK\\logstash-7.17.3\\logstash-7.17.3\\jdk\\WARNING: Using LS_JAVA_HOME while Logstash distribution comes with a bundled JDK.OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.Sending Logstash logs to C:/ELK/logstash-7.17.3/logstash-7.17.3/logs which is now configured via log4j2.properties[2023-05-05T14:24:31,585][INFO ][logstash.runner ] Log4j configuration path used is: C:\\ELK\\logstash-7.17.3\\logstash-7.17.3\\config\\log4j2.properties[2023-05-05T14:24:31,601][INFO ][logstash.runner ] Starting Logstash {\"logstash.version\"=&gt;\"7.17.3\", \"jruby.version\"=&gt;\"jruby 9.2.20.1 (2.5.8) 2021-11-30 2a2962fbd1 OpenJDK 64-Bit Server VM 11.0.14.1+1 on 11.0.14.1+1 +indy +jit [mswin32-x86_64]\"}[2023-05-05T14:24:31,601][INFO ][logstash.runner ] JVM bootstrap flags: [-Xms1g, -Xmx2g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djruby.compile.invokedynamic=true, -Djruby.jit.threshold=0, -Djruby.regexp.interruptible=true, -XX:+HeapDumpOnOutOfMemoryError, -Djava.security.egd=file:/dev/urandom, -Dlog4j2.isThreadContextMapInheritable=true][2023-05-05T14:24:31,761][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified[2023-05-05T14:24:32,816][INFO ][org.reflections.Reflections] Reflections took 78 ms to scan 1 urls, producing 119 keys and 419 valuesConfiguration OK[2023-05-05T14:24:33,781][INFO ][logstash.runner ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash自動重載設定檔檢查通過後我們用--config.reload.automatic選項重新載入設定檔，如此一來就不用一直重啟程式。在過程中你可能會看到忽略pipelines.yml的警告，因為我們已經在命令中明確指定要用的設定檔了，所以可以忽略這個警告，之後我們再學習使用pipelines.ymlbin/logstash -f first-pipeline.conf --config.reload.automatic等到看到[main] Pipeline started {\"pipeline.id\"=&gt;\"main\"}這個訊息後，我們可以直接輸入一些文字，按下enter，就可以看到輸入的文字被輸出到stdout了。例如入Hello wordl後按下Enter，結果如下Hello World{ \"@version\" =&gt; \"1\", \"host\" =&gt; \"eastcoastVM01\", \"message\" =&gt; \"Hello World\\r\", \"@timestamp\" =&gt; 2023-05-05T06:32:33.396Z}使用 Grok Filter 外掛程式(Plugin)Grok是眾多logstash外掛程式的其中一個，這裡可以看到更多關於logstash的外掛程式。grok filter plugin可以幫我們將沒有結構化的log轉化成結構化的log多個資料來源以下範例是多個資料來源，分別來自twitter和firebeat，輸出也有多個，分別為elasticsearch和寫到檔案input { twitter { consumer_key =&gt; \"enter_your_consumer_key_here\" consumer_secret =&gt; \"enter_your_secret_here\" keywords =&gt; [\"cloud\"] oauth_token =&gt; \"enter_your_access_token_here\" oauth_token_secret =&gt; \"enter_your_access_token_secret_here\" } beats { port =&gt; \"5044\" }}output { elasticsearch { hosts =&gt; [\"IP Address 1:port1\", \"IP Address 2:port2\", \"IP Address 3\"] } file { path =&gt; \"/path/to/target/file\" }}建立一個接收rabbitmq訊號的範例解析rabbitmq訊號在input中我們可以加入input plugin，這裡我們使用rabbitmq plugin，先建立一個最簡單的範例並且將解析結果輸出到console。在rabbitmq plugin中的說明文件有提到，預設的輸出是json codec而設定rabbitmq的參數在這裡，我們會需要設定rabbitmq的連線資訊，範例如下。# The # character at the beginning of a line indicates a comment. Use# comments to describe your configuration.input { rabbitmq { host =&gt; \"localhost\" port =&gt; 5672 username =&gt; guest password =&gt; guest }}# The filter part of this file is commented out to indicate that it is# optional.# filter {## }output {stdout {}}抽取事件中的欄位有時候我們會需要依據事件中欄位的資料做一些處理，Field Reference可以幫助我們抽取事件中的欄位。以下事件為範例，如果要取得第一階的欄位如agent, ip, request, response, ua，只需要一個[]就可以取得例如[request]，如果是第二階欄位如os則要用[ua][os]{ \"agent\": \"Mozilla/5.0 (compatible; MSIE 9.0)\", \"ip\": \"192.168.24.44\", \"request\": \"/index.html\" \"response\": { \"status\": 200, \"bytes\": 52353 }, \"ua\": { \"os\": \"Windows 7\" }}對欄位操作Mutate filter pluginhttps://www.elastic.co/guide/en/logstash/7.17/plugins-filters-mutate.html#plugins-filters-mutate-replace檢查子欄位是否存在https://github.com/elastic/logstash/issues/10215#issuecomment-447912618加入一個filed，其值是一個sub fieldhttps://stackoverflow.com/a/39126309" }, { "title": "Ubuntu-cli-網路狀態檢查", "url": "/posts/Ubuntu-cli-%E7%B6%B2%E8%B7%AF%E7%8B%80%E6%85%8B%E6%AA%A2%E6%9F%A5/", "categories": "網路除錯", "tags": "network", "date": "2023-05-03 17:28:00 +0800", "snippet": "下載tracetcphttps://github.com/0xcafed00d/tracetcp檢查遠端伺服器有沒有開portnc -z -v -w5 &lt;host&gt; &lt;port&gt;https://stackoverflow.com/a/9463554" }, { "title": "ld找不到動態函式庫的除錯方法", "url": "/posts/ld%E6%89%BE%E4%B8%8D%E5%88%B0%E5%8B%95%E6%85%8B%E5%87%BD%E5%BC%8F%E5%BA%AB%E7%9A%84%E9%99%A4%E9%8C%AF%E6%96%B9%E6%B3%95/", "categories": "環境設定與部屬", "tags": "linux", "date": "2023-05-03 17:28:00 +0800", "snippet": "注意是否有從C++ 呼叫C語言的函式，如果有必須要使用extern Chttps://hackmd.io/@rhythm/HyOxzDkmDhttps://www.airs.com/blog/archives/38https://www.google.com/search?q=Linkers+part+site%3Ahttps%3A%2F%2Fwww.airs.com%2F&amp;rlz=1C1GCEU_zh-TWTW902TW902&amp;oq=Linkers+part+site%3Ahttps%3A%2F%2Fwww.airs.com%2F&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM1ODlqMGo3qAIAsAIA&amp;sourceid=chrome&amp;ie=UTF-8#ip=1注意function是否為static functionc語言中的static function在function被定義的檔案以外的scope是看不到的undefined reference to表示必要的函式庫或是.o檔沒有被連接 用nm指令確認函式確實存在.so檔裡面例如:nm -D libnvds_utils.so --defined-only的輸出如下，這個指令只會列出有對外開放的函式 0000000000001470 T nvds_dependencies_version_print00000000000018d0 T nvds_mask_utils_resize_to_binary_argb3200000000000013f0 T nvds_version0000000000001410 T nvds_version_print0000000000001310 T _Z18libnvds_utils_initv0000000000001300 T _Z20libnvds_utils_deinitv https://stackoverflow.com/a/4514781 nm不只可以用在函式庫檔，.o檔也可以用nm deepstream_source_bin.o --defined-only 0000000000000000 b install_mux_eosmonitor_probe0000000000000010 b last_reset_time_global.314910000000000000008 b mutex.3146000000000000030a8 t nvstreammux_eosmonitor_probe_func0000000000006ab0 T reset_encodebin00000000000065e8 T reset_source_pipeline000000000000133c t restart_stream_buf_prob0000000000002ffc t rtspsrc_monitor_probe_func0000000000001270 t seek_decode0000000000000020 t set_camera_csi_params00000000000000bc t set_camera_v4l2_params0000000000006a04 T set_source_to_playing0000000000002178 t smart_record_callback0000000000002270 t smart_record_event_generator0000000000002e74 t watch_source_async_state_change00000000000026d0 t watch_source_status... /usr/bin/ld: cannot find …編譯過程中發現ld找不到某個函式庫例如/usr/bin/ld: cannot find -ljpeg，可以利用指令ld &lt;函式庫&gt; --verbose可以查看ld找了那些路徑，例如目前ld找不到-ljpeg可以利用ld -ljpeg --verbose，輸出如下ld: mode aarch64linuxattempt to open /usr/local/lib/aarch64-linux-gnu/libjpeg.so failedattempt to open /usr/local/lib/aarch64-linux-gnu/libjpeg.a failedattempt to open /lib/aarch64-linux-gnu/libjpeg.so failedattempt to open /lib/aarch64-linux-gnu/libjpeg.a failedattempt to open /usr/lib/aarch64-linux-gnu/libjpeg.so failedattempt to open /usr/lib/aarch64-linux-gnu/libjpeg.a failedattempt to open /usr/local/lib/libjpeg.so failedattempt to open /usr/local/lib/libjpeg.a failedattempt to open /lib/libjpeg.so failedattempt to open /lib/libjpeg.a failedattempt to open /usr/lib/libjpeg.so failedattempt to open /usr/lib/libjpeg.a failedattempt to open /usr/aarch64-linux-gnu/lib/libjpeg.so failedattempt to open /usr/aarch64-linux-gnu/lib/libjpeg.a failedld: cannot find -ljpeg注意makefile的擺放順序連接器指令放最後面例如gcc -I/usr/local/include -o yaml_reader yaml_reader.c -L/usr/local/lib -lfyamlhttps://stackoverflow.com/questions/22426574/gcc-undefined-reference-tohttps://stackoverflow.com/questions/16710047/usr-bin-ld-cannot-find-lnameofthelibrary注意cmake是否有把程式加入編譯add_executable(…)內加入的cpp檔會被編譯，確認是否有將程式加入" }, { "title": "Deepstream辨識結果遠端觀看", "url": "/posts/Deepstream%E8%BE%A8%E8%AD%98%E7%B5%90%E6%9E%9C%E9%81%A0%E7%AB%AF%E8%A7%80%E7%9C%8B-server/", "categories": "伺服器管理", "tags": "ubuntu", "date": "2023-04-28 17:28:00 +0800", "snippet": "RTSP遠端觀看設定可以參考這篇特別注意如果Deepstream不是在Jetson上面跑記得要換成下面指令啟動server，因為dGPU的Deepstream沒有nvvidconv原件!!./test-launch \"videotestsrc is-live=1 ! videoconvert ! x264enc ! h264parse ! rtph264pay name=pay0 pt=96\"整合到自己的程式裡sources\\apps\\apps-common\\src\\deepstream_sink_bin.c有詳細的整合方式。https://github.com/aler9/mediamtx#installation" }, { "title": "樹梅派列印機和掃描器伺服器", "url": "/posts/%E6%A8%B9%E6%A2%85%E6%B4%BE%E5%88%97%E5%8D%B0%E6%A9%9F%E5%92%8C%E6%8E%83%E6%8F%8F%E5%99%A8%E4%BC%BA%E6%9C%8D%E5%99%A8/", "categories": "伺服器管理", "tags": "ubuntu", "date": "2023-04-28 17:28:00 +0800", "snippet": " 樹梅派作業系統 CUPS和SANEhttps://wiki.archlinux.org/title/CUPS L3110-主要依照這篇https://antivirus.com/2021/05/26/raspberry-pi-project-how-to-convert-a-usb-all-in-one-printer-to-a-wireless-printer/ 加使用者看這一篇–Add Printer foribbiden排除https://unix.stackexchange.com/questions/235477/cups-add-printer-page-returns-forbidden-on-web-interface 印不出來除錯 tail -n 100 -f /var/log/cups/error_log https://wiki.archlinux.org/title/CUPS/Troubleshooting 安裝 printer-driver-escpr、hplip列印的時候出現以下錯誤，而且job一直是stopped File \\\"/usr/lib/cups/filter/epson-escpr-wrapper\\\" not available: No such file or directory 下面方法解決問題並且成功列印測試頁。sudo apt install printer-driver-escpr #安裝後解決sudo apt install hplip #下次測試不安裝可不可以順利運作(epson)https://forums.raspberrypi.com/viewtopic.php?t=225739local列印成功後，設定網路 開啟網路管理服務以及nmtui systemctl start NetworkManagersudo nmtui 不要設定AllowUser以免權限不足如果發現錯誤，請在網頁AllowUser留白並且儲存Returning IPP client-error-not-authorized for Create-Job (ipps://192.168.50.169:631/printers/epson_l3110_series) from 192.168.50.9.https://askubuntu.com/a/708217掃描器使用SANE:Setting up a Raspberry Pi Scanner Server using SANE安裝必要軟體後，檢查SANE能不能找到你的掃描器，如果不行就必須手動設定，方法如官網Helpful commands for Troubleshooting sane網頁板掃描頁面https://github.com/sbs20/scanservjs/tree/master安裝後出現以下說明Created symlink /etc/systemd/system/multi-user.target.wants/scanservjs.service → /etc/systemd/system/scanservjs.service.scanservjs installed and running http://127.0.0.1:8080If you encounter problems when running, try sudo journalctl -e -u scanservjs桌面版軟體安裝後在windows上面安裝前端軟體SaneTwain其他參考:https://ubuntu.com/server/docs/service-cupsairprinthttps://www.developer.com/mobile/cups-and-raspberry-pi-airprinting/https://unix.stackexchange.com/questions/394687/printer-drivers-required-if-cups-is-installed" }, { "title": "Nomachine無法控制Ubuntu Server解法", "url": "/posts/Nomachine%E7%84%A1%E6%B3%95%E6%8E%A7%E5%88%B6Ubuntu-Server%E8%A7%A3%E6%B3%95/", "categories": "環境設定與部屬", "tags": "ubuntu", "date": "2023-04-28 17:28:00 +0800", "snippet": " 無螢幕的Server(Headless server)有三種方法 設定x server接受headless狀態 插上一個假的HDMI dongle 讓Nomachine建立虛擬螢幕對server下指令關閉display-manager並且重啟Nomachine服務 sudo systemctl stop display-managersudo /etc/NX/nxserver --restart 參考:https://forum.nomachine.com/topic/problems-connecting-with-nomachine-in-pc-client-without-monitor" }, { "title": "Linux實用TUI", "url": "/posts/Linux%E5%AF%A6%E7%94%A8TUI/", "categories": "伺服器管理", "tags": "ubuntu", "date": "2023-04-28 17:28:00 +0800", "snippet": " NetworkManager TUI，nmtui設定網路ip安裝 sudo apt updatesudo apt install network-manager -y 參考:https://ithelp.ithome.com.tw/m/articles/10267179 資料夾空間查詢TUI ncdu sudo apt install ncduhttps://ephrain.net/mac-%E5%9C%A8%E7%B5%82%E7%AB%AF%E6%A9%9F%E4%B8%AD%E4%BD%BF%E7%94%A8-ncdu%EF%BC%8C%E6%AA%A2%E8%A6%96%E7%A1%AC%E7%A2%9F%E7%A9%BA%E9%96%93%E5%A4%A7%E5%B0%8F/https://github.com/rofl0r/ncdu dua-clihttps://github.com/Byron/dua-cli?tab=readme-ov-file duc https://duc.zevv.nl/" }, { "title": "Jetson設定", "url": "/posts/Jetson%E8%A8%AD%E5%AE%9A/", "categories": "環境設定與部屬", "tags": "ubuntu", "date": "2023-04-28 17:28:00 +0800", "snippet": " 遠端桌面Nomachine 硬體狀態jtop sudo apt updatesudo apt install python3-pipsudo pip3 install -U jetson-stats 關閉GUI節省GPU資源 暫時關閉以及打開方法 sudo init 3 #暫時關閉 sudo init 5 #打開 重啟後不再打開GUI sudo systemctl set-default multi-user.target #關閉 sudo systemctl set-default multi-user.target #打開參考:https://forum.nomachine.com/topic/problems-connecting-with-nomachine-in-pc-client-without-monitor" }, { "title": "Ubuntu安裝CUDA cuDNN TeosorRT", "url": "/posts/Ubuntu%E5%AE%89%E8%A3%9DCUDA-cuDNN-TeosorRT/", "categories": "環境設定與部屬", "tags": "ubuntu", "date": "2023-04-27 17:28:00 +0800", "snippet": " 安裝CUDA將CUDA的repo加入apt wget https://developer.download.nvidia.com/compute/cuda/11.7.1/local_installers/cuda-repo-debian11-11-7-local_11.7.1-515.65.01-1_amd64.debsudo dpkg -i cuda-repo-debian11-11-7-local_11.7.1-515.65.01-1_amd64.debsudo rm /etc/apt/sources.list.d/*cuda*sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pubsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\"sudo apt-get update 接下來注意不要直接sudo apt-get -y install cuda，因為可能會直接安裝最新版的CUDA，而不是你指定的版本首先確認有哪些版本可以下載apt-cache policy vlc輸出如下cuda: Installed: (none) Candidate: 12.1.1-1 Version table: 12.1.1-1 500 500 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 Packages 12.1.0-1 500 500 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 Packages 12.0.1-1 500 500 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 Packages 12.0.0-1 500 500 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 Packages 11.8.0-1 500 500 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 Packages 11.7.1-1 500 500 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 Packages 11.7.0-1 500 500 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 Packages......在這裡我們想安裝CUDA 11.7.1，指令如下sudo apt-get install cuda=11.7.1-1再次確認即將安裝的是不是CUDA11.7，是的話再按y 安裝cuDNN和TensorRT sudo apt-get install libnvinfer8=8.4.1-1+cuda11.6 libnvinfer-plugin8=8.4.1-1+cuda11.6 libnvparsers8=8.4.1-1+cuda11.6 \\ libnvonnxparsers8=8.4.1-1+cuda11.6 libnvinfer-bin=8.4.1-1+cuda11.6 libnvinfer-dev=8.4.1-1+cuda11.6 \\ libnvinfer-plugin-dev=8.4.1-1+cuda11.6 libnvparsers-dev=8.4.1-1+cuda11.6 libnvonnxparsers-dev=8.4.1-1+cuda11.6 \\ libnvinfer-samples=8.4.1-1+cuda11.6 libcudnn8=8.4.1.50-1+cuda11.6 libcudnn8-dev=8.4.1.50-1+cuda11.6 \\ python3-libnvinfer=8.4.1-1+cuda11.6 python3-libnvinfer-dev=8.4.1-1+cuda11.6 參考:https://docs.nvidia.com/metropolis/deepstream/6.1.1/dev-guide/text/DS_Quickstart.html#https://askubuntu.com/questions/340530/how-can-i-check-the-available-version-of-a-package-in-the-repositories" }, { "title": "Ubuntu設定自動化安全性更新", "url": "/posts/Ubuntu%E8%A8%AD%E5%AE%9A%E8%87%AA%E5%8B%95%E5%8C%96%E5%AE%89%E5%85%A8%E6%80%A7%E6%9B%B4%E6%96%B0/", "categories": "伺服器管理", "tags": "ubuntu", "date": "2023-04-26 17:28:00 +0800", "snippet": " install sudo apt install unattended-upgrades Verify systemctl status unattended-upgrades config sudo nano /etc/apt/apt.conf.d/50unattended-upgrades Blacklist Unattended-Upgrade::Package-Blacklist Email NotificationsUnattended-Upgrade::Mail example@email.com;Unattended-Upgrade::MailOnlyOnError “true”; Enable Automatic Upgrades sudo nano /etc/apt/apt.conf.d/20auto-upgrades Testing Automatic Upgrades sudo unattended-upgrades --dry-run --debug check log /var/log/unattended-upgrades/unattended-upgrades.log 參考:https://phoenixnap.com/kb/automatic-security-updates-ubuntu" }, { "title": "Windows使用SOCKS5-proxy上網", "url": "/posts/%E4%BD%BF%E7%94%A8SOCKS5-proxy%E4%B8%8A%E7%B6%B2/", "categories": "", "tags": "", "date": "2023-04-19 10:54:00 +0800", "snippet": "簡介這裡將介紹一個只需要使用SSH連線到一台可以連到對網網路的主機，就可以讓防火牆內的主機上網的方法圖片說明設定puttyhttps://www.simplified.guide/putty/create-socks-proxy或是用ssh指令連接到可以上網的電腦ssh -D 4444 -q -C -N user@ma.ttias.bewindows 設定SOCKS5 proxyhttps://blog.gtwang.org/linux/ssh-tunnel-socks-proxy-forwarding-tutorial/新增憑證https://learn.microsoft.com/zh-tw/biztalk/adapters-and-accelerators/accelerator-swift/adding-certificates-to-the-certificates-store-on-the-clientwindows下設定git proxy commandhttps://serverfault.com/questions/956613/windows-10-ssh-proxycommand-posix-spawn-no-such-file-or-directory" }, { "title": "windows docker設定", "url": "/posts/windows-docker/", "categories": "", "tags": "", "date": "2023-04-19 10:54:00 +0800", "snippet": "docker image搬離開系統槽https://stackoverflow.com/questions/62441307/how-can-i-change-the-location-of-docker-images-when-using-docker-desktop-on-wsl2 關閉wsl2 wsl --shutdown 匯出docke檔案 wsl --export docker-desktop-data \"D:\\Docker\\wsl\\data\\docker-desktop-data.tar\" unregister wsl --unregister docker-desktop-data 匯入 wsl --import docker-desktop-data \"D:\\Docker\\wsl\\data\" \"D:\\Docker\\wsl\\data\\docker-desktop-data.tar\" --version 2 wsl2 volumehttps://stackoverflow.com/questions/61083772/where-are-docker-volumes-located-when-running-wsl-using-docker-desktop" }, { "title": "Windows設定自動重啟服務", "url": "/posts/Windows%E8%A8%AD%E5%AE%9A%E8%87%AA%E5%8B%95%E9%87%8D%E5%95%9F%E6%9C%8D%E5%8B%99/", "categories": "", "tags": "", "date": "2023-04-13 10:54:00 +0800", "snippet": "開啟工作排程器分別設定停止服務和啟動服務兩個工作 使用最高權限執行工作並且使用者不須登入就執行 分別設定停止服務和啟動服務兩個工作在動作設定中，選擇開啟程式，並且在程式或指令中輸入net，並且在參數中輸入stop \"服務名稱\"或start \"服務名稱\" " }, { "title": "libcurl上傳圖片", "url": "/posts/libcurl%E4%B8%8A%E5%82%B3%E5%9C%96%E7%89%87/", "categories": "", "tags": "", "date": "2023-03-22 22:25:00 +0800", "snippet": "快速產生libcurl程式碼首先先用curl指令發送request，確認可以發送成功後可以用指令自動產生程式碼，在這裡我們將上傳一張圖片到http server，利用curl讀取電腦的圖片並且上傳curl -X POST \"http://localhost:8000/upload\" -H \"accept: application/json\" -H \"Content-Type: multipart/form-data\" -F \"uploadedFile=@a.jpg;type=image/jpeg\" -F \"EventTime=2022-01-01\"利用curl的--libcurl選項就可以快速產生c語言的程式碼，程式碼會被儲存到code.ccurl -X POST \"http://localhost:8000/upload\" -H \"accept: application/json\" -H \"Content-Type: multipart/form-data\" -F \"uploadedFile=@a.jpg;type=image/jpeg\" -F \"EventTime=2022-01-01\" --libcurl code.c產生的程式碼如下/********* Sample code generated by the curl command line tool ********** * All curl_easy_setopt() options are documented at: * https://curl.haxx.se/libcurl/c/curl_easy_setopt.html ************************************************************************/#include &lt;curl/curl.h&gt;int main(int argc, char *argv[]){ CURLcode ret; CURL *hnd; curl_mime *mime1; curl_mimepart *part1; struct curl_slist *slist1; mime1 = NULL; slist1 = NULL; slist1 = curl_slist_append(slist1, \"accept: application/json\"); slist1 = curl_slist_append(slist1, \"Content-Type: multipart/form-data\"); hnd = curl_easy_init(); curl_easy_setopt(hnd, CURLOPT_BUFFERSIZE, 102400L); curl_easy_setopt(hnd, CURLOPT_URL, \"http://localhost:8000/upload\"); curl_easy_setopt(hnd, CURLOPT_NOPROGRESS, 1L); mime1 = curl_mime_init(hnd); part1 = curl_mime_addpart(mime1); curl_mime_filedata(part1, \"a.jpg\"); curl_mime_name(part1, \"uploadedFile\"); curl_mime_type(part1, \"image/jpeg\"); part1 = curl_mime_addpart(mime1); curl_mime_data(part1, \"2022-01-01\", CURL_ZERO_TERMINATED); curl_mime_name(part1, \"EventTime\"); curl_easy_setopt(hnd, CURLOPT_MIMEPOST, mime1); curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, slist1); curl_easy_setopt(hnd, CURLOPT_USERAGENT, \"curl/7.68.0\"); curl_easy_setopt(hnd, CURLOPT_MAXREDIRS, 50L); curl_easy_setopt(hnd, CURLOPT_HTTP_VERSION, (long)CURL_HTTP_VERSION_2TLS); curl_easy_setopt(hnd, CURLOPT_SSH_KNOWNHOSTS, \"/home/ai_server/.ssh/known_hosts\"); curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, \"POST\"); curl_easy_setopt(hnd, CURLOPT_FTP_SKIP_PASV_IP, 1L); curl_easy_setopt(hnd, CURLOPT_TCP_KEEPALIVE, 1L); /* Here is a list of options the curl code used that cannot get generated as source easily. You may select to either not use them or implement them yourself. CURLOPT_WRITEDATA set to a objectpointer CURLOPT_INTERLEAVEDATA set to a objectpointer CURLOPT_WRITEFUNCTION set to a functionpointer CURLOPT_READDATA set to a objectpointer CURLOPT_READFUNCTION set to a functionpointer CURLOPT_SEEKDATA set to a objectpointer CURLOPT_SEEKFUNCTION set to a functionpointer CURLOPT_ERRORBUFFER set to a objectpointer CURLOPT_STDERR set to a objectpointer CURLOPT_HEADERFUNCTION set to a functionpointer CURLOPT_HEADERDATA set to a objectpointer */ ret = curl_easy_perform(hnd); curl_easy_cleanup(hnd); hnd = NULL; curl_mime_free(mime1); mime1 = NULL; curl_slist_free_all(slist1); slist1 = NULL; return (int)ret;}/**** End of sample code ****/將curl_mime_filedata改成curl_mime_data由於我的目的是將在記憶體中已經被encode好的圖片直接上傳，所以要用curl_mime_data直接上傳記憶體內的內容。注意除了用curl_mime_data放入資料以外，還必須自己手動把Content-Disposition補上filename。另外記得curl_mime_data不可以用CURL_ZERO_TERMINATED而是要實際算出圖片的資料長度。可以參考官方的範例 curl_mime *mime; curl_mimepart *part; /* create a mime handle */ mime = curl_mime_init(easy); /* add a part */ part = curl_mime_addpart(mime); /* send image data from memory */ curl_mime_data(part, imagebuf, imagebuf_len); /* set a file name to make it look like a file upload */ curl_mime_filename(part, \"image.png\"); /* set name */ curl_mime_name(part, \"data\");讀binary file直接將圖片讀進記憶體內不要做任何處理範例void ReadFile(char *name){\tFILE *file;\tchar *buffer;\tunsigned long fileLen;\t//Open file\tfile = fopen(name, \"rb\");\tif (!file)\t{\t\tfprintf(stderr, \"Unable to open file %s\", name);\t\treturn;\t}\t\t//Get file length\tfseek(file, 0, SEEK_END);\tfileLen=ftell(file);\tfseek(file, 0, SEEK_SET);\t//Allocate memory\tbuffer=(char *)malloc(fileLen+1);\tif (!buffer)\t{\t\tfprintf(stderr, \"Memory error!\"); fclose(file);\t\treturn;\t}\t//Read file contents into buffer\tfread(buffer, fileLen, 1, file);\tfclose(file);\t//Do what ever with buffer\tfree(buffer);}termshark再除錯的過程中，最好可以直接看一看自己的封包長什麼樣子，對於沒有螢幕的Ubuntu Server，可以安裝termshark，它可以做到跟wireshark差不多的事情完整範例/********* Sample code generated by the curl command line tool ********** * All curl_easy_setopt() options are documented at: * https://curl.haxx.se/libcurl/c/curl_easy_setopt.html ************************************************************************/#include &lt;curl/curl.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]){ CURLcode ret; CURL *hnd; curl_mime *mime1; curl_mimepart *part1; struct curl_slist *slist1; mime1 = NULL; slist1 = NULL; slist1 = curl_slist_append(slist1, \"accept: application/json\"); slist1 = curl_slist_append(slist1, \"Content-Type: multipart/form-data\"); hnd = curl_easy_init(); curl_easy_setopt(hnd, CURLOPT_BUFFERSIZE, 102400L); curl_easy_setopt(hnd, CURLOPT_URL, \"http://localhost:8000/upload\"); curl_easy_setopt(hnd, CURLOPT_NOPROGRESS, 1L); mime1 = curl_mime_init(hnd); part1 = curl_mime_addpart(mime1); // https://www.w3schools.blog/c-read-binary-file FILE *file; const char *buffer; unsigned long fileLen; //Open file file = fopen(\"image.jpg\", \"rb\"); if (!file) { fprintf(stderr, \"Unable to open file\"); return; } //Get file length fseek(file, 0, SEEK_END); fileLen=ftell(file); fseek(file, 0, SEEK_SET); //Allocate memory buffer=(char *)malloc(fileLen+1); if (!buffer) { fprintf(stderr, \"Memory error!\"); fclose(file); return; } //Read file contents into buffer fread(buffer, fileLen, 1, file); fclose(file); /* add data to the part */ curl_mime_data(part1, buffer, fileLen); /* set a file name to make it look like a file upload */ curl_mime_filename(part1, \"image.jpg\"); free(buffer); curl_mime_name(part1, \"uploadedFile\"); curl_mime_type(part1, \"image/jpeg\"); part1 = curl_mime_addpart(mime1); curl_mime_data(part1, \"2022-02-02\", CURL_ZERO_TERMINATED); curl_mime_name(part1, \"EventTime\"); curl_easy_setopt(hnd, CURLOPT_MIMEPOST, mime1); curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, slist1); curl_easy_setopt(hnd, CURLOPT_USERAGENT, \"curl/7.68.0\"); curl_easy_setopt(hnd, CURLOPT_MAXREDIRS, 50L); curl_easy_setopt(hnd, CURLOPT_HTTP_VERSION, (long)CURL_HTTP_VERSION_2TLS); curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, \"POST\"); curl_easy_setopt(hnd, CURLOPT_FTP_SKIP_PASV_IP, 1L); curl_easy_setopt(hnd, CURLOPT_TCP_KEEPALIVE, 1L); ret = curl_easy_perform(hnd); curl_easy_cleanup(hnd); hnd = NULL; curl_mime_free(mime1); mime1 = NULL; curl_slist_free_all(slist1); slist1 = NULL; return (int)ret;}/**** End of sample code ****/參考:https://daniel.haxx.se/blog/2022/09/12/convert-a-curl-cmdline-to-libcurl-source-code/https://curl.se/libcurl/c/curl_mime_filename.htmlhttps://geekscripts.guru/termshark-terminal-ui-for-tshark/" }, { "title": "Computer Vision Models Learning and Inference整理", "url": "/posts/computer-vision-models-learning-and-inference%E6%95%B4%E7%90%86/", "categories": "", "tags": "", "date": "2023-03-12 21:47:00 +0800", "snippet": "CH3 常見的probability distributions要利用第二章操作probabilities的規則，為了使用這些規則，我們需要定義一些機率分布。選擇機率分布的依據是取決於我們正在建模的數據x的領域。當我們在使用模型去擬合資料的時候，我們需要知道我們對擬合的不確定性有多大，而這個不確定性被表示為”對擬合模型的參數的機率分布”。也就是說每當一個模型在擬合資料的時候，都存在一個與之相關聯的參數的第二個機率分布。例如 Dirichlet 是用於categorical distribution的參數的模型。在這種狀況下 Dirichlet的參數會被稱為超參數(hyperparameters)。更一般地說，超參數確定了原始分布參數的機率分布的形狀。 Distribution Domain Parameters modeled by   Bernoulli x ∈ {0, 1} beta   categorical x ∈ {1, 2, . . . , K} Dirichlet   univariate normal x ∈ R normal inverse gamma   multivariate normal x ∈ Rk normal inverse Wishart   Distribution Domain Parameters modeled by Bernoulli x ∈ {0, 1} beta categorical x ∈ {1, 2, . . . , K} Dirichlet univariate normal x ∈ R normal inverse gamma multivariate normal x ∈ Rk normal inverse Wishart CH3.1 Bernoulli distributionBernoulli distribution是一個離散分布用於模擬二元試驗。他用於描述只有兩中輸出結果的狀況，$x \\in {0, 1}$分別代表是(success)、否(failure)。在機器視覺中，Bernoulli distribution可以用來模擬資料。例如，它可以描述一個像素具有大於或小於128的強度值的概率。或者是用來描述世界的狀態。例如，它可以描述圖像中臉部存在或不存在的概率。Bernoulli distribution只有一個parameter $\\lambda \\in [0, 1]$，用來描述觀察到success的機率。Bernoulli distribution的機率質量函數如下\\(Pr(x = 0) = 1 - \\lambda\\)\\(Pr(x = 1) = \\lambda\\)我們可以用另一種表達方式，將0或1帶入就可以得到上面其中一條式子。\\(Pr(x) = \\lambda^x(1-\\lambda)^{1-x}\\)或是另一種等價的表達方式\\(Pr(x) = Bern_x[\\lambda]\\)CH3.2 Beta distributionBeta distribution是一個連續分布，他是定義在單變量$\\lambda$上的連續分布，$\\lambda \\in [0, 1]$。它適用於表示伯努利分布參數$\\lambda$的不確定性。beta distribution 有兩個parameter$\\alpha, \\beta \\in [0, \\infty]$，兩個parameter均為正數並且影響distribution的形狀。以數學表達如下\\(Pr(\\lambda) = \\frac{\\Gamma[\\alpha + \\beta]}{\\Gamma[\\alpha]\\Gamma[\\beta]}\\lambda^{\\alpha-1}(1-\\lambda)^{\\beta-1}\\)式子中的$\\Gamma[]$代表gamma function，定義為\\(\\Gamma[z] = \\int_0^{\\infty}t^{z-1}e^{-t}dt\\)，他與階乘密切相關，因此對於正數的積分$\\Gamma[z] = (z - 1)!$而且$\\Gamma[z+1] = z\\Gamma[z]$ 。beta distribution還有更簡單的表達式\\(Pr(\\lambda) = Beta_{\\lambda}[\\alpha, \\beta]\\)CH3.3 Catagorical distributionCatagorical distribution是一個離散分布，他用來決定K個可能結果之一的概率。因此Bernoulli distribution是Catagorical distribution的一種特例，也就是只有兩種可能結果的Catagorical distribution。在機器視覺中也經常出現多個離散值取一個的情況，例如依照照片可能是{car,motorbike,van,truck}的其中一個。對於有K種結果的Catagorical distribution，Catagorical distribution會一個$K \\times 1$的參數的向量$\\lambda = [\\lambda_1, \\lambda_2 … , \\lambda_K]$其中$\\lambda_K \\in [0, 1]$而且$\\sum^K_{k=1}\\lambda_k = 1$Catagorical distributiond可以寫成\\[Pr(x = k) = \\lambda_k\\]更簡短的可以寫成\\(Pr(x) = Cat_x[\\lambda]\\)或者，我們可以將數據看作取值$x \\in {e_1, e_2, …,e_K}$，其中$e_k$是第k個單位向量；除了第k個元素為1之外，$e_k$的所有元素都為零。寫成式子如下\\[Pr(x=e_k) = \\prod^K_{j=1}\\lambda_k^{x_j} = \\lambda_k\\]其中$x_j$是$x$的第j個元素。CH3.4 Dirichlet distributionDirichlet distribution 是一個定義在K個連續值$\\lambda_1 … \\lambda_K$上的分佈，其中$\\lambda_k \\in [0, 1]$而且$\\sum^K_{k=1}\\lambda_k = 1$。因此他很適合用來作為定義Catagorical distribution的參數分布。在$K$個維度上的Dirichlet distribution有$K$個parameter $\\alpha_1 … \\alpha_K$，每一個都可以是正數或是零。parameters之間的相對值決定了 expected values $E[\\lambda_1] … E[\\lambda_K]$。parameters的絕對值決定了Dirichlet distribution的集中度。他的機率密度函數如下\\(Pr(\\lambda_{1...L}) = \\frac{\\Gamma[\\sum^K_{k=1}\\alpha_k]}{\\prod^K_{k=1}\\Gamma[\\alpha_k]}\\prod^K_{k=1}\\lambda_k^{\\alpha_k-1}\\)更簡短的寫法\\(Pr(\\lambda_{1...K}) = Dir_{\\lambda_{1...K}}[\\alpha_{1...K}]\\)如同Bernoulli distribution是Catagorical distribution的特例，所以Beta distribution是Dirichlet distribution的特例，也就是$K=2$的Beta distribution。3.5 Univariate normal distributionUnivariate normal distribution 或是 Gaussian distribution 是一個定義在實數上$x \\in [-\\infty, \\infty]$的連續分佈。在計算機視覺中，常常忽略像素強度被量化的事實，並使用連續的正態分佈模型來建模。Normal distribution有兩個parameter，平均數$\\mu$和變異數$\\sigma^2$，平均數$\\mu$決定了分佈的中心的位置，變異數$\\sigma^2$決定了分佈的寬度。Normal distribution的機率密度函數如下\\(Pr(x|) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\}\\)或是更簡單的寫法\\(Pr(x) = Norm_x[\\mu, \\sigma^2]\\)3.6 Normal-scaled inverse gamma distributionNormal-scaled inverse gamma distribution是一個定義在一對實數$\\mu, \\sigma$上的連續分佈，他的機率密度函數如下，其中$\\mu$可以為正為負，但是$\\sigma$必須為正。Normal-scaled inverse gamma distribution有四個parameter，$\\alpha, \\beta, \\gamma, \\delta$，其中$\\alpha, \\beta, \\gamma$必須為正，而$\\delta$可以為正為負。機率密度函數如下:\\(Pr(\\mu, \\sigma^2) = \\frac{\\sqrt{\\gamma}}{\\sigma\\sqrt{2\\pi}}\\frac{\\beta^\\alpha}{\\Gamma[\\alpha]}(\\frac{1}{\\sigma^2})^{\\alpha + 1}exp[-\\frac{2\\beta + \\gamma(\\delta - \\mu)^2}{2\\sigma^2}]\\)或者是寫成\\(Pr(\\mu, \\sigma^2) = NormInvGam_{\\mu, \\sigma^2}[\\alpha, \\beta, \\gamma, \\delta]\\)3.7 Multivariate normal distributionmultivariate normal 也就是 D-dimensional Gaussian distribution，他的維度可以表示成D個元素 $x_1, … x_D$每個維度都是連續並且介於$[-\\infty, \\infty]$。而univariate normal distribution是multivariate normal distribution的特例，也就是$D=1$。在機器視覺中，多變量正態分佈可以用來模擬圖像區域內 D 個像素的強度的聯合分佈。世界的狀態也可以用這個分佈來描述。例如，多變量正態分佈可以描述場景中物體的三維位置（x、y、z）的聯合不確定性。multivariate normal distribution有兩個parameter，平均數向量$\\mu$ 以及covariance $\\Sigma$。其中$\\mu$是一個$D \\times 1$的向量來描述分布的平均值。而covariance $\\Sigma$是一個$D \\times D$的正定矩陣，因此對於任何實數向量$z$而言，$z^T\\Sigma z$都是正數。機率密度函式如下\\(Pr(x) = \\frac{1}{\\sqrt{(2\\pi)^D|\\Sigma|}}exp[-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)]\\)或是更簡短一點\\(Pr(x) = Norm_x[\\mu, \\Sigma]\\)3.8 Normal inverse Wishart distributionnormal inverse Wishart distribution是一個定義在$D \\times 1$的向量 $\\mu和$D \\times D$的矩陣 \\Sigma$上的連續分佈。他適合用來描述 multivariate normal distribution 的參數的不確定性。normal inverse Wishart distribution有四個參數，$\\alpha, \\Psi, \\gamma, \\delta$，其中$\\alpha$和$\\gamma$為正純量，$\\delta$為$D \\times 1$的向量，$\\Psi$為$D \\times D$的正定矩陣。機率密度函數如下\\(\\operatorname{Pr}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})=\\frac{\\gamma^{D / 2}|\\boldsymbol{\\Psi}|^{\\alpha / 2} \\exp \\left[-0.5\\left(\\operatorname{Tr}\\left[\\boldsymbol{\\Psi} \\boldsymbol{\\Sigma}^{-1}\\right]+\\gamma(\\boldsymbol{\\mu}-\\boldsymbol{\\delta})^T \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}-\\boldsymbol{\\delta})\\right)\\right]}{2^{\\alpha D / 2}(2 \\pi)^{D / 2}|\\boldsymbol{\\Sigma}|^{(\\alpha+D+2) / 2} \\Gamma_D[\\alpha / 2]}\\)其中$\\Gamma_D[\\bullet]$是multivariate gamma function and而$\\operatorname{Tr}[\\Psi]$回傳矩陣的迹(trace)。更簡單的寫法如下\\(Pr(\\mu, \\Sigma) = NormInvWish_{\\mu, \\Sigma}[\\alpha, \\Psi, \\gamma, \\delta]\\)很難將normal inverse Wishart distribution分佈可視化，但很容易抽樣並檢查樣本：每個樣本是一個常態分佈的平均值和協方差。3.9 Conjugacy在前面幾節有提到有些distribution可以呈現另一個distribution參數的機率分布。因為這些分布之間都有Conjugacy的關係。例如beta distribution conjugate Bernoulli distribution。Dirichlet conjugate categorical。當我們將兩個有Conjugacy的distribution相乘，結果將與共軛具有相同形式的新分佈成正比。例如\\(Bern_x[\\lambda]\\times Beta_\\lambda[\\alpha, \\beta] = \\kappa(x, \\alpha, \\beta)\\times Beta_\\lambda[\\~{\\alpha}, \\~{\\beta}]\\)在這裡$\\kappa$是一個對於所關心的變量$\\lambda$來說是常數的縮放因子。conjugate重要的原因是因為在學習（擬合分佈）和評估模型（評估新數據在擬合分佈下的概率）的過程中，我們需要對分佈進行乘法運算。共軛關係意味著這些乘積都可以以封閉形式整潔地計算得出。CH4 擬和機率模型這章節的目標是將機率模型擬和到資料\\(\\{x_i\\}^I_{i=1}\\)，這個過程稱為學習learning，目標是找到模型的參數組\\(\\theta\\)。此外我們也學習如何用學習後的模型對新的數據\\(x^*\\)計算出他的機率，這過程evaluating the predictive distribution。在這章我們探討三種方法 maximum likelihood maximum a posteriori Bayesian approachmaximum likelihoodmaximum likelihood目標是要找到一組參數\\(\\hat{\\theta}\\)使得資料\\(\\{x_i\\}^I_{i=1}\\)出現的機率最大化。而計算likelihood function 在單一個資料點\\(x_i\\)，也就是\\(Pr(x_i|\\theta)\\)，我們只需在\\(x_i\\)處評估概率密度函數。假設每一個資料點都是從分布中獨立被取出的，那麼所有資料點的機率\\(Pr(x_{i...I}|{\\theta})\\)就是所有單獨資料點代入likelihood function的乘積。因此要maximum likelihood可以寫成\\[\\hat{\\theta} = argmax_{\\theta}[Pr(x_{i...I}|{\\theta})] =argmax_{\\theta} [\\prod_{i=1}^I Pr(x_i|\\theta)]\\]式子中的\\(argmax_{\\theta}f[\\theta]\\)是指找到一組參數組\\({\\theta}\\)，讓\\(argmax_{\\theta}f[\\theta]\\)最大化。要計算新資料\\(x^*\\)的predictive distribution，只需將新資料和我們找到的參數組帶入likelihood function，計算出機率即可。Maximum Posteriori在Maximum Posteriori（MAP）擬合中，我們引入有關參數\\(\\theta\\)的先驗信息。由於我們可能對可能的參數值有所了解。例如，在時間序列中，時間 t 的參數值可以告訴我們在時間 t + 1 可能的值，於是將此信息將被編碼在先驗分佈中。如同它的名稱，Maximum Posteriori方法將會找到一組參數組\\(\\hat{\\theta}\\)，使得Posteriori probability \\(Pr(\\theta|x_{i...I})\\)最大化。\\[\\hat{\\theta} = argmax_{\\theta}[Pr(\\theta|x_{i...I})]\\]\\[=argmax_{\\theta} [\\frac{Pr(x_{i...I}|\\theta)Pr(\\theta)}{Pr(x_{i...I})}]\\]\\[=argmax_{\\theta} [\\frac{\\prod_{i=1}^I Pr(x_i|\\theta)Pr(\\theta)}{Pr(x_{i...I})}]\\]在這裡第一行可以由貝葉斯定理推得第二行。另外由於我們找的是參數組\\(\\theta\\)的最大值，所以分母的常數\\(Pr(x_{i...I})\\)是可以忽略的。因此我們可以將式子簡化成\\[\\hat{\\theta} = argmax_{\\theta} [\\prod_{i=1}^I Pr(x_i|\\theta)Pr(\\theta)]\\]我們可以發現他其實跟maximum likelihood只差了一項先驗分佈\\(Pr(\\theta)\\)，所以maximum likelihood其實是maximum posteriori的一種特例，也就是maximum likelihood是\\(Pr(\\theta)\\)是一個常數的情況。Bayesian ApproachBayesian Approach裡，我們不再把參數\\(\\theta\\)當作一個常數，而是承認一件顯而易見的事實，參數組\\(\\theta\\)可能不是唯一的。因此我們嘗試利用貝葉思定裡計算\\(Pr(\\theta|x_{i...I})\\)，也就是在資料\\(x_{i...I}\\)出現的情況下，參數組\\(\\theta\\)的機率分佈。\\[Pr(\\theta|x_{i...I}) = \\frac{\\prod_{i=1}^I Pr(x_i|\\theta)Pr(\\theta)}{Pr(x_{i...I})}\\]而要驗證Bayesian Approach會比較複雜一點，因為跟前面不一樣我們沒有一個固定的參數組\\(\\theta\\)可以帶入並且計算出機率，在這裡我們必須可能模型的機率分布。因此我們用以下方法計算。\\[Pr(x^*|x_{i...I}) = \\int Pr(x^*|\\theta)Pr(\\theta|x_{i...I})d\\theta\\]這條式子可以用以下方式解讀:$Pr(x^*|\\theta)$ 是對於給定的參數組 \\(\\theta\\)，\\(x^*\\)出現的機率，因此這個積分可以視為使用不同的參數\\(\\theta\\)所做出預測的加權總和，其中權重是由參數的posterior probability distribution \\(Pr(\\theta|x_{i...I})\\) 來決定的（代表我們對不同參數正確性的信心程度）。統一三種方法的 predictive density calculations如果我們將maximum likelihood, maximum posteriori 的參數的機率分布視為一種特例，也就是maximum likelihood, maximum posteriori參數分布全部集中在\\(\\hat{\\theta}\\)。正式的說法就是參數分布為一個以\\(\\hat{\\theta}\\)為中心的delta function。一個delta function \\(\\delta[z]\\)是一個函式他的積分為1，而且在除了中心點z以外的任何地方都是0。我們將剛才predictive density帶入delta function，可以得到以下結果。\\[Pr(x^*|x_{i...I}) = \\int Pr(x^*|\\theta)\\delta[\\theta - \\hat{\\theta}]d\\theta\\]\\[= Pr(x^*|\\hat{\\theta})\\]ch4.4範例一下面範例我們考慮擬和一個univariate normal model到一組數據\\(\\{x_i\\}^I_{i=1}\\)。首先univariate normal model的probability density function為\\[Pr(x|\\mu,\\sigma^2) = Norm_x[\\mu,\\sigma^2] = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp[-\\frac{(x-\\mu)^2}{2\\sigma^2}]\\]他有兩個參數平均\\(\\mu\\)和變異數\\(\\sigma^2\\)，首先我們從一個平均為1，變異數為1的normal distribution中取出\\(I\\)個數據\\(x_{1...I}\\)，我們的目標是利用前面的三種方法擬和抽取出來的數據集。方法一Maximum likelihood estimation對於觀測到的數據$Pr(x_{1…I}|\\mu,\\sigma^2)\\(來說，參數\\){\\mu,\\sigma^2}$$ 的概率(likelihood) Pr(x_1…I |µ, σ^2) 是通過對每個數據點分別評估概率密度函數，然後取乘積得到的。\\[Pr(x_{1...I}|\\mu,\\sigma^2) = \\prod_{i=1}^I Pr(x_i|\\mu,\\sigma^2)\\]\\[= \\prod_{i=1}^I Norm_{x_i}[\\mu,\\sigma^2]\\]\\[= \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp[-\\sum_{i=1}^I \\frac{(x_i-\\mu)^2}{2\\sigma^2}]\\]很明顯的某些\\(\\{\\mu,\\sigma^2\\}\\)參數組會使得likelihood比其他參數組還高。而且我們可以在二維平面視覺化各種參數組的likelihood，我們將以平均\\(\\mu\\)和變異數\\(\\sigma^2\\)為軸，而Maximum likelihood的解答就是在圖形的頂點(圖4.2)。也就是以下式子的解答。\\[\\hat{\\mu}, {\\hat\\sigma}^2 = argmax_{\\mu,\\sigma^2} [Pr(x_{1...I}|\\mu,\\sigma^2)]\\] 理論上我們可以藉由微分$$Pr(x_{1…I} \\mu,\\sigma^2)\\(來求解，但是實際上\\)Pr(x_{1…I} \\mu,\\sigma^2)\\(太複雜，因此我們可以將\\)Pr(x_{1…I} \\mu,\\sigma^2)\\(取log，因為log是一個單調遞增函數，經過轉換後的\\)Pr(x_{1…I} \\mu,\\sigma^2)$$的最大值會在相同的地方。代數上，對數把各個數據點的可能性的乘積轉化為它們的總和，因此可以將每個數據點的貢獻分離出來。於是Maximum likelihood可以用以下方式計算。 \\[\\hat{\\mu}, {\\hat\\sigma}^2 = argmax_{\\mu,\\sigma^2} [\\sum_{i=1}^I log [Norm_{x_{i}}[\\hat{\\mu}, {\\hat\\sigma}^2]]]\\]\\[= argmax_{\\mu,\\sigma^2} [-0.5Ilog[2\\pi] - 0.5Ilog(\\sigma^2) - 0.5\\sum_{i=1}^I\\frac{(x_i-\\mu)^2}{\\sigma^2}]\\]接著對對 log likelihood function L 進行\\(\\mu\\)的偏微分。\\(\\frac{\\partial L}{\\partial \\mu} = \\sum_{i=1}^I \\frac{(x_i-\\mu)}{\\sigma^2}\\)\\(= \\frac{\\sum_{i=1}^I x_i}{\\sigma^2} - \\frac{I\\mu}{\\sigma^2} = 0\\)整理後可以得到\\(\\hat{\\mu} = \\frac{\\sum_{i=1}^I x_i}{I}\\)利用類似的方利用類似的方法可以得到變異數\\(\\sigma^2\\)的解答為\\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^I (x_i-\\hat{\\mu})^2}{I}\\)Least squares ﬁtting另外需要注意的是，很多文獻都是以最小二乘法來討論擬合的。我們使用maximumlikelihood來擬和正態分佈的平均參數\\(\\mu\\)。將前面式子將\\(\\sigma^2\\)視為常數可以得到\\(\\hat{\\mu} = argmax_{\\mu,\\sigma^2} [-0.5Ilog[2\\pi] - 0.5Ilog(\\sigma^2) - 0.5\\sum_{i=1}^I\\frac{(x_i-\\mu)^2}{\\sigma^2}]\\)\\[= argmax_{\\mu,\\sigma^2} [-\\sum_{i=1}^I(x_i-\\mu)^2]\\]\\[= argmax_{\\mu,\\sigma^2} [\\sum_{i=1}^I(x_i-\\mu)^2]\\]也就是說least squares ﬁtting和使用maximum likelihood 估計常態分布的均值參數是等價的。log likehood好處likelihood function可以看到是許多乘法的結果，因此微分很不好算。由於log函數是monotonic的關係，所以likelihood function經過log轉換後的最大值會在相同的地方，而且經過log轉換後乘法變成加法，因此微分變得容易許多。https://bookdown.org/dereksonderegger/571/13-maximum-likelihood-estimation.html#likelihood-functionhttps://math.stackexchange.com/questions/3053131/why-are-the-local-extrema-of-a-log-transformed-function-equal-to-local-extrema-ohttps://towardsdatascience.com/log-loss-function-math-explained-5b83cd8d9c83方法二Maximum posteriori estimation根據前面的定義，Maximum posteriori estimation的cost function為\\(\\hat{\\mu}, {\\hat\\sigma}^2 = argmax_{\\mu,\\sigma^2} [\\prod_{i=1}^I Pr(x_i|\\mu,\\sigma^2)Pr(\\mu,\\sigma^2)]\\)\\[= argmax_{\\mu,\\sigma^2} [\\prod_{i=1}^I Norm_{x_i}[\\mu,\\sigma^2]NormInvGam_{\\mu,\\sigma^2}[\\alpha,\\beta,\\gamma,\\delta]]\\]在這裡我們選擇我們選擇了normal inverse gamma prior，其參數為α，β，γ，δ（圖4.4），因為它與normal distribution共軛。在式子中的prior如下\\(Pr(\\mu,\\sigma^2) = \\frac{\\sqrt{\\gamma}}{\\sigma\\sqrt{2\\pi}}\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}(\\frac{1}{\\sigma^2})^{\\alpha + 1}exp[-\\frac{2\\beta + \\gamma(\\delta-\\mu)^2}{2\\sigma^2}]\\)而posterior distribution 與likelihood和prior的乘積成正比（見圖4.5），在與數據一致且先驗可信的區域具有最高的機率密度。而跟maximum likelihood一樣我們利用把式子取log來計算最大值。式子如下\\(\\hat{\\mu}, {\\hat\\sigma}^2 = argmax_{\\mu,\\sigma^2} [\\sum_{i=1}^I log [Norm_{x_{i}}[\\mu, {\\sigma}^2]] + log [NormInvGam_{\\mu,\\sigma^2}[\\alpha,\\beta,\\gamma,\\delta]]]\\)要找到MAP(maximum a posteriori)我們將式子拆成兩段並且分別對\\(\\mu\\)和\\(\\sigma^2\\)做偏微分。式子如下\\(\\hat{\\mu} = \\frac{\\sum_{i=1}^I x_i + \\gamma\\delta}{I + \\gamma}\\)\\[\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^I (x_i-\\hat{\\mu})^2 + 2\\beta + \\gamma(\\delta-\\hat{\\mu})^2}{I + 3 + 2\\alpha}\\]而平均數$\\hat{\\mu}$的解答可以進一步簡化\\(\\hat{\\mu} = \\frac{I\\bar{x} + \\gamma\\delta}{I + \\gamma}\\)這式子是兩項的加權平均值，第一項是資料的平均$\\bar{x}$並且以訓練樣本的數量$I$為權重，第二項是先驗分佈的參數$\\delta$並且以先驗分佈的參數$\\gamma$為權重 這裡給我們一些MAP(maximum a posteriori)的洞察。 當資料數量越多時，MAP的解會越接近資料平均(也就是ML(Maximum likelihood)的解) 當資料數量少一些的時候，MAP的解會在ML和prior的中間 當完全沒有資料的時候，MAP的解就是proir 方法三Bayesian estimation在Bayesian estimation我們利用Bayesian定理計算參數的posterior distribution。\\(Pr(\\mu, \\sigma^2 | x_{1...I}) = \\frac{\\prod_{i=1}^I Pr(x_i|\\mu,\\sigma^2)Pr(\\mu,\\sigma^2)}{Pr(x_{1...I})}\\)\\[= \\frac{\\prod_{i=1}^I Norm_{x_i}[\\mu,\\sigma^2]NormInvGam_{\\mu,\\sigma^2}[\\alpha,\\beta,\\gamma,\\delta]}{Pr(x_{1...I})}\\]\\[= \\frac{\\kappa NormInvGam_{\\mu,\\sigma^2}[\\~\\alpha,\\~\\beta,\\~\\gamma,\\~\\delta]}{Pr(x_{1...I})}\\]在這裡likelihood和prior有共軛關係，而$\\kappa$是 associated constant。Normal likelihood和normal inverse gamma prior的乘機產生出一個關於$\\mu$$\\sigma^2$的posterior distribution。其參數如下\\[\\~\\alpha = \\alpha + \\frac{I}{2}\\]\\[\\~\\gamma = \\gamma + I\\]\\[\\~\\delta = \\frac{\\gamma\\delta + \\sum_{i=1} x_i}{\\gamma + I}\\]\\[\\~\\beta = \\frac{\\sum_{i=1} x_i^2}{2} + \\beta + \\frac{\\gamma\\delta^2}{2} - \\frac{(\\gamma\\delta + \\sum_{i=1} x_i)^2}{2(\\gamma + I)}\\]需要注意的是，後驗分布（式4.20左側）必須是一個有效的概率分布，總和為一，因此共軛乘積中的常數 κ 和右側的分母必須完全抵消，才能得到：\\[Pr(\\mu, \\sigma^2 | x_{1...I}) = NormInvGam_{\\mu,\\sigma^2}[\\~\\alpha,\\~\\beta,\\~\\gamma,\\~\\delta]\\]現在我們可以看到conjugate prior的好處，我們保證可以得到關於參數的後驗分布的封閉形式表達式。 Predictive density跟maximum likelihood和MAP(maximum a posteriori)不一樣是，Bayesian estimation計算Predictive density的方式是我們計算每個可能參數集的預測值的加權平均值，其中加權由參數的後驗分布給出。\\[Pr(x_*|x_{1...I}) = \\int \\int Pr(x^*|\\mu,\\sigma^2)Pr(\\mu,\\sigma^2|x_{1...I})d\\mu d\\sigma^2\\]\\[= \\int \\int Norm_{x^*}[\\mu,\\sigma^2]NormInvGam_{\\mu,\\sigma^2}[\\~\\alpha,\\~\\beta,\\~\\gamma,\\~\\delta]d\\mu d\\sigma^2\\]\\[= \\int \\int \\kappa(x^*, \\~\\alpha, \\~\\beta, \\~\\gamma, \\~\\delta)NormInvGam_{\\mu,\\sigma^2}[\\~\\alpha,\\~\\beta,\\~\\gamma,\\~\\delta]d\\mu d\\sigma^2\\]這裡我們又再次用到conjugate relation。積分包含一個與$\\mu$和$\\sigma^2$無關的常數乘以一個概率分布。將常數移到積分號外，可以得到：\\[Pr(x^*|x_{1...I}) = \\kappa(x^*, \\~\\alpha, \\~\\beta, \\~\\gamma, \\~\\delta)\\int \\int NormInvGam_{\\mu,\\sigma^2}[\\~\\alpha,\\~\\beta,\\~\\gamma,\\~\\delta]d\\mu d\\sigma\\]因為pdf的積分為1，所以\\[= \\kappa(x^*, \\~\\alpha, \\~\\beta, \\~\\gamma, \\~\\delta)\\]常數可以表示為：\\[\\kappa(x^*, \\~\\alpha, \\~\\beta, \\~\\gamma, \\~\\delta) = \\frac{1}{\\sqrt{2\\pi}}\\frac{\\sqrt{\\~\\gamma}\\~\\beta^{\\~\\alpha}}{\\sqrt{\\v\\gamma}\\v\\beta^{\\v\\alpha}}\\frac{\\Gamma(\\v\\alpha)}{\\Gamma(\\~\\alpha)}\\]其中\\[\\v\\alpha = \\~\\alpha + \\frac{I}{2}\\]\\[\\v\\gamma = \\~\\gamma + I\\]\\[\\v\\beta = \\frac{\\sum_{i=1} x_i^2}{2} + \\~\\beta + \\frac{\\~\\gamma\\~\\delta^2}{2} - \\frac{(\\~\\gamma\\~\\delta + \\sum_{i=1} x_i)^2}{2(\\~\\gamma + I)}\\]在這裡我可以看到第二個使用conjugate prior的好處:可以計算積分，所以我們得到一個很好的封閉形式表達式來預測密度。在有大量訓練數據的情況下，貝葉斯預測分布和最大事後概率（MAP）預測分布非常相似，但當數據量減少時，貝葉斯預測分布的尾部明顯更長。這是貝葉斯解決方案的典型特徵：它們在預測時更加中庸（不那麼確定）。在 MAP 的情況下，錯誤地承諾一個 µ 和 σ^2 的估計值導致我們對未來的預測過於自信。ch4.5範例一第二個範例我們考慮離散的資料${x_i}^I_{i=1}$其中$x_i \\in {1, 2, …, 6}$。這種表達方式可以用來表達一個不均勻的骰子所出現的點數資料。我們將使用 categorical distribution來描述這些資料。\\(Pr(x=k|\\lambda_{1...K}) = \\lambda_k\\)利用Maximum posteriori estimation和maximum a posteriori來推測六個參數${\\lambda_k}^6_{k=1}$。而Bayesian方法則計算參數的probability distribution4.5.1 Maximum Likelihood為了找到Maximum Likelihood，我們要最大化每一個資料點的likelihood相乘的乘積\\[\\hat \\lambda_{1...6} = argmax_{\\lambda_{1...6}}[\\prod^I_{i=1}Pr(x_i|\\lambda_{1...6})] \\qquad s.t. \\sum_k \\lambda_k = 1\\]\\[= argmax_{\\lambda_{1...6}}[\\prod^I_{i=1} Cat_{x_i}[\\lambda_{1...6}]] \\qquad s.t. \\sum_k \\lambda_k = 1\\]\\[= argmax_{\\lambda_{1...6}}[\\prod^6_{k=1}\\lambda^{N_k}_k] \\qquad s.t. \\sum_k \\lambda_k = 1\\]其中$N_k$代表在訓練資料中觀察到k的總次數。跟前一個例子一樣，利用log probability來協助尋找最大值。\\(L = \\sum^6_{k=1}N_klog[\\lambda_k] + \\nu(\\sum^6_{k=1}\\lambda_k - 1)\\)在這個式子中利用了 Lagrange multiplier $\\nu$ 來達成$\\sum^6_{k=1} \\lambda_k = 1$的限制。接著我們對L對於$\\lambda_k$和$\\nu$微分並且將導數設為0，可以得到下式。\\(\\hat \\lambda_k = \\frac{N_k}{\\sum^6_{m=1}N_m}\\)換句話說$\\lambda_k$和觀察到k的次數成正比。4.5.2 Maximum a posteriori要找到 maximum a posteriori 首先要定義一個prior。我們選擇和categorical likelihood共軛的 Dirichlet distribution。式子如下。\\(\\hat \\lambda_{1...6} = \\underset{\\lambda_{1...6}}{\\mathrm{argmax}}[\\prod^I_{i=1}Pr(x_i|\\lambda_{1...6})Pr(\\lambda_{1...6})]\\)\\[= \\underset{\\lambda_{1...6}}{\\mathrm{argmax}}[\\prod^I_{i=1}Cat_{xi}[\\lambda_{1...6}]Dir_{\\lambda_{1...6}}[\\alpha_{1...6}]]\\]\\[= \\underset{\\lambda_{1...6}}{\\mathrm{argmax}}[\\prod^6_{k=1}\\lambda_k^{N_k}\\prod^6_{k=1}\\lambda_k^{\\alpha_k-1}]\\]\\[= \\underset{\\lambda_{1...6}}{\\mathrm{argmax}}[\\prod^6_{k=1}\\lambda^{N_k + \\alpha_k -1}_k]\\]接著和 maximum likelihood一樣利用 Lagrange multiplier來達成$\\sum^6_{k=1} \\lambda_k = 1$的限制。Maximum a posteriori推估參數的式子如下。\\(\\hat \\lambda_k = \\frac{N_k + \\alpha_k -1}{\\sum^6_{m=1}(N_m + \\alpha_m - 1)}\\)其中$N_k$代表訓練資料中k出現的次數，這裡注意到如果$\\alpha_k$全部設為1的時候，式子就變成跟 maximum likelihood的解一樣。4.5.3 Bayesian Approach在Bayesian approach中我們計算對於參數的posterior。\\(Pr(\\lambda_1 ... \\lambda_6|x_{1...I}) = \\frac{\\prod^I_{i=1}Pr(x_i|\\lambda_{1...6})Pr(\\lambda_{1...6})}{Pr(x_{1...I})}\\)\\(=\\frac{\\prod^I_{i=1}Cat_{x_i}[\\lambda_{1...6}]Dir_{\\lambda_{1...6}}[\\alpha_{1...6}]}{Pr(x_{1...I})}\\)\\(=\\frac{\\kappa(\\alpha_{1...6}, x_{1...I})Dir_{\\lambda_{1...6}}[\\~\\alpha_{1...6}]}{Pr(x_{1...I})}\\)\\(=Dir_{\\lambda_{1...6}}[\\~\\alpha_{1...6}]\\)其中$~\\alpha_k=N_k+\\alpha_k$。我們再次利用共軛關係，以產生具有與先驗分布相同形式的後驗分布。為了確保左邊的概率分布有效，常數κ必須再次與分母相抵消。Predictive DensityMaximum Likelihood和Maximum a posteriori計算Predictive Density的方式就是把新的資料點代入求出來的參數。注意到如果prior是uniform(也就是$\\alpha_{1…6}=1$)，則MAP和ML會完全一樣，而預測結果會和觀察資料的頻率一樣。對於Bayesian Approach，我們計算每個可能的參數集的預測的加權平均值，其中加權由參數的後驗分布給出。\\(Pr(x^*|x_{1...I})=\\int Pr(x^*|\\lambda_{1...6})Pr(\\lambda_{1...6}|x_{1...I})d\\lambda_{1...6}\\)\\(=\\int Cat_{x^*}[\\lambda_{1...6}]Dir_{\\lambda_{1...6}}[\\~\\alpha_{1...6}]d\\lambda_{1...6}\\)\\(=\\int \\kappa(x^*, \\~\\alpha_{1...6})Dir_{\\lambda_{1...6}}[\\breve\\alpha_{1...6}]d\\lambda_{1...6}\\)\\(=\\kappa(x^*, \\~\\alpha_{1...6})\\)在這裡，我們再次利用共軛關係，得到一個常數乘以一個概率分布，而積分則簡單地等於該常數，因為概率分布的積分為一。\\(Pr(x^*=k|x_{1...I})=\\kappa(x^*, \\~\\alpha_{1...6})=\\frac{N_k+\\alpha_k}{\\sum^6_{j=1}(N_j+\\alpha_j)}\\)再次強調貝葉斯預測密度比 ML/MAP解更不自信。特別是，儘管在訓練數據中從未觀察到$x^*=4$這個值，但它並未將觀察到該值的概率分配為零。這是合理的；僅僅因為在15次觀察中我們並未抽到4這個數字，並不意味著我們將永遠不會看到它。我們可能只是運氣不好。貝葉斯方法將這一點納入考慮，並給予這個類別一個小的概率。CH5 The normal distribution回顧第三章 multivariate normal distribution有兩個參數:平均$\\mu$和變異數$\\Sigma$。Proability density function為:\\(Pr(x) = \\frac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}exp[-0.5(x - \\mu)^T\\Sigma^{-1}(x-\\mu)]\\)或是簡短的\\(Pr(x)=Norm_x[\\mu, \\Sigma]\\)5.1 covariance矩陣的種類covariance矩陣有三種類型 spherical:對角元素全部都是同樣的正數，而且除了對角元素以外都是0 diagonal:對角元素數字不一樣且均為正數，而且除了對角元素以外都是0 full covariances:所有元素都不為0的正數，此外矩陣式對稱的也就是$\\sigma_{12}^2=\\sigma_{21}^2$對於bivariate的情況spherical covariances產生出圓的圖形，Diagonal covariances產生出橢圓的圖形，而且橢圓的主軸和座標軸重疊，Full covariances產生出橢圓但是他的主軸方向可以是任意方向。 如果為 covariance 為 spherical 或 diagonal，則個別的變數均為獨立的，也就是\\(Pr(x_1, x_2) = Pr(x_1)Pr(x_2)\\)5.2 Decomposition of covariance利用幾何的觀點可以Decomposition full covariances matric。想像一下有一個新的座標軸對齊full covariances所產生的橢圓圖形的兩個主軸，在這個新的座標軸上觀察這這個圖形，他的covariance matric就變成diagonal covariance matric。所以用座標轉換的觀點，我們可以得到新坐標軸上的diagonal covariance matric和原作標軸上full covariances matric的關係。其中R為座標旋轉矩陣。\\(\\Sigma_{full}=R^T\\Sigma'_{diag}R\\)拆解過後，$\\Sigma’_{diag}$裡面隱含了varience，也就是在新座標軸上圖形的寬度資訊，因此可以再利用eigen-decomposition得在空間中哪一個方向對圖形比較重要。5.3 Linear transformations of variablesmultivariate normal pdf 經過線性轉換後，依然是一個multivariate normal，而轉換後的multivariate normal他的mean和covarience會和轉換前的multivariate normal有關，也和線性轉換方程式的$y=Ax+b$的係數和常數有關。這個關係讓我麼可以簡化抽樣normal distribitaion的過程。假設想要從mean為$\\mu$和covarianc為$\\Sigma$的normal distribitaion抽樣，首先我們可以先從一個standart normal distribution抽樣一個點(mean $\\mu=0$, covariance $\\Sigma=I$)，接著套用Linear transformations $y=\\Sigma^{1/2}x+\\mu$" }, { "title": "影音串流如何運作的", "url": "/posts/%E5%BD%B1%E9%9F%B3%E4%B8%B2%E6%B5%81%E5%A6%82%E4%BD%95%E9%81%8B%E4%BD%9C%E7%9A%84/", "categories": "", "tags": "", "date": "2023-02-23 11:04:00 +0800", "snippet": "Live Streaming工作流程首先Live Streaming起頭於將大量的影音檔壓縮以便傳送，我們利用encoder將原始影音檔用指定的codec(例如H.264)進行壓縮。經過壓縮後gigabytes大小的資料被縮小成megabytes大小。經過壓縮的資料encoder會把資料放入media container，這動作稱為打包。media container的目的是為了讓其他人知道這些被壓縮的資料是用什麼codec壓縮的。media container另一個重要功能是紀錄用來同步聲音和影像的資訊。常見的media container格式有mp4。被打包過後的資料透過特定的傳輸協議protocol在網路上傳送，常見的協議有RTMP、HLS。參考:https://pjchender.blogspot.com/2019/07/protocol-of-media-video-and-audio.htmlhttps://yarslv.com/codecs-and-containers-explained/#what-is-a-containerhttps://www.wowza.com/blog/complete-guide-to-live-streaming" }, { "title": "Data exploration for Object Detection", "url": "/posts/Data-exploration-for-Object-Detection/", "categories": "深度學習", "tags": "train_model", "date": "2023-02-14 14:45:00 +0800", "snippet": "資料整體的品質首先可以對整個資料集做一個初步的檢查，包含 瀏覽整份資料集 確認沒有嚴重有誤的照片(例如全黑的照片) 確認所有照片都能夠被電腦讀取(以免訓練到一半程式被中斷)照片尺寸和深寬比對於整份資料集，統計所有照片的深寬比和尺寸十分重要，這些將會影響anchor size 和 ratios。通常有三種情況 照片大小和深寬比都一樣: 只需要決定縮放比例 照片大小和深寬比不同但差異不大，深寬比都介於0.7~1.5: 可以non-destructive resize(也就是不改變深寬比的縮放) -&gt; padding 照片大小和深寬比差異很大參考:https://neptune.ai/blog/data-exploration-for-image-segmentation-and-object-detection" }, { "title": "makefile教學", "url": "/posts/makefile%E6%95%99%E5%AD%B8/", "categories": "", "tags": "", "date": "2023-02-05 22:47:00 +0800", "snippet": "Makefiles用途用來決定大型程式需要被重新編譯的部分。第一個範例首先安裝make，並且將下面程式放到名稱為Makefile的檔案裡面。注意Makefile必須要用TAB來縮排而不是用空白鍵。hello:\techo \"Hello, World\"接下來在Makefile所在的資料夾位置下make指令$ makeecho \"Hello, World\"Hello, WorldMakefile語法Makefile是由許多的規則組合而成，每一條則看起來如下targets: prerequisites\tcommand\tcommand\tcommand targets是檔案名稱，用空白建作為分隔。通常每個rule只有一個target command是產生targets的一系列的步驟。command以Tab作為開頭，而不是空白鍵。 prerequisites也是檔案名稱，以空白鍵作為分隔，這些是指令開始製作target前必須存在的檔案，因此這些檔案也可以稱為dependenciesMake基礎元素hello:\techo \"Hello, World\"\techo \"This line will always print, because the file hello does not exist.\"以這個範例來說， 有一個名為hello的target 這個target有兩個command 這個target沒有prerequisites接下來我們執行make hello，由於hello檔不存在，所以下面的指令會被執行。如果hello檔存在，make就不會做任何事。特別注意在這裡hello同時代表target以及檔案，因為通常來說下面的command執行的目的就是要生成target。下面舉一個編譯c語言的例子，首先我們製作一個blah.c檔。 // blah.cint main() { return 0; } 接下來製作另一個Makefile。 blah: cc blah.c -o blah 接下來執行make，因為我們每有在第一個參數指定目標target，所以第一個target會被執行。第一次執行的時blah檔會被生成，如果再執行一次就會出現make: 'blah' is up to date的訊息，因為blah檔已經存在了。但是這有一個問題，如果我們更動blah.c檔案，make並不會重新編譯!!要解決這個問題就必須要增加prerequisite。 blah: blah.c cc blah.c -o blah 我們增加了blah的prerequisite，這時候make就除了檢查blah有沒有存在以外，還會另外去檢查blah.c是不是比blah還新。這裡我們可以看到make是利用系統的時間戳來判定blah.c有沒有被修改過，因此如果修改blah.c之後又把blah.c時間戳改回修改前的時間，那make就會以為blah.c沒有被修改過。 Make cleanclean常用來清除make產生的檔案，但是他並不是make的關鍵字。可以用make clean清除make產生的檔案。我們可以在makefile中編寫clean要清除的檔案。注意clean這個target除非你用make clean指令，不然他不會被執行。some_file: \ttouch some_fileclean:\trm -f some_fileMakefile使用相對路徑rootdir = $(realpath .)https://stackoverflow.com/a/3342259Variables變數Variables只能夠是字串，並且用:=賦值。對make來說單引號跟雙引號並意義，make會把他當成字元來處理。因此賦值的時候不需要加引號。下面範例使用Variablesfiles := file1 file2some_file: $(files)\techo \"Look at this variable: \" $(files)\ttouch some_filefile1:\ttouch file1file2:\ttouch file2clean:\trm -f file1 file2 some_file要引用變數可以用${}或是$()x := dudeall:\techo $(x)\techo ${x}\t# Bad practice, but works\techo $x Targetsall target可以用來依次產生所有需要的target，通常會放在第一個target的位置，如此一來只要下make指令就可以生成所有target。all: one two threeone:\ttouch onetwo:\ttouch twothree:\ttouch threeclean:\trm -f one two three多個target當一個rule有多個target的時候，底下的command就會針對每一個target都跑一次。$@就是一個有target名稱的automatic variable，下面範例就可以用$@看看現在command正在執行的是哪一個targetall: f1.o f2.of1.o f2.o:\techo $@# Equivalent to:# f1.o:#\t echo f1.o# f2.o:#\t echo f2.oAutomatic Variables and Wildcards* 萬用字元在cmake中*和%在cmake中都是萬用字元，但是它們代表的意義不一樣。*最好要包裝在wildcard 萬用字符函式中。否則可能會常陷入下面常見的陷阱。 陷阱: *不能直接在變量定義中使用 陷阱: 當*未匹配任何文件時，它會保持不變（除非在萬用字符函數(wildcard)中運行）。```makefilething_wrong := .o # Don’t do this! ‘’ will not get expandedthing_right := $(wildcard *.o)all: one two three fourFails, because $(thing_wrong) is the string “*.o”one: $(thing_wrong)Stays as *.o if there are no files that match this pattern :(two: *.oWorks as you would expect! In this case, it does nothing.three: $(thing_right)Same as rule threefour: $(wildcard *.o)## % 萬用字元`%`非常有用，但由於它可以在各種情況下使用，因此有些令人困惑。1. 在“匹配”模式下使用時，它會在字符串中匹配一個或多個字符。此匹配稱為stem。2. 在“替換”模式下使用時，它會取出匹配的stem，並將其替換為一個字符串。3. `％`在規則定義和某些特定函數中最常用。## Automatic Variables這裡有完整的[Automatic Variables表](https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html)，下面只介紹常用的```makefilehey: one two\t# Outputs \"hey\", since this is the target name # 印出目前的target\techo $@\t# Outputs all prerequisites newer than the target # 印出所有比target新的prerequisite\techo $?\t# Outputs all prerequisites # 印出所有的prerequisite\techo $^\ttouch heyone:\ttouch onetwo:\ttouch twoclean:\trm -f hey one twoRulesMake的隱藏規則CC CXX CFLAGS CXXFLAGS LDFLAGS LDLIBS這些變數是make的隱藏規則。 CC : 編譯C語言的編譯器; 預設是 cc CXX : 編譯C++語言的編譯器; 預設是 g++ CFLAGS : 給C語言編譯器的額外參數 CXXFLAGS : 給C++語言編譯器的額外參數 CPPFLAGS : 給C/C++編譯器的額外參數 LDFLAGS : 給連結器的額外參數下面範例使用隱藏規則CC = gcc # 使用gcc來編譯C語言CFLAGS = -g # 給gcc的額外參數，開啟debug模式# 隱藏規則 #1: blah會由C連接器產生(即使我們的command沒有呼叫C連接器)# 隱藏規則 #2: blah.o 會由c編譯器產生，因為blah.c存在(即使我們的command沒有呼叫c編譯器)blah: blah.oblah.c:\techo \"int main() { return 0; }\" &gt; blah.cclean:\trm -f blah*Static Pattern Rules他的語法如下targets...: target-pattern: prereq-patterns ... commands這個語法的意思是，如果有一個target符合target-pattern(利用% wildcard)，且它的所有prerequisite都符合prereq-patterns，那麼就會執行commands。例如我們可以改寫下面makefileobjects = foo.o bar.o all.oall: $(objects)# These files compile via implicit rulesfoo.o: foo.cbar.o: bar.call.o: all.call.c:\techo \"int main() { return 0; }\" &gt; all.c%.c:\ttouch $@clean:\trm -f *.c *.o all改寫後如下，可以看到，我們把foo.o bar.o all.o的規則都合併成一個規則$(objects): %.o: %.c。首先foo.o符合%.o，且它的所有prerequisite都符合%.c，因此會執行%.o: %.c的規則。objects = foo.o bar.o all.oall: $(objects)# These files compile via implicit rules# Syntax - targets ...: target-pattern: prereq-patterns ...# In the case of the first target, foo.o, the target-pattern matches foo.o and sets the \"stem\" to be \"foo\".# It then replaces the '%' in prereq-patterns with that stem$(objects): %.o: %.call.c:\techo \"int main() { return 0; }\" &gt; all.c%.c:\ttouch $@clean:\trm -f *.c *.o allStatic Pattern Rules and Filter此外，我們可以使用filter函式來過濾掉不需要的檔案，後面會再講到函式這裡只是先展示如何跟函式搭配使用，在下面的範例我們使用了 .raw 和 .result 這兩個擴展名。obj_files = foo.result bar.o lose.osrc_files = foo.raw bar.c lose.call: $(obj_files)# Note: PHONY is important here. Without it, implicit rules will try to build the executable \"all\", since the prereqs are \".o\" files..PHONY: all # Ex 1: .o files depend on .c files. Though we don't actually make the .o file.$(filter %.o,$(obj_files)): %.o: %.c\t@echo \"target: $@ prereq: $&lt;\"# Ex 2: .result files depend on .raw files. Though we don't actually make the .result file.$(filter %.result,$(obj_files)): %.result: %.raw\t@echo \"target: $@ prereq: $&lt;\" %.c %.raw:\t@echo \"touch $@ prereq: $&lt;\" \ttouch $@clean:\trm -f $(src_files)執行的結果如下，首先執行第一條規則all: $(obj_files)產生第一個target foo.result，並由$(filter %.result,$(obj_files)): %.result: %.raw產生foo.result。foo.result的prerequisitfoo.raw由%.c %.raw:產生。可以看到，我們把foo.result bar.o lose.o的規則都合併成一個規則$(filter %.result,$(obj_files)): %.result: %.raw。首先foo.result符合%.result，且它的所有prerequisite都符合%.raw，因此會執行%.result: %.raw的規則。touch foo.rawtarget: foo.result prereq: foo.rawtouch bar.ctarget: bar.o prereq: bar.ctouch lose.ctarget: lose.o prereq: lose.cPattern Rules我們可以將Pattern Rules視為兩種用法。 自定義的implicit rules # 自訂一個 pattern rule 將每一個.c檔編譯成.o檔%.o : %.c $(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@ 簡化版的static pattern rules # 定義一個沒有 prerequisites 的 pattern rule# 他將會在需要的時候產出一個空白的.c檔%.c: touch $@ 在這裡%代表任意非空白的字串。 Double-Colon RulesDouble-Colon Rules 很少被用到，他允許對同一個target定義多個規則，且這些規則可以是不同的commands。如以下範例all: blahblah::\t@echo \"hello\"blah::\t@echo \"hello again\"他的輸出是hellohello againCommands and execution指令回顯/禁用在預設情況下，make會回顯每一個command，如果你不想要回顯，可以在command前面加上@，如下all: \t@echo \"This make line will not be printed\"\techo \"But this will\"命令執行每一行命令都會在一個新的shell中執行，因此如果你想要在同一個shell中執行，可以使用分號;來連接命令，如下all: \tcd ..\t# The cd above does not affect this line, because each command is effectively run in a new shell\techo `pwd`\t# This cd command affects the next because they are on the same line\tcd ..;echo `pwd`\t# Same as above\tcd ..; \\\techo `pwd`預設shell預設情況下，make會使用/bin/sh來執行命令，如果你想要使用其他的shell，可以使用.SHELL來指定，如下SHELL=/bin/bashcool:\techo \"Hello from bash\"$$符號在Makefile中，$$代表一個$符號，如此一來，我們就可以在Makefile中使用bash或是sh的shell variable。在下面這個例子中特別注一一下 Makefile variables 和 Shell variablesmake_var = I am a make variableall:\t# Same as running \"sh_var='I am a shell variable'; echo $sh_var\" in the shell\tsh_var='I am a shell variable'; echo $$sh_var\t# Same as running \"echo I am a make variable\" in the shell\techo $(make_var)用-k、-i、-進行錯誤處理執行make的時候使用-k參數可以讓make繼續執行，即使其中一個target失敗了。執行make的時候使用-i參數可以讓make忽略所有的錯誤。在command前面加上-可以讓make忽略該command的錯誤，如下one:\t# This error will be printed but ignored, and make will continue to run\t-false\ttouch one打斷或是結束makectrl + c可以打斷或是結束make，他將會刪掉剛生成的target遞迴使用 make為了遞迴調用 Makefile，使用特殊的 $(MAKE) 代替 make，因為它將為您傳遞 make 標誌，並且不會受到這些標誌的影響。當使用 $(MAKE) 來遞迴調用 Makefile 時，它將傳遞先前用於調用 make 的所有標誌和選項，以及在 Makefile 中定義的任何其他變量。這有助於確保在整個項目中使用相同的編譯選項和變量。同時，$(MAKE) 不會受到當前 make 的影響，這可以避免不必要的錯誤和不一致性。new_contents = \"hello:\\n\\ttouch inside_file\"all:\tmkdir -p subdir\tprintf $(new_contents) | sed -e 's/^ //' &gt; subdir/makefile\tcd subdir &amp;&amp; $(MAKE)clean:\trm -rf subdirExport, environments, and recursive make當make執行的時候，他會先把所有環境變數轉換成make的變數，例如下面範例假如我們先在shell設定環境變數shell_env_var。 設定環境並且執行make export shell_env_var='I am an environment variable'; make 執行下面的makefile all: # Print out the Shell variable echo $$shell_env_var # Print out the Make variable echo $(shell_env_var) make的export指令可以把make的變數直接轉換成環境變數 shell_env_var=Shell env var, created inside of Makeexport shell_env_varall: echo $(shell_env_var) echo $$shell_env_var 如此一來當我們在make command呼叫make的時候，就可以利用export指令將變數傳遞給子make程式。下面範例中cooly變數會被傳遞到子資料夾內所執行的make的makefile裡面。這裡可以注意到，cooly變數在all target之前被定義，但是他還是可以被all target使用。new_contents = \"hello:\\n\\techo \\$$(cooly)\"all:\tmkdir -p subdir\tprintf $(new_contents) | sed -e 's/^ //' &gt; subdir/makefile\t@echo \"---MAKEFILE CONTENTS---\"\t@cd subdir &amp;&amp; cat makefile\t@echo \"---END MAKEFILE CONTENTS---\"\tcd subdir &amp;&amp; $(MAKE)# Note that variables and exports. They are set/affected globally.cooly = \"The subdirectory can see me!\"export cooly# This would nullify the line above: unexport coolyclean:\trm -rf subdir .EXPORT_ALL_VARIABLES.EXPORT_ALL_VARIABLES可以直接把所有的make變數都轉換成環境變數```shell.EXPORT_ALL_VARIABLES:new_contents = “hello:\\n\\techo $$(cooly)”cooly = “The subdirectory can see me!”This would nullify the line above: unexport coolyall:\tmkdir -p subdir\tprintf $(new_contents) | sed -e ‘s/^ //’ &gt; subdir/makefile\t@echo “—MAKEFILE CONTENTS—”\t@cd subdir &amp;&amp; cat makefile\t@echo “—END MAKEFILE CONTENTS—”\tcd subdir &amp;&amp; $(MAKE)clean:\trm -rf subdir## make的命令列選項[這裡有make的命令列選項](https://www.gnu.org/software/make/manual/make.html#Options-Summary)，可以注意`--dry-run`, `--touch`, `--old-file`這幾個。另外make可以一次接受多個target，例如`make clean run test`就會先執行clean，接著run和test。# 變數part2## 兩種賦值方法* 延遲賦值（lazy evaluation）`=`: ```bashVAR = fooVAR2 = $(VAR)VAR = barall:\t# 在此處 VAR2 的值將是 \"bar\"，因為VAR2直到被真正使用展開\techo $(VAR2)?=這個符號可以為沒被設定過的店數設定值one = helloone ?= will not be set #one被設定過了，所以沒作用two ?= will be set #two還沒被設定做，將設定值all: \techo $(one)\techo $(two)輸出如下echo hellohelloecho will be setwill be set 立即賦值（immediate assignment）:=:```bashVAR := fooVAR2 := $(VAR)VAR := barall:\t# 在此處 VAR2 的值將是 “foo”，因為VAR2在:=的時候就展開了\techo $(VAR2)因此`:=`可以append variable，如果是`=`就會齣戲無窮迴圈錯誤```makefileone = hello# 這段程式可以運行# one gets defined as a simply expanded variable (:=) and thus can handle appendingone := ${one} thereall: \techo $(one)下面這段程式會出現無窮迴圈錯誤。one = hello# 注意這裡用的是 = ,會造成無窮迴圈錯誤one = ${one} thereall: \techo $(one)空白一行字起頭的空白會被make忽略掉，但是尾巴空白的不會，要在起頭加空白可以用$(nullstring)，更精確地說其實未定義的變數都是empty stringwith_spaces = hello # with_spaces has many spaces after \"hello\"after = $(with_spaces)therestart_space = $(nullstring) helloall: \techo \"$(after)\"\techo \"$(start_space)\" echo $(nowhere) #這也會輸出empty stringappend+=可以用來append variablefoo := startfoo += moreall: \techo $(foo)覆寫make命列列參數override可以用來覆寫make命令列參數，例如下面這個例子，分別用make option_one=hi和make option_two=hi去執行，可以發現只有option_one會被覆寫# Overrides command line argumentsoverride option_one = did_override# Does not override command line argumentsoption_two = not_overrideall: \techo $(option_one)\techo $(option_two)針對target設定變數變數可以只設定給指定的target，例如下面例子，one只定義給all targetall: one = coolall: \techo one is defined: $(one)other:\techo one is nothing: $(one)Pattern-specific variables變數也可以指定義給特定的target patterns，例如下面例子，只有符合%.cpattern的target會被定義one%.c: one = coolblah.c: \techo one is defined: $(one)other:\techo one is nothing: $(one)Makefile判斷式if/elsefoo = okall:ifeq ($(foo), ok)\techo \"foo equals ok\"else\techo \"nope\"endif檢查變數是否為空nullstring =foo = $(nullstring) # end of line; there is a space hereall:ifeq ($(strip $(foo)),)\techo \"foo is empty after being stripped\"endififeq ($(nullstring),)\techo \"nullstring doesn't even have spaces\"endif檢查變數是否被定義bar =foo = $(bar)all:ifdef foo\techo \"foo is defined\"endififndef bar\techo \"but bar is not\"endif$(MAKEFLAGS)下面範例展示如何使用 findstring 和 MAKEFLAGS 測試 make flag。分別用make指令和make -i指令執行下面makefileall:# Search for the \"-i\" flag. MAKEFLAGS is just a list of single characters, one per flag. So look for \"i\" in this case.ifneq (,$(findstring i, $(MAKEFLAGS)))\techo \"i was passed to MAKEFLAGS\"endifFunctionsFirst Functions函式主要用來處理文字。呼叫函式的方法有$(fn, arguments)或${fn, arguments}，而make也內建許多函式。例如subst替換掉文字。bar := ${subst not, totally, \"I am not superman\"}all: \t@echo $(bar)而如果你相替換掉空白或是逗號，可以利用變數。comma := ,empty:=space := $(empty) $(empty)foo := a b cbar := $(subst $(space),$(comma),$(foo))all: \t@echo $(bar)特別注意到不要在逗號和下一個參數之間留空白，因為它會被視為文字。comma := ,empty:=space := $(empty) $(empty)foo := a b cbar := $(subst $(space), $(comma) , $(foo))all: \t# Output is \", a , b , c\". Notice the spaces introduced\t@echo $(bar)字串替換函式$(patsubst pattern,replacement,text)的功能如下。foo := a.o b.o l.a c.oone := $(patsubst %.o,%.c,$(foo))# This is a shorthand for the abovetwo := $(foo:%.o=%.c)# This is the suffix-only shorthand, and is also equivalent to the above.three := $(foo:.o=.c)all:\techo $(one)\techo $(two)\techo $(three)The foreach functionforeach函式的用法為$(foreach var,list,text)，foreach會把以空白間區隔文字的list一個一個賦值給var，而text會累加前面的結果，範例如下foo := who are you# For each \"word\" in foo, output that same word with an exclamation afterbar := $(foreach wrd,$(foo),$(wrd)!)all:\t# Output is \"who! are! you!\"\t@echo $(bar)if function用法如下foo := $(if this-is-not-empty,then!,else!)empty :=bar := $(if $(empty),then!,else!)all:\t@echo $(foo)\t@echo $(bar)The call functionmake可以用call來呼叫自定義函式sweet_new_fn = Variable Name: $(0) First: $(1) Second: $(2) Empty Variable: $(3)all:\t# Outputs \"Variable Name: sweet_new_fn First: go Second: tigers Empty Variable:\"\t@echo $(call sweet_new_fn, go, tigers)The shell functionmake也可以呼叫shell函式，但是會把輸出的換行符號改成空白鍵其他功能Include Makefiles使用Include可以讓makefile裡面呼叫其他makefilevpath 指令vpath %.h ../headers ../other-directory# Note: vpath allows blah.h to be found even though blah.h is never in the current directorysome_binary: ../headers blah.h\ttouch some_binary../headers:\tmkdir ../headers# We call the target blah.h instead of ../headers/blah.h, because that's the prereq that some_binary is looking for# Typically, blah.h would already exist and you wouldn't need this.blah.h:\ttouch ../headers/blah.hclean:\trm -rf ../headers\trm -f some_binary換行指令太長可以利用\\換行some_file: \techo This line is too long, so \\\t\tit is broken up into multiple lines.phony在目標中添加”.PHONY”將防止Make將虛擬目標與文件名混淆。在這個例子中，如果創建了名為”clean”的文件，”make clean”仍然會運行。從技術上講，我應該在每個帶有”all”或”clean”的例子中都使用它，但為了保持例子的清晰，我沒有這樣做。此外，”phony”目標通常具有很少用作文件名的名稱，在實踐中許多人都會跳過這一步。some_file:\ttouch some_file\ttouch clean.PHONY: cleanclean:\trm -f some_file\trm -f clean.delete_on_error如果命令返回非零的退出狀態，make工具將停止運行規則（並將向前傳播到前置要求）。DELETE_ON_ERROR將在規則以這種方式失敗時刪除該規則的目標。這將對所有目標發生，不僅僅是像PHONY這樣的目標。儘管由於歷史原因，make工具沒有使用這個選項，但始終使用它是一個好主意。.DELETE_ON_ERROR:all: one twoone:\ttouch one\tfalsetwo:\ttouch two\tfalse" }, { "title": "Ubuntu設定VNC遠端桌面", "url": "/posts/ubuntu%E8%A8%AD%E5%AE%9Avnc%E9%81%A0%E7%AB%AF%E6%A1%8C%E9%9D%A2/", "categories": "", "tags": "", "date": "2023-02-02 22:25:00 +0800", "snippet": "VNC使用ubuntu桌面https://bytexd.com/how-to-install-configure-vnc-server-on-ubuntu/#google_vignetteVNC操作指令http://kito.wikidot.com/vnc清乾淨apt packagehttps://askubuntu.com/questions/187888/what-is-the-correct-way-to-completely-remove-an-application刪除並重啟vnc servervncserver -kill :1vncserver -localhost no :1參考:https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-vnc-on-ubuntu-20-04" }, { "title": "deepstream教學", "url": "/posts/deepstream%E6%95%99%E5%AD%B8/", "categories": "深度學習工具", "tags": "deepstream", "date": "2023-01-11 12:28:00 +0800", "snippet": "客製化模型實作nvinfer介面nvinfer呼叫介面任何客製化介面最終必須被編譯成一個獨立的shared library。nvinfer在執行期間利用dlopen()呼叫函式庫，並且利用dlsym()呼叫函式庫中的函式。進一步的資訊紀錄在nvdsinfer_custom_impl.h裡面https://docs.nvidia.com/metropolis/deepstream/sdk-api/nvdsinfer__custom__impl_8h.html客製化Output Parsing 對於detectors使用者必須自行解析模型的輸出並且將之轉化成bounding box 座標和物件類別。對於classifiers則是必須自行解析出物件屬性。範例在/opt/nvidia/deepstream/deepstream/sources/libs/nvdsinfer_customparser，裡面的README有關於使用custom parser的說明。 客製化parsing function必須為NvDsInferParseCustomFunc型態。在nvdsinfer_custom_impl.h的221行可以看到下面的型態定義，代表每一個客製化的解析函式都必須符合這個格式```c/** Type definition for the custom bounding box parsing function. * @param[in] outputLayersInfo A vector containing information on the output layers of the model. @param[in] networkInfo Network information. @param[in] detectionParams Detection parameters required for parsing objects. @param[out] objectList A reference to a vector in which the function is to add parsed objects. /typedef bool ( NvDsInferParseCustomFunc) ( std::vector const &amp;outputLayersInfo, NvDsInferNetworkInfo const &amp;networkInfo, NvDsInferParseDetectionParams const &amp;detectionParams, std::vector &amp;objectList);``` 客製化parsing function可以在Gst-nvinfer的參數檔parse-bbox-func-name和custom-lib-name屬性指定。例如我們定義了Yolov2-tiny的客製化bounding box解析函式NvDsInferParseCustomYoloV2Tiny，編譯出來的shared library位於nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so，我們在設定檔就就必須要有以下設定 parse-bbox-func-name=NvDsInferParseCustomYoloV2Tinycustom-lib-path=nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so 可以藉由在定義函式後呼叫CHECK_CUSTOM_PARSE_FUNC_PROTOTYPE()marco來驗證函式的定義。使用範例如下extern \"C\" bool NvDsInferParseCustomYoloV2Tiny( std::vector&lt;NvDsInferLayerInfo&gt; const&amp; outputLayersInfo, NvDsInferNetworkInfo const&amp; networkInfo, NvDsInferParseDetectionParams const&amp; detectionParams, std::vector&lt;NvDsInferParseObjectInfo&gt;&amp; objectList){ ...}CHECK_CUSTOM_PARSE_FUNC_PROTOTYPE(NvDsInferParseCustomYoloV2Tiny);https://forums.developer.nvidia.com/t/deepstreamsdk-4-0-1-custom-yolov3-tiny-error/108391?u=jenhaoIPlugin Implementation對於TensorRT不支援的network layer，Deepstream提供IPlugin interface來客製化處理。在/opt/nvidia/deepstream/deepstream/sources底下的objectDetector_SSD, objectDetector_FasterRCNN, 和 objectDetector_YoloV3資料夾展示了如何使用custom layers。在objectDetector_YoloV3範例中我們可以看到如何製作Tensorrt不支援的Yolov3的yolo layer。可以在yolo.cpp中看到自定義的layer是如何被呼叫使用的，程式節錄如下。....else if (m_ConfigBlocks.at(i).at(\"type\") == \"yolo\") { nvinfer1::Dims prevTensorDims = previous-&gt;getDimensions(); assert(prevTensorDims.d[1] == prevTensorDims.d[2]); TensorInfo&amp; curYoloTensor = m_OutputTensors.at(outputTensorCount); curYoloTensor.gridSize = prevTensorDims.d[1]; curYoloTensor.stride = m_InputW / curYoloTensor.gridSize; m_OutputTensors.at(outputTensorCount).volume = curYoloTensor.gridSize * curYoloTensor.gridSize * (curYoloTensor.numBBoxes * (5 + curYoloTensor.numClasses)); std::string layerName = \"yolo_\" + std::to_string(i); curYoloTensor.blobName = layerName; nvinfer1::IPluginV2* yoloPlugin = new YoloLayerV3(m_OutputTensors.at(outputTensorCount).numBBoxes, m_OutputTensors.at(outputTensorCount).numClasses, m_OutputTensors.at(outputTensorCount).gridSize); assert(yoloPlugin != nullptr); nvinfer1::IPluginV2Layer* yolo = network.addPluginV2(&amp;previous, 1, *yoloPlugin); assert(yolo != nullptr); yolo-&gt;setName(layerName.c_str()); std::string inputVol = dimsToString(previous-&gt;getDimensions()); previous = yolo-&gt;getOutput(0); assert(previous != nullptr); previous-&gt;setName(layerName.c_str()); std::string outputVol = dimsToString(previous-&gt;getDimensions()); network.markOutput(*previous); channels = getNumChannels(previous); tensorOutputs.push_back(yolo-&gt;getOutput(0)); printLayerInfo(layerIndex, \"yolo\", inputVol, outputVol, std::to_string(weightPtr)); ++outputTensorCount; }...而其他版本的YOLO，Nvidia也已經幫我們建立好許多Plugin，例如yolov2的region layer，Nvidia已經幫我們建立，其他已經建立好的layer可以在這裡找到。https://github.com/NVIDIA/TensorRT/tree/1c0e3fdd039c92e584430a2ed91b4e2612e375b8/plugin畫出範例的結構圖首先在~/.bashrc加入下面這行設定pipeline圖儲存的位置，注意GStreamer不會幫你建立資料夾，你必須確認資料夾存在export GST_DEBUG_DUMP_DOT_DIR=/tmp接下來在pipeline 狀態設為PLAYING之前加入下面這行程式GST_DEBUG_BIN_TO_DOT_FILE(pipeline, GST_DEBUG_GRAPH_SHOW_ALL, \"dstest1-pipeline\");最後執行程式後就會產生.dot在前面設定的資料夾，你可以下載Graphviz，或是用VScode的插件來看圖Deepstream 說明書https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvdsxfer.htmlgst-launch-1.0建立rtsp輸入源的pipeline首先先用gst-launch-1.0建立一個簡單的rtsp輸入、螢幕輸出的pipelinegst-launch-1.0 rtspsrc location='rtsp://192.168.1.10:554/user=admin_password=xxxxxx_channel=1_stream=0.sdp' ! rtph264depay ! h264parse ! nvv4l2decoder ! nvvideoconvert ! video/x-raw,format=BGRx ! videoconvert ! video/x-raw,format=BGR ! autovideosink將python的範例程式轉成c++https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/tree/master/apps/deepstream-rtsp-in-rtsp-out建立mjpeg串流 指令方式 gst-launch-1.0 -v rtspsrc location=\"rtsp://&lt;rtsp url&gt;/live1.sdp\" \\! rtph264depay ! avdec_h264 \\! timeoverlay halignment=right valignment=bottom \\! videorate ! video/x-raw,framerate=37000/1001 ! jpegenc ! multifilesink location=\"snapshot.jpeg\" https://stackoverflow.com/questions/59885450/jpeg-live-stream-in-html-slow 查詢deepstream bin的說明gst-inspect-1.0 nvurisrcbingst-launch-1.0輸出除錯訊息到檔案參考:https://www.cnblogs.com/xleng/p/12228720.htmlGST_DEBUG_NO_COLOR=1 GST_DEBUG_FILE=pipeline.log GST_DEBUG=5 gst-launch-1.0 -v rtspsrc location=\"rtsp://192.168.8.19/live.sdp\" user-id=\"root\" user-pw=\"3edc\\$RFV\" ! rtph264depay ! avdec_h264 ! timeoverlay halignment=right valignment=bottom ! videorate ! video/x-raw,framerate=37000/1001 ! jpegenc ! multifilesink location=\"snapshot.jpeg\"參考:https://gstreamer.freedesktop.org/documentation/tutorials/basic/debugging-tools.html?gi-language=chttps://embeddedartistry.com/blog/2018/02/22/generating-gstreamer-pipeline-graphs/本地端觀看udp傳送影像host設為本機ip或127.0.0.1send:gst-launch-1.0 -v videotestsrc ! x264enc tune=zerolatency bitrate=500 speed-preset=superfast ! rtph264pay ! udpsink port=5000 host=$HOSTreceive:gst-launch-1.0 -v udpsrc port=5000 ! \"application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96\" ! rtph264depay ! h264parse ! avdec_h264 ! videoconvert ! autovideosinkGlibs說明書http://irtfweb.ifa.hawaii.edu/SoftwareDocs/gtk20/glib/glib-hash-tables.html#g-int-hashGDB文字圖形介面https://blog.louie.lu/2016/09/12/gdb-%E9%8C%A6%E5%9B%8A%E5%A6%99%E8%A8%88/範例https://gist.github.com/liviaerxin/bb34725037fd04afa76ef9252c2ee875#tips-for-debugrtsp 元件nvrtspoutsinkbinnvrtspoutsinkbin沒有說明書，只能用gst-inspect-1.0看https://forums.developer.nvidia.com/t/where-can-fine-nvrtspoutsinkbin-info/199124範例/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream_reference_apps/deepstream-bodypose-3d/sources/deepstream_pose_estimation_app.cpp /* Create RTSP output bin */ rtsp_out_bin = gst_element_factory_make (\"nvrtspoutsinkbin\", \"nvrtsp-renderer\"); if (!rtsp_out_bin) { g_printerr (\"Failed to create RTSP output elements. Exiting.\\n\"); return -1; } g_object_set (G_OBJECT (rtsp_out_bin), \"sync\", TRUE, NULL); g_object_set (G_OBJECT (rtsp_out_bin), \"bitrate\", 768000, NULL); g_object_set (G_OBJECT (rtsp_out_bin), \"rtsp-port\", rtsp_port_num, NULL); g_object_set (G_OBJECT (rtsp_out_bin), \"enc-type\", enc_type, NULL); gst_bin_add_many (GST_BIN (pipeline), rtsp_out_bin, NULL);取得source idhttps://forums.developer.nvidia.com/t/how-to-get-sources-index-in-deepstream/244461 可以用prob取得meta datadeepstream_test3_app.c 有範例probe使用範例 切換輸入源https://forums.developer.nvidia.com/t/how-switch-camera-output-gst-nvmultistreamtiler/233062tiler_sink_pad.add_probe(Gst.PadProbeType.BUFFER, tiler_sink_pad_buffer_probe, 0)tiler.set_property(\"show-source\", &lt;stream_id&gt;) `/opt/nvidia/deepstream/deepstream/sources/apps/apps-common/src/deepstream-yaml/deepstream_source_yaml.cpp有範例斷線重連rust的插件(可能可以編譯成c函式庫)https://coaxion.net/blog/2020/07/automatic-retry-on-error-and-fallback-stream-handling-for-gstreamer-sources/https://gitlab.freedesktop.org/gstreamer/gst-plugins-rs/-/tree/master/utils/fallbackswitch編譯rust插件https://www.collabora.com/news-and-blog/blog/2020/06/23/cross-building-rust-gstreamer-plugins-for-the-raspberry-pi/RUST說明書https://rust-lang.tw/book-tw/ch01-03-hello-cargo.html截出有物件的圖https://forums.developer.nvidia.com/t/saving-frame-with-detected-object-jetson-nano-ds4-0-2/121797/3關閉Ubuntu圖形介面https://linuxconfig.org/how-to-disable-enable-gui-on-boot-in-ubuntu-20-04-focal-fossa-linux-desktop關閉使用gpu的資源https://heary.cn/posts/Linux环境下重装NVIDIA驱动报错kernel-module-nvidia-modeset-in-use问题分析/發現nvidia smi persistence mode會占用GPU資源，必須釋放掉才能安裝新的driver可以用nvidia-smi的指令關掉https://docs.nvidia.com/deploy/driver-persistence/index.html#usagenvidia-smi -pm 0移除舊的driverapt-get remove --purge nvidia-driver-520apt-get autoremovequeue的用途https://docs.xilinx.com/r/en-US/ug1449-multimedia/Performance-Improvement-from-the-GStreamer-Perspectiveprobehttps://coaxion.net/blog/2014/01/gstreamer-dynamic-pipelines/https://erit-lvx.medium.com/probes-handling-in-gstreamer-pipelines-3f96ea367f31deepstream-test4 用prob取得metadata的範例NvDsBatchMeta資料圖:https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_metadata.htmlstatic GstPadProbeReturnosd_sink_pad_buffer_probe (GstPad * pad, GstPadProbeInfo * info, gpointer u_data){ GstBuffer *buf = (GstBuffer *) info-&gt;data; NvDsFrameMeta *frame_meta = NULL; NvOSD_TextParams *txt_params = NULL; guint vehicle_count = 0; guint person_count = 0; gboolean is_first_object = TRUE; NvDsMetaList *l_frame, *l_obj; NvDsBatchMeta *batch_meta = gst_buffer_get_nvds_batch_meta (buf); if (!batch_meta) { // No batch meta attached. return GST_PAD_PROBE_OK; } //batch_meta : NvDsBatchMeta https://docs.nvidia.com/metropolis/deepstream/sdk-api/struct__NvDsBatchMeta.html // //l_frame : NvDsFrameMetaList, 本質是GList http://irtfweb.ifa.hawaii.edu/SoftwareDocs/gtk20/glib/glib-doubly-linked-lists.html#GList // struct GList // { // gpointer data; // GList *next; // GList *prev; // }; for (l_frame = batch_meta-&gt;frame_meta_list; l_frame; l_frame = l_frame-&gt;next) { frame_meta = (NvDsFrameMeta *) l_frame-&gt;data; if (frame_meta == NULL) { // Ignore Null frame meta. continue; } is_first_object = TRUE; // frame_meta : NvDsFrameMeta https://docs.nvidia.com/metropolis/deepstream/sdk-api/struct__NvDsFrameMeta.html // l_obj : NvDsObjectMetaList * 本質是GList // obj_meta : NvDsObjectMeta for (l_obj = frame_meta-&gt;obj_meta_list; l_obj; l_obj = l_obj-&gt;next) { NvDsObjectMeta *obj_meta = (NvDsObjectMeta *) l_obj-&gt;data; if (obj_meta == NULL) { // Ignore Null object. continue; } // obj_meta : NvDsObjectMeta // text_params : NvOSD_TextParams 描述物件的文字 // line233 - 241應該是清掉原本的文字然後放入字定義的class名稱 txt_params = &amp;(obj_meta-&gt;text_params); if (txt_params-&gt;display_text) g_free (txt_params-&gt;display_text); txt_params-&gt;display_text = g_malloc0 (MAX_DISPLAY_LEN); g_snprintf (txt_params-&gt;display_text, MAX_DISPLAY_LEN, \"%s \", pgie_classes_str[obj_meta-&gt;class_id]); if (obj_meta-&gt;class_id == PGIE_CLASS_ID_VEHICLE) vehicle_count++; if (obj_meta-&gt;class_id == PGIE_CLASS_ID_PERSON) person_count++; /* Now set the offsets where the string should appear */ txt_params-&gt;x_offset = obj_meta-&gt;rect_params.left; txt_params-&gt;y_offset = obj_meta-&gt;rect_params.top - 25; /* Font , font-color and font-size */ txt_params-&gt;font_params.font_name = \"Serif\"; txt_params-&gt;font_params.font_size = 10; txt_params-&gt;font_params.font_color.red = 1.0; txt_params-&gt;font_params.font_color.green = 1.0; txt_params-&gt;font_params.font_color.blue = 1.0; txt_params-&gt;font_params.font_color.alpha = 1.0; /* Text background color */ txt_params-&gt;set_bg_clr = 1; txt_params-&gt;text_bg_clr.red = 0.0; txt_params-&gt;text_bg_clr.green = 0.0; txt_params-&gt;text_bg_clr.blue = 0.0; txt_params-&gt;text_bg_clr.alpha = 1.0; /* * Ideally NVDS_EVENT_MSG_META should be attached to buffer by the * component implementing detection / recognition logic. * Here it demonstrates how to use / attach that meta data. */ if (is_first_object &amp;&amp; !(frame_number % frame_interval)) { /* Frequency of messages to be send will be based on use case. * Here message is being sent for first object every frame_interval(default=30). */ NvDsEventMsgMeta *msg_meta = (NvDsEventMsgMeta *) g_malloc0 (sizeof (NvDsEventMsgMeta)); msg_meta-&gt;bbox.top = obj_meta-&gt;rect_params.top; msg_meta-&gt;bbox.left = obj_meta-&gt;rect_params.left; msg_meta-&gt;bbox.width = obj_meta-&gt;rect_params.width; msg_meta-&gt;bbox.height = obj_meta-&gt;rect_params.height; msg_meta-&gt;frameId = frame_number; msg_meta-&gt;trackingId = obj_meta-&gt;object_id; msg_meta-&gt;confidence = obj_meta-&gt;confidence; generate_event_msg_meta (msg_meta, obj_meta-&gt;class_id, obj_meta); // 要增加自訂的meta data必須要先用 nvds_acquire_user_meta_from_pool (batch_meta);取得 // https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_metadata.html#user-custom-metadata-addition-inside-nvdsbatchmeta NvDsUserMeta *user_event_meta = nvds_acquire_user_meta_from_pool (batch_meta); if (user_event_meta) { user_event_meta-&gt;user_meta_data = (void *) msg_meta; user_event_meta-&gt;base_meta.meta_type = NVDS_EVENT_MSG_META; user_event_meta-&gt;base_meta.copy_func = (NvDsMetaCopyFunc) meta_copy_func; user_event_meta-&gt;base_meta.release_func = (NvDsMetaReleaseFunc) meta_free_func; nvds_add_user_meta_to_frame (frame_meta, user_event_meta); } else { g_print (\"Error in attaching event meta to buffer\\n\"); } is_first_object = FALSE; } } } g_print (\"Frame Number = %d \" \"Vehicle Count = %d Person Count = %d\\n\", frame_number, vehicle_count, person_count); frame_number++; return GST_PAD_PROBE_OK;}注意element的名稱不要一樣以免出錯NvDsObjEncUsrArgs參數的功用 bool \tisFrame : 告訴encoder要編碼整張照片還是編碼每一個偵測物件的截圖。 1: Encodes the entire frame. 0: Encodes object of specified resolution. bool \tsaveImg : 會直接儲存一張照片到當前資料夾 bool \tattachUsrMeta : 決定是否加上NVDS_CROP_IMAGE_META metadata Deepstream截圖，以deepstream_image_meta_test為例注意:根據文件nvds_obj_enc_process是一個非阻塞的函式，使用者必須呼叫nvds_obj_enc_finish()以確保所有的圖片都已經確實被處理完成。第一步，設定要儲存照片的條件並且encode成jpg檔/* pgie_src_pad_buffer_probe will extract metadata received on pgie src pad * and update params for drawing rectangle, object information etc. We also * iterate through the object list and encode the cropped objects as jpeg * images and attach it as user meta to the respective objects.*/static GstPadProbeReturnpgie_src_pad_buffer_probe (GstPad * pad, GstPadProbeInfo * info, gpointer ctx){ GstBuffer *buf = (GstBuffer *) info-&gt;data; GstMapInfo inmap = GST_MAP_INFO_INIT; if (!gst_buffer_map (buf, &amp;inmap, GST_MAP_READ)) { GST_ERROR (\"input buffer mapinfo failed\"); return GST_PAD_PROBE_DROP; } NvBufSurface *ip_surf = (NvBufSurface *) inmap.data; gst_buffer_unmap (buf, &amp;inmap); NvDsObjectMeta *obj_meta = NULL; guint vehicle_count = 0; guint person_count = 0; NvDsMetaList *l_frame = NULL; NvDsMetaList *l_obj = NULL; NvDsBatchMeta *batch_meta = gst_buffer_get_nvds_batch_meta (buf); for (l_frame = batch_meta-&gt;frame_meta_list; l_frame != NULL; l_frame = l_frame-&gt;next) { NvDsFrameMeta *frame_meta = (NvDsFrameMeta *) (l_frame-&gt;data); /* For demonstration purposes, we will encode the first 10 frames. */ if(frame_count &lt;= 10) { NvDsObjEncUsrArgs frameData = { 0 }; /* Preset */ frameData.isFrame = 1; /* To be set by user */ frameData.saveImg = save_img; frameData.attachUsrMeta = attach_user_meta; /* Set if Image scaling Required */ frameData.scaleImg = FALSE; frameData.scaledWidth = 0; frameData.scaledHeight = 0; /* Quality */ frameData.quality = 80; /* Main Function Call */ nvds_obj_enc_process (ctx, &amp;frameData, ip_surf, NULL, frame_meta); } guint num_rects = 0; for (l_obj = frame_meta-&gt;obj_meta_list; l_obj != NULL; l_obj = l_obj-&gt;next) { obj_meta = (NvDsObjectMeta *) (l_obj-&gt;data); if (obj_meta-&gt;class_id == PGIE_CLASS_ID_VEHICLE) { vehicle_count++; num_rects++; } if (obj_meta-&gt;class_id == PGIE_CLASS_ID_PERSON) { person_count++; num_rects++; } /* Conditions that user needs to set to encode the detected objects of * interest. Here, by default all the detected objects are encoded. * For demonstration, we will encode the first object in the frame. */ if ((obj_meta-&gt;class_id == PGIE_CLASS_ID_PERSON || obj_meta-&gt;class_id == PGIE_CLASS_ID_VEHICLE) &amp;&amp; num_rects == 1) { NvDsObjEncUsrArgs objData = { 0 }; /* To be set by user */ objData.saveImg = save_img; objData.attachUsrMeta = attach_user_meta; /* Set if Image scaling Required */ objData.scaleImg = FALSE; objData.scaledWidth = 0; objData.scaledHeight = 0; /* Preset */ objData.objNum = num_rects; /* Quality */ objData.quality = 80; /*Main Function Call */ nvds_obj_enc_process (ctx, &amp;objData, ip_surf, obj_meta, frame_meta); } } } nvds_obj_enc_finish (ctx); frame_count++; return GST_PAD_PROBE_OK;}第二步，檢查usrMetaData是否的meta_type是不是NVDS_CROP_IMAGE_META如果發現是NVDS_CROP_IMAGE_META，就儲存照片/* osd_sink_pad_buffer_probe will extract metadata received on OSD sink pad * and update params for drawing rectangle, object information. We also iterate * through the user meta of type \"NVDS_CROP_IMAGE_META\" to find image crop meta * and demonstrate how to access it.*/static GstPadProbeReturnosd_sink_pad_buffer_probe (GstPad * pad, GstPadProbeInfo * info, gpointer u_data){ GstBuffer *buf = (GstBuffer *) info-&gt;data; guint num_rects = 0; NvDsObjectMeta *obj_meta = NULL; guint vehicle_count = 0; guint person_count = 0; NvDsMetaList *l_frame = NULL; NvDsMetaList *l_obj = NULL; NvDsDisplayMeta *display_meta = NULL; NvDsBatchMeta *batch_meta = gst_buffer_get_nvds_batch_meta (buf); g_print (\"Running osd_sink_pad_buffer_probe...\\n\"); for (l_frame = batch_meta-&gt;frame_meta_list; l_frame != NULL; l_frame = l_frame-&gt;next) { NvDsFrameMeta *frame_meta = (NvDsFrameMeta *) (l_frame-&gt;data); int offset = 0; /* To verify encoded metadata of cropped frames, we iterate through the * user metadata of each frame and if a metadata of the type * 'NVDS_CROP_IMAGE_META' is found then we write that to a file as * implemented below. */ char fileFrameNameString[FILE_NAME_SIZE]; const char *osd_string = \"OSD\"; /* For Demonstration Purposes we are writing metadata to jpeg images of * the first 10 frames only. * The files generated have an 'OSD' prefix. */ if (frame_number &lt; 11) { NvDsUserMetaList *usrMetaList = frame_meta-&gt;frame_user_meta_list; FILE *file; int stream_num = 0; while (usrMetaList != NULL) { NvDsUserMeta *usrMetaData = (NvDsUserMeta *) usrMetaList-&gt;data; if (usrMetaData-&gt;base_meta.meta_type == NVDS_CROP_IMAGE_META) { snprintf (fileFrameNameString, FILE_NAME_SIZE, \"%s_frame_%d_%d.jpg\", osd_string, frame_number, stream_num++); NvDsObjEncOutParams *enc_jpeg_image = (NvDsObjEncOutParams *) usrMetaData-&gt;user_meta_data; /* Write to File */ file = fopen (fileFrameNameString, \"wb\"); fwrite (enc_jpeg_image-&gt;outBuffer, sizeof (uint8_t), enc_jpeg_image-&gt;outLen, file); fclose (file); } usrMetaList = usrMetaList-&gt;next; } } for (l_obj = frame_meta-&gt;obj_meta_list; l_obj != NULL; l_obj = l_obj-&gt;next) { obj_meta = (NvDsObjectMeta *) (l_obj-&gt;data); if (obj_meta-&gt;class_id == PGIE_CLASS_ID_VEHICLE) { vehicle_count++; num_rects++; } if (obj_meta-&gt;class_id == PGIE_CLASS_ID_PERSON) { person_count++; num_rects++; } /* To verify encoded metadata of cropped objects, we iterate through the * user metadata of each object and if a metadata of the type * 'NVDS_CROP_IMAGE_META' is found then we write that to a file as * implemented below. */ char fileObjNameString[FILE_NAME_SIZE]; /* For Demonstration Purposes we are writing metadata to jpeg images of * vehicles or persons for the first 100 frames only. * The files generated have a 'OSD' prefix. */ if (frame_number &lt; 100 &amp;&amp; (obj_meta-&gt;class_id == PGIE_CLASS_ID_PERSON || obj_meta-&gt;class_id == PGIE_CLASS_ID_VEHICLE)) { NvDsUserMetaList *usrMetaList = obj_meta-&gt;obj_user_meta_list; FILE *file; while (usrMetaList != NULL) { NvDsUserMeta *usrMetaData = (NvDsUserMeta *) usrMetaList-&gt;data; if (usrMetaData-&gt;base_meta.meta_type == NVDS_CROP_IMAGE_META) { NvDsObjEncOutParams *enc_jpeg_image = (NvDsObjEncOutParams *) usrMetaData-&gt;user_meta_data; snprintf (fileObjNameString, FILE_NAME_SIZE, \"%s_%d_%d_%d_%s.jpg\", osd_string, frame_number, frame_meta-&gt;batch_id, num_rects, obj_meta-&gt;obj_label); /* Write to File */ file = fopen (fileObjNameString, \"wb\"); fwrite (enc_jpeg_image-&gt;outBuffer, sizeof (uint8_t), enc_jpeg_image-&gt;outLen, file); fclose (file); usrMetaList = NULL; } else { usrMetaList = usrMetaList-&gt;next; } } } } display_meta = nvds_acquire_display_meta_from_pool (batch_meta); NvOSD_TextParams *txt_params = &amp;display_meta-&gt;text_params[0]; txt_params-&gt;display_text = g_malloc0 (MAX_DISPLAY_LEN); offset = snprintf (txt_params-&gt;display_text, MAX_DISPLAY_LEN, \"Person = %d \", person_count); offset = snprintf (txt_params-&gt;display_text + offset, MAX_DISPLAY_LEN, \"Vehicle = %d \", vehicle_count); /* Now set the offsets where the string should appear */ txt_params-&gt;x_offset = 10; txt_params-&gt;y_offset = 12; /* Font , font-color and font-size */ txt_params-&gt;font_params.font_name = \"Serif\"; txt_params-&gt;font_params.font_size = 10; txt_params-&gt;font_params.font_color.red = 1.0; txt_params-&gt;font_params.font_color.green = 1.0; txt_params-&gt;font_params.font_color.blue = 1.0; txt_params-&gt;font_params.font_color.alpha = 1.0; /* Text background color */ txt_params-&gt;set_bg_clr = 1; txt_params-&gt;text_bg_clr.red = 0.0; txt_params-&gt;text_bg_clr.green = 0.0; txt_params-&gt;text_bg_clr.blue = 0.0; txt_params-&gt;text_bg_clr.alpha = 1.0; nvds_add_display_meta_to_frame (frame_meta, display_meta); } g_print (\"Frame Number = %d Number of objects = %d \" \"Vehicle Count = %d Person Count = %d\\n\", frame_number, num_rects, vehicle_count, person_count); frame_number++; return GST_PAD_PROBE_OK;}加入自己客製的的metadata參考deepstream-user-metadata-test範例的nvinfer_src_pad_buffer_probe 有四個東西需要使用者自行提供 user_meta_data : pointer to User specific meta data meta_type : Metadata type that user sets to identify its metadata copy_func : Metadata copy or transform function to be provided when there is buffer transformation release_func : Metadata release function to be provided when it is no longer required. 這個範例添加一個亂數到metadata上面，以下是要達成這個目標要準備的函式 user_meta_data```cvoid set_metadata_ptr(){ int i = 0; gchar *user_metadata = (gchar)g_malloc0(USER_ARRAY_SIZE); g_print(“\\n****** Setting user metadata array of 16 on nvinfer src pad\\n”); for(i = 0; i &lt; USER_ARRAY_SIZE; i++) { user_metadata[i] = rand() % 255; g_print(“user_meta_data [%d] = %d\\n”, i, user_metadata[i]); } return (void *)user_metadata;} 2. meta_type記得要在在probe function裡面定義變數```c/** set the user metadata type */#define NVDS_USER_FRAME_META_EXAMPLE (nvds_get_user_meta_type(\"NVIDIA.NVINFER.USER_META\"))NvDsMetaType user_meta_type = NVDS_USER_FRAME_META_EXAMPLE; copy_func/* copy function set by user. \"data\" holds a pointer to NvDsUserMeta*/static gpointer copy_user_meta(gpointer data, gpointer user_data){ NvDsUserMeta *user_meta = (NvDsUserMeta *)data; gchar *src_user_metadata = (gchar*)user_meta-&gt;user_meta_data; gchar *dst_user_metadata = (gchar*)g_malloc0(USER_ARRAY_SIZE); memcpy(dst_user_metadata, src_user_metadata, USER_ARRAY_SIZE); return (gpointer)dst_user_metadata;} release_func/* release function set by user. \"data\" holds a pointer to NvDsUserMeta*/static void release_user_meta(gpointer data, gpointer user_data){ NvDsUserMeta *user_meta = (NvDsUserMeta *) data; if(user_meta-&gt;user_meta_data) { g_free(user_meta-&gt;user_meta_data); user_meta-&gt;user_meta_data = NULL; }} 新增一個probe把資料放入metadata```c/* Set nvds user metadata at frame level. User need to set 4 parameters after acquring user meta from pool using nvds_acquire_user_meta_from_pool(). * Below parameters are required to be set. user_meta_data : pointer to User specific meta data meta_type: Metadata type that user sets to identify its metadata copy_func: Metadata copy or transform function to be provided when there is buffer transformation release_func: Metadata release function to be provided when it is no longer required. * osd_sink_pad_buffer_probe will extract metadata received on OSD sink pad and update params for drawing rectangle, object information etc. */ static GstPadProbeReturnnvinfer_src_pad_buffer_probe (GstPad * pad, GstPadProbeInfo * info, gpointer u_data){ GstBuffer *buf = (GstBuffer *) info-&gt;data; NvDsMetaList * l_frame = NULL; NvDsUserMeta *user_meta = NULL; NvDsMetaType user_meta_type = NVDS_USER_FRAME_META_EXAMPLE;NvDsBatchMeta *batch_meta = gst_buffer_get_nvds_batch_meta (buf);for (l_frame = batch_meta-&gt;frame_meta_list; l_frame != NULL; l_frame = l_frame-&gt;next) { NvDsFrameMeta *frame_meta = (NvDsFrameMeta *) (l_frame-&gt;data); /* Acquire NvDsUserMeta user meta from pool */ user_meta = nvds_acquire_user_meta_from_pool(batch_meta); /* Set NvDsUserMeta below */ user_meta-&gt;user_meta_data = (void *)set_metadata_ptr(); user_meta-&gt;base_meta.meta_type = user_meta_type; user_meta-&gt;base_meta.copy_func = (NvDsMetaCopyFunc)copy_user_meta; user_meta-&gt;base_meta.release_func = (NvDsMetaReleaseFunc)release_user_meta; /* We want to add NvDsUserMeta to frame level */ nvds_add_user_meta_to_frame(frame_meta, user_meta);}return GST_PAD_PROBE_OK; } ```將客製化訊息傳換json以之後發送訊息nvmsgconv的功能:利用NVDS_EVENT_MSG_METAmetadata來產生JSON格式的”DeepStream Schema” payload。所產生的payload會以NVDS_META_PAYLOAD的型態儲存到buffer。除了NvDsEventMsgMeta定義的常用訊號結構，使用者還可以自訂客製化物件並加到NVDS_EVENT_MSG_METAmetadata。要加入自定義訊息NvDsEventMsgMeta提供”extMsg”和”extMsgSize”欄位。使用者可以把自定義的structure指針assign給”extMsg”，並且在”extMsgSize”指令資料大小。以deepstream-test4為例，在這裡message放入了客製化訊息NvDsVehicleObject和NvDsPersonObject，如果想要客製化自己的訊息就必須要自己定義。自製自己的客製化訊息可以參考/opt/nvidia/deepstream/deepstream-6.2/sources/libs/nvmsgconv/deepstream_schema/eventmsg_payload.cpp參考客製化訊息如何定義轉換成jsonnvmsgconv的原始碼/opt/nvidia/deepstream/deepstream-6.2/sources/gst-plugins/gst-nvmsgconv/opt/nvidia/deepstream/deepstream-6.2/sources/libs/nvmsgconv nvmsgconv開啟除錯功能debug-payload-dir : Absolute path of the directory to dump payloads for debugging 以deepstream-test4為例，首先將模型的偵測結果NvDsObjectMeta轉換成NvDsEventMsgMeta，在這步將訊息struct加到extMsg上 將製作好的NvDsEventMsgMeta加進buffer裡面，metadata為NvDsUserMeta，在這一步也要指定meta_copy_func、meta_free_funcmvmsgbroker使用方法以下將以rabbitmq為範例 安裝rabbitmq client說明文件在/opt/nvidia/deepstream/deepstream/sources/libs/amqp_protocol_adaptor的readme.md git clone -b v0.8.0 --recursive https://github.com/alanxz/rabbitmq-c.git cd rabbitmq-c mkdir build &amp;&amp; cd build cmake .. cmake --build . sudo cp librabbitmq/librabbitmq.so.4 /opt/nvidia/deepstream/deepstream/lib/ sudo ldconfig 安裝rabbitmq server#Install rabbitmq on your ubuntu system: https://www.rabbitmq.com/install-debian.html#The “Using rabbitmq.com APT Repository” procedure is known to work well sudo apt-get install rabbitmq-server#Ensure rabbitmq service has started by running (should be the case): sudo service rabbitmq-server status#Otherwise sudo service rabbitmq-server start 設定連線詳細資訊 建立cfg_amqp.txt連線資訊檔(/opt/nvidia/deepstream/deepstream/sources/libs/amqp_protocol_adaptor 有範例)，並且傳給nvmsgbroker。內容範例如下[message-broker]hostname = localhostport = 5672username = guestpassword = guestexchange = amq.topictopic = topicnameamqp-framesize = 131072#share-connection = 1 exchange: 預設的exchange是amq.topic，可以更改成其他的 Topic : 設定要發送的topic名稱 share-connection : Uncommenting this field signifies that the connection created can be shared with other components within the same process. 直接將連線資訊傳給msgapi_connect_ptr conn_handle = msgapi_connect_ptr((char *)\"url;port;username;password\",(nvds_msgapi_connect_cb_t) sample_msgapi_connect_cb, (char *)CFG_FILE); 測試用程式在/opt/nvidia/deepstream/deepstream/sources/libs/amqp_protocol_adaptor有測試用的程式test_amqp_proto_async.c和test_amqp_proto_sync.c，可以用來測試連線是否成功，編譯方式如下 make -f Makefile.test ./test_amqp_proto_async ./test_amqp_proto_sync 注意: 你可能須要root權限才能在這個資料夾編譯程式 libnvds_amqp_proto.so 位於 /opt/nvidia/deepstream/deepstream-/lib/ 測試和驗證發送出去的訊息 建立exchange , queue，並且將他們綁定在一起 # Rabbitmq management:It comes with a command line tool which you can use to create/configure all of your queues/exchanges/etchttps://www.rabbitmq.com/management.html# Install rabbitmq management plugin:sudo rabbitmq-plugins enable rabbitmq_management# Use the default exchange amq.topicOR create an exchange as below, the same name as the one you specify within the cfg_amqp.txt#sudo rabbitmqadmin -u guest -p guest -V / declare exchange name=myexchange type=topic# Create a Queuesudo rabbitmqadmin -u guest -p guest -V / declare queue name=myqueue durable=false auto_delete=true#Bind Queue to exchange with routhing_key specificationrabbitmqadmin -u guest -p guest -V / declare binding source=amq.topic destination=myqueue routing_key=topicname#To check if the queues were actually created, execute:$ sudo rabbitmqctl list_queuesListing queuesmyqueue 0* 接收訊息 ```bash #Install the amqp-tools sudo apt-get install amqp-toolscat «EOF &gt; test_amqp_recv.shwhile read -r line; do echo “$line”doneEOFchmod +x test_amqp_recv.sh * 執行consumer```bashamqp-consume -q \"myqueue\" -r \"topicname\" -e \"amq.topic\" ./test_amqp_recv.sh混用c 和 c++ 程式https://hackmd.io/@rhythm/HyOxzDkmDhttps://embeddedartistry.com/blog/2017/05/01/mixing-c-and-c-extern-c/async property某些狀況下async property 設為true會讓pipeline卡住，還需要進一步了解原因nvmsgconv 詳細payload設定在/opt/nvidia/deepstream/deepstream/sources/libs/nvmsgconv/nvmsgconv.cpp裡面可以看到nvds_msg2p_ctx_create這個函式，是用來產出payload的函式。在nvmsgconv讀取的yaml檔裡面可以設定的group和屬性如下sensor enable : 是否啟用這個sensor id : 對應NvDsEventMsgMeta的sensorId type : description location lat;lon;alt的格式 coordinate x;y;z的格式 placeanalyticsNvDsEventMsgMeta 轉換成json的詳細實作在/opt/nvidia/deepstream/deepstream-6.2/sources/libs/nvmsgconv/deepstream_schema/eventmsg_payload.cpp這個程式裡，分別有sensor, place, analytics的轉換實作客製化nvmsgconv payload如果要客製化payload的話，可以參考/opt/nvidia/deepstream/deepstream-6.2/sources/libs/nvmsgconv/deepstream_schema/eventmsg_payload.cpp裡面的實作，並且加入自己需要的客製化payload。首先將整個/opt/nvidia/deepstream/deepstream-6.2/sources/libs/nvmsgconv複製到其他資料夾並且準備編譯環境編譯環境這裡介紹在Ubuntu20.04的桌上型主機上環境的配置方法，Jetson的環境配置方法可能略有不同。 下載並且編譯protobuf在Ubuntu20.04下使用apt-get install protobuf 只會安裝到protobuf 3.6的版本，而許多標頭檔要到3.7以上才有，而且不能超過3.19，以免某些標頭檔又遺失。如果中間有步驟做錯，只要還沒make install，建議直接刪除protobuf的資料夾，重新下載並且編譯。首先直接從github下載protobuf原始碼git clone https://github.com/protocolbuffers/protobuf.git切換版本到v3.19.6，並且更新submodule。cd protobufgit submodule update --init --recursive./autogen.sh編譯並且安裝，make check過程中如果有錯誤，編譯出來的程式可能會有部分功能遺失。./configuremakemake checksudo make installsudo ldconfig # refresh shared library cache.編譯客製化的nvmsgconv接下來進到nvmsgconv的資料夾，修改一下最後產出的lib檔案名稱和install的位置，然後用make指令編譯預訓練模型/opt/nvidia/deepstream/deepstream-6.2/samples/models/tao_pretrained_models/trafficcamnetusb相機https://docs.nvidia.com/jetson/archives/r35.4.1/DeveloperGuide/text/SD/CameraDevelopment/CameraSoftwareDevelopmentSolution.html#applications-using-gstreamer-with-the-nvarguscamerasrc-plugin儲存影像https://forums.developer.nvidia.com/t/drawn-rectangle-is-not-available-on-encoded-frame/178022/7?u=jenhao元件速度測量https://forums.developer.nvidia.com/t/deepstream-sdk-faq/80236/12?u=jenhao參考:https://www.gclue.jp/2022/06/gstreamer.html" }, { "title": "Ubuntu設定home目錄到定另一顆硬碟", "url": "/posts/ubuntu%E8%A8%AD%E5%AE%9Ahome%E7%9B%AE%E9%8C%84%E5%88%B0%E5%AE%9A%E5%8F%A6%E4%B8%80%E9%A1%86%E7%A1%AC%E7%A2%9F/", "categories": "", "tags": "伺服器管理, Ubuntu", "date": "2022-12-27 17:39:00 +0800", "snippet": "在現在常見的SSD作業系統碟加上HDD資料碟的配置，下面接介紹如何手動將/home移動到HDD資料碟格式化硬碟(完全新的硬碟才需要)，這裡假設整顆硬碟不再分割磁碟lsblk #找出硬碟的名稱sudo mkfs -t ext4 /dev/sdb #格式化整顆硬碟將資料碟mount在一個暫時的資料夾下面sudo mkdir /mnt/tmpsudo mount /dev/sdb1 /mnt/tmp複製原本/home裡面的資料sudo rsync -avx /home/ /mnt/tmp建立/home的永久mount點 先用以下指令查詢資料碟的UUID sudo blkid 用sudo nano /etc/fstab # or any other editor將下面一行寫入/etc/fstab文件最後面來設定mount點UUID=&lt;noted number from above&gt; /home ext4 defaults 0 2重開機檢查是否生效(危險區)刪除舊的/home以下指令會刪掉舊的/home。務必先unmount新的home以免刪錯sudo umount /home # unmount the new home first!sudo rm -rf /home/* # deletes the old home掛載另一顆硬碟將/home掛載到另一顆硬碟參考: https://askubuntu.com/a/50539https://www.tecmint.com/convert-home-directory-partition-linux/https://help.ubuntu.com/community/DiskSpace" }, { "title": "GStreamer基礎教學", "url": "/posts/gstreamer%E5%9F%BA%E7%A4%8E%E6%95%99%E5%AD%B8/", "categories": "深度學習工具", "tags": "gstreamer", "date": "2022-12-21 17:18:00 +0800", "snippet": "GObject 和 GLibGStreamer建立在GObject和GLib之上，熟悉GObject和GLib對於學習GStreamer會有幫助，要區分目前的函示是屬於GStreamer還是GLib的方法就是GStreamer的函式是gst_開頭，而GLib的函式是g_開頭1.簡單範例範例下面程式碼是一個最基礎的GStreamer範例basic-tutorial-1.c#include &lt;gst/gst.h&gt;#ifdef __APPLE__#include &lt;TargetConditionals.h&gt;#endifinttutorial_main (int argc, char *argv[]){ GstElement *pipeline; GstBus *bus; GstMessage *msg; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Build the pipeline */ pipeline = gst_parse_launch (\"playbin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm\", NULL); /* Start playing */ gst_element_set_state (pipeline, GST_STATE_PLAYING); /* Wait until error or EOS */ bus = gst_element_get_bus (pipeline); msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_ERROR | GST_MESSAGE_EOS); /* See next tutorial for proper error message handling/parsing */ if (GST_MESSAGE_TYPE (msg) == GST_MESSAGE_ERROR) { g_error (\"An error occurred! Re-run with the GST_DEBUG=*:WARN environment \" \"variable set for more details.\"); } /* Free resources */ gst_message_unref (msg); gst_object_unref (bus); gst_element_set_state (pipeline, GST_STATE_NULL); gst_object_unref (pipeline); return 0;}intmain (int argc, char *argv[]){#if defined(__APPLE__) &amp;&amp; TARGET_OS_MAC &amp;&amp; !TARGET_OS_IPHONE return gst_macos_main (tutorial_main, argc, argv, NULL);#else return tutorial_main (argc, argv);#endif}在Linux下可以用以下指令編譯。gcc basic-tutorial-1.c -o basic-tutorial-1 `pkg-config --cflags --libs gstreamer-1.0`解說上面這個範例最重要的只有五個需要注意的地方，其他的程式碼都是程式結束後清理的例行動作。 首先所有的Gstreamer都必須呼叫gst_init()，他有三個功能 初始化GStreamer 確認plug-ins都可以使用 執行命令列的參數選項，可以直接將main函式的argc和argv直接傳入gst_init()```c/* Initialize GStreamer */gst_init (&amp;argc, &amp;argv); /* Build the pipeline */2. gst_parse_launchGStreamer 元件像水管一樣接起來組成像水管的`pipeline`，影音資料像像水流一樣，`source`元件是`pipeline`的起頭，像水龍頭一樣流出影音資料。`sink`元件是`pipeline`的結尾，是影音資料最後到達的地方。過程中經過中間的處理原件可以對影音資料進行處理。 通常你會需要用程式定義每個元件和串接方式，但是如果你的pipeline很簡單，你可以直接用文字描述的方式作為參數傳給`gst_parse_launch`來建立pipeline3. playbin在這個範例中我們用到playbin來建立pipeline，playbin是一個特殊的元件，他可以同時做為source和sink，而且他可以自己建立成一個pipeline。在這個範例我們給他一個影片串流的URL，如果URL有錯或是指定的影片檔不存在，playbin可以回傳錯誤，在這個範例我們遇到錯誤的時候是直接離開程式。```c gst_parse_launch (\"playbin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm\", NULL); stateGStreamer 還有一個重要的觀念state。每一個GStreamer element都有state，很像影音撥放器的播放和暫停按鈕。在這個範例裡面，pipeline是我們唯一的element，因此要把他設為撥放才會開始撥放影片。 /* Start playing */gst_element_set_state (pipeline, GST_STATE_PLAYING); message bus、gst_element_get_bus、gst_bus_timed_pop_filtered在下面這兩行，gst_element_get_bus會取得pipeline的bus，而gst_bus_timed_pop_filtered會把main thread停住直到我們感興趣的訊息，在這裡是GST_MESSAGE_ERROR和GST_MESSAGE_EOS，而GST_MESSAGE_EOS代表影片結束了，因此當影片結束的時候整個程式就會停止。 /* Wait until error or EOS */ bus = gst_element_get_bus (pipeline); msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_ERROR | GST_MESSAGE_EOS);2. GStreamer 觀念這個教學將會示範用程式建立pipeline。在這裡將會學到 介紹GStreamer element並且學習如何建立 串接element 客製化element行為 利用message bus監看錯誤是件並且從中取出錯誤訊息用程式寫出前一個教學的撥放器完整程式碼basic-tutorial-2.c#include &lt;gst/gst.h&gt;#ifdef __APPLE__#include &lt;TargetConditionals.h&gt;#endifinttutorial_main (int argc, char *argv[]){ GstElement *pipeline, *source, *sink; GstBus *bus; GstMessage *msg; GstStateChangeReturn ret; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Create the elements */ source = gst_element_factory_make (\"videotestsrc\", \"source\"); sink = gst_element_factory_make (\"autovideosink\", \"sink\"); /* Create the empty pipeline */ pipeline = gst_pipeline_new (\"test-pipeline\"); if (!pipeline || !source || !sink) { g_printerr (\"Not all elements could be created.\\n\"); return -1; } /* Build the pipeline */ gst_bin_add_many (GST_BIN (pipeline), source, sink, NULL); if (gst_element_link (source, sink) != TRUE) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (pipeline); return -1; } /* Modify the source's properties */ g_object_set (source, \"pattern\", 0, NULL); /* Start playing */ ret = gst_element_set_state (pipeline, GST_STATE_PLAYING); if (ret == GST_STATE_CHANGE_FAILURE) { g_printerr (\"Unable to set the pipeline to the playing state.\\n\"); gst_object_unref (pipeline); return -1; } /* Wait until error or EOS */ bus = gst_element_get_bus (pipeline); msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_ERROR | GST_MESSAGE_EOS); /* Parse message */ if (msg != NULL) { GError *err; gchar *debug_info; switch (GST_MESSAGE_TYPE (msg)) { case GST_MESSAGE_ERROR: gst_message_parse_error (msg, &amp;err, &amp;debug_info); g_printerr (\"Error received from element %s: %s\\n\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message); g_printerr (\"Debugging information: %s\\n\", debug_info ? debug_info : \"none\"); g_clear_error (&amp;err); g_free (debug_info); break; case GST_MESSAGE_EOS: g_print (\"End-Of-Stream reached.\\n\"); break; default: /* We should not reach here because we only asked for ERRORs and EOS */ g_printerr (\"Unexpected message received.\\n\"); break; } gst_message_unref (msg); } /* Free resources */ gst_object_unref (bus); gst_element_set_state (pipeline, GST_STATE_NULL); gst_object_unref (pipeline); return 0;}intmain (int argc, char *argv[]){#if defined(__APPLE__) &amp;&amp; TARGET_OS_MAC &amp;&amp; !TARGET_OS_IPHONE return gst_macos_main (tutorial_main, argc, argv, NULL);#else return tutorial_main (argc, argv);#endif}GStreamer elementelement是GStreamer最根本的元素，影音資料從source流向sink，過程中經過filter對影音資料進行處理，這三個元素組成為pipeline建立element/* Create the elements */source = gst_element_factory_make (\"videotestsrc\", \"source\");sink = gst_element_factory_make (\"autovideosink\", \"sink\");建立element可以用gst_element_factory_make()來建立，第一個參數是要建立的element名稱，第二個參數是我們給element取的名字。幫element命名的好處是如果你沒有儲存pointer，你可以用名稱來找到這個element，而且除錯訊息也會變得比較有意義。這個教學中建立兩個element，videotestsrc和autovideosink，然後沒有建立任何filter。所以pipeline長的像下圖。videotestsrc是一個source element，他會產生除錯用的影像。autovideosink是一個sink element，他會將影像顯示到螢幕上。建立pipeline/* Create the empty pipeline */pipeline = gst_pipeline_new (\"test-pipeline\");if (!pipeline || !source || !sink) { g_printerr (\"Not all elements could be created.\\n\"); return -1;}所有的element都必須在pipeline裡面才能運作，利用gst_pipeline_new()，可以建立新的pipeline。bin /* Build the pipeline */ gst_bin_add_many (GST_BIN (pipeline), source, sink, NULL); if (gst_element_link (source, sink) != TRUE) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (pipeline); return -1; }Gstreamer的bin是也是一個element，它可以拿來成裝其他 GstElement。GstBin的類別關係圖如下GObject ╰──GInitiallyUnowned ╰──GstObject ╰──GstElement ╰──GstBinpipeline也是bin，用來裝入element。利用gst_bin_add_many()可以將element放入pipeline，他可以一次加入許多element。他的第一個參數是bin，第二個參數之後都是element，也就是要放入的element連接element到目前為止element並還沒有連接起來，利用gst_element_link()將element聯接起來。他的第一個參數是來源，第二個參數是目標，也就是第一個參數的element會把資料傳給第二個參數的element，所以是有順序性的。注意，只有位於同一個bin的element可以互相聯接。屬性GStreamer 的element全部都是一種特殊的GObject，因此他們都有property，有些可以讀取有些可以寫入property必須透過GLib的方法g_object_get()和g_object_set()來讀取和寫入，因此注意到這輛個函式是g_開頭。g_object_set()支援一次修改多個properties。回到我們的程式，我們改變videotestsrc的”pattern” properties，你可以將它改成其他類型來看看輸出的畫面有什麼改變。/* Modify the source's properties */g_object_set (source, \"pattern\", 0, NULL);錯誤檢查到目前為止pipeline都已經建立完成，接下來我們要增加一些程式來應付錯誤發生的情況。 /* Start playing */ ret = gst_element_set_state (pipeline, GST_STATE_PLAYING); if (ret == GST_STATE_CHANGE_FAILURE) { g_printerr (\"Unable to set the pipeline to the playing state.\\n\"); gst_object_unref (pipeline); return -1; }這是我們一樣呼叫gst_element_set_state來開始撥放，但是我們另外檢查gst_element_set_state回傳的錯誤。另外，我們還多了一些程式來處理gst_bus_timed_pop_filtered()拿到的錯誤訊息，錯誤訊息是一個GstMessage，如果遇到EOS以外的錯誤訊息，就把他印出來。GstMessage十分方便，幾乎可以承載任何形式的訊息，而GSstreamer提供了許多解析訊息的函式。首先我們先利用GST_MESSAGE_TYPE()來取得錯誤的類型，如果不是EOS錯誤，就再用gst_message_parse_error()把錯誤轉型成GLib的GError以及錯誤訊息的文字。注意使用完之後要記得釋放。 /* Parse message */ if (msg != NULL) { GError *err; gchar *debug_info; switch (GST_MESSAGE_TYPE (msg)) { case GST_MESSAGE_ERROR: gst_message_parse_error (msg, &amp;err, &amp;debug_info); g_printerr (\"Error received from element %s: %s\\n\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message); g_printerr (\"Debugging information: %s\\n\", debug_info ? debug_info : \"none\"); g_clear_error (&amp;err); g_free (debug_info); break; case GST_MESSAGE_EOS: g_print (\"End-Of-Stream reached.\\n\"); break; default: /* We should not reach here because we only asked for ERRORs and EOS */ g_printerr (\"Unexpected message received.\\n\"); break; } gst_message_unref (msg); }GStreamer busGStreamer bus是用來將元素所產生的GstMessage按順序傳送給應用程式的thread。這裡要強調的是，消息是從處理影像的thread傳遞給應用程式的thread。訊息可以用gst_bus_timed_pop_filtered()這個函式來同步取得。或是用signals 來非同步取得，應用設必須隨時注意bus上有沒有出現錯誤。動態pipeline在這個範例所建立的pipeline並不是完整的，而這裡將示範如何在程式運行時才將完整的pipeline建立好。程式將打開一個multiplexed (或是 muxed)的檔案，也就是聲音和影像都儲存在一個檔案(container file)。用來打開這種檔案的element稱為demuxers。常見的container file有mp4、MKV、WMV等等。如果container file裡面包含多個串流(例如一個影片串流，兩個聲音串流)，demuxer就會把他們分別分配到不同的出口，而不同的pipeline就可以各自處理這些串流。在GStreamer裡element用來傳遞資料的接口稱為pad(GstPad)，sink pad就是資料流進element的口，以及source pad就是element將資料流出的口。記憶的方式就是source elements只會擁有source pad，而sink element只會擁有sink pad。filter element則同時擁有source pad和sink pad。在這個範例裡面，demuxer包含一個sink pad 和多個 source pad，而demuxer複雜的地方就在於在讀取檔案之前沒辦法確定demuxer到底有多少個source pad，因為demuxer要讀取到檔案之後才能決定有多少個source pad。如此一來，demuxers一開始是沒有任何source pad的，因此也沒辦法在編譯時就將demuxers跟其他element連接。當程式開始運作後並且讀取到檔案時，這時候才是連接demuxer的時機。為了簡單起見這個範例只連接audio pad而忽略video pad。範例下面範例basic-tutorial-3.c將示範動態pipeline#include &lt;gst/gst.h&gt;/* Structure to contain all our information, so we can pass it to callbacks */typedef struct _CustomData { GstElement *pipeline; GstElement *source; GstElement *convert; GstElement *resample; GstElement *sink;} CustomData;/* Handler for the pad-added signal */static void pad_added_handler (GstElement *src, GstPad *pad, CustomData *data);int main(int argc, char *argv[]) { CustomData data; GstBus *bus; GstMessage *msg; GstStateChangeReturn ret; gboolean terminate = FALSE; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Create the elements */ data.source = gst_element_factory_make (\"uridecodebin\", \"source\"); data.convert = gst_element_factory_make (\"audioconvert\", \"convert\"); data.resample = gst_element_factory_make (\"audioresample\", \"resample\"); data.sink = gst_element_factory_make (\"autoaudiosink\", \"sink\"); /* Create the empty pipeline */ data.pipeline = gst_pipeline_new (\"test-pipeline\"); if (!data.pipeline || !data.source || !data.convert || !data.resample || !data.sink) { g_printerr (\"Not all elements could be created.\\n\"); return -1; } /* Build the pipeline. Note that we are NOT linking the source at this * point. We will do it later. */ gst_bin_add_many (GST_BIN (data.pipeline), data.source, data.convert, data.resample, data.sink, NULL); if (!gst_element_link_many (data.convert, data.resample, data.sink, NULL)) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (data.pipeline); return -1; } /* Set the URI to play */ g_object_set (data.source, \"uri\", \"https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm\", NULL); /* Connect to the pad-added signal */ g_signal_connect (data.source, \"pad-added\", G_CALLBACK (pad_added_handler), &amp;data); /* Start playing */ ret = gst_element_set_state (data.pipeline, GST_STATE_PLAYING); if (ret == GST_STATE_CHANGE_FAILURE) { g_printerr (\"Unable to set the pipeline to the playing state.\\n\"); gst_object_unref (data.pipeline); return -1; } /* Listen to the bus */ bus = gst_element_get_bus (data.pipeline); do { msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_STATE_CHANGED | GST_MESSAGE_ERROR | GST_MESSAGE_EOS); /* Parse message */ if (msg != NULL) { GError *err; gchar *debug_info; switch (GST_MESSAGE_TYPE (msg)) { case GST_MESSAGE_ERROR: gst_message_parse_error (msg, &amp;err, &amp;debug_info); g_printerr (\"Error received from element %s: %s\\n\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message); g_printerr (\"Debugging information: %s\\n\", debug_info ? debug_info : \"none\"); g_clear_error (&amp;err); g_free (debug_info); terminate = TRUE; break; case GST_MESSAGE_EOS: g_print (\"End-Of-Stream reached.\\n\"); terminate = TRUE; break; case GST_MESSAGE_STATE_CHANGED: /* We are only interested in state-changed messages from the pipeline */ if (GST_MESSAGE_SRC (msg) == GST_OBJECT (data.pipeline)) { GstState old_state, new_state, pending_state; gst_message_parse_state_changed (msg, &amp;old_state, &amp;new_state, &amp;pending_state); g_print (\"Pipeline state changed from %s to %s:\\n\", gst_element_state_get_name (old_state), gst_element_state_get_name (new_state)); } break; default: /* We should not reach here */ g_printerr (\"Unexpected message received.\\n\"); break; } gst_message_unref (msg); } } while (!terminate); /* Free resources */ gst_object_unref (bus); gst_element_set_state (data.pipeline, GST_STATE_NULL); gst_object_unref (data.pipeline); return 0;}/* This function will be called by the pad-added signal */static void pad_added_handler (GstElement *src, GstPad *new_pad, CustomData *data) { GstPad *sink_pad = gst_element_get_static_pad (data-&gt;convert, \"sink\"); GstPadLinkReturn ret; GstCaps *new_pad_caps = NULL; GstStructure *new_pad_struct = NULL; const gchar *new_pad_type = NULL; g_print (\"Received new pad '%s' from '%s':\\n\", GST_PAD_NAME (new_pad), GST_ELEMENT_NAME (src)); /* If our converter is already linked, we have nothing to do here */ if (gst_pad_is_linked (sink_pad)) { g_print (\"We are already linked. Ignoring.\\n\"); goto exit; } /* Check the new pad's type */ new_pad_caps = gst_pad_get_current_caps (new_pad); new_pad_struct = gst_caps_get_structure (new_pad_caps, 0); new_pad_type = gst_structure_get_name (new_pad_struct); if (!g_str_has_prefix (new_pad_type, \"audio/x-raw\")) { g_print (\"It has type '%s' which is not raw audio. Ignoring.\\n\", new_pad_type); goto exit; } /* Attempt the link */ ret = gst_pad_link (new_pad, sink_pad); if (GST_PAD_LINK_FAILED (ret)) { g_print (\"Type is '%s' but link failed.\\n\", new_pad_type); } else { g_print (\"Link succeeded (type '%s').\\n\", new_pad_type); }exit: /* Unreference the new pad's caps, if we got them */ if (new_pad_caps != NULL) gst_caps_unref (new_pad_caps); /* Unreference the sink pad */ gst_object_unref (sink_pad);}解說首先我們先將資料組成一個struct以便後面使用/* Structure to contain all our information, so we can pass it to callbacks */typedef struct _CustomData { GstElement *pipeline; GstElement *source; GstElement *convert; GstElement *resample; GstElement *sink;} CustomData;接下來這行是forward reference晚一點會實做這個函式。/* Handler for the pad-added signal */static void pad_added_handler (GstElement *src, GstPad *pad, CustomData *data);接下來建立element，在這裡uridecodebin會自動初始化需要的element(sources, demuxers and decoders)以便將URI轉換成影音串流。跟playbin比起來他只完成了一半，因為它包含了demuxers，所以只有到執行階段的時候source pad才會被初始化。audioconvert用來轉換audio的格式。audioresample用來調整audio的sample rate。autoaudiosink和autovideosink類似，他將會把聲音串流輸出到音效卡/* Create the elements */data.source = gst_element_factory_make (\"uridecodebin\", \"source\");data.convert = gst_element_factory_make (\"audioconvert\", \"convert\");data.resample = gst_element_factory_make (\"audioresample\", \"resample\");data.sink = gst_element_factory_make (\"autoaudiosink\", \"sink\");串接element接下來我們將converter, resample and sink這些element連接起來。注意這時候還不可以連接source，因為這時候souce還沒有source pad。if (!gst_element_link_many (data.convert, data.resample, data.sink, NULL)) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (data.pipeline); return -1;}然後設定source要讀取的URI/* Set the URI to play */g_object_set (data.source, \"uri\", \"https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm\", NULL);SignalsGSignals是GStreamer的一個重點，他讓我們可以在我們感興趣的事情發生的時候通知我們。GStreamer用名稱來區分signal，而每一個GObject也都有自己的signal。``在這個範例我們將會關心source(也就是uridecodebin element)發出來的pad-added這個訊號。我們必須用g_signal_connect()來連接訊號並且給他callback function(pad_added_handler)和我們的data pointer，讓callback functiony在號發生的時候執行。GStreamer不會對data pointer做任何事情，他只是單純的把data pointer傳進我們的callback function，以便我們可以傳送參數給callback function。/* Connect to the pad-added signal */g_signal_connect (data.source, \"pad-added\", G_CALLBACK (pad_added_handler), &amp;data);在這個範例我們傳入字定義的data struct CustomData。我們的callback function當source element有足夠的資訊可以產生source pad的時候，就會觸發”pad-added”訊號，而這時候我們的callback就會被呼叫。static void pad_added_handler (GstElement *src, GstPad *new_pad, CustomData *data)在我們的callback中，第一個參數是觸發訊號的GstElement，也就是uridecodebin。第二個參數是source剛剛產生的pad，也就是我們想要連接的pad。第三個參數是一個pointer，我們將用他來傳入我麼的參數給callback。在callback裡面，我們將CustomData裡的converter element，利用gst_element_get_static_pad ()將他的sink pad取出來。他也就是要跟source新產生的pad對接的pad。GstPad *sink_pad = gst_element_get_static_pad (data-&gt;convert, \"sink\");在上一個範例我們讓GStreamer自己決定要連接的pad，在這裡我們將手動連接pad。首先加入下面這段程式碼以免pad重複被連接/* If our converter is already linked, we have nothing to do here */if (gst_pad_is_linked (sink_pad)) { g_print (\"We are already linked. Ignoring.\\n\"); goto exit;}接下來我們檢查新產生的pad他產生的資料是什麼，因為我們只需要連接audio而忽略video。而且我們不能把video的pad和audio的pad對接。gst_pad_get_current_caps()可以查到pad會輸出什麼資料，pad的”能力”(capabilities)被紀錄在GstCaps裡面。而pad所有可用的能力可以用gst_pad_query_caps()查詢GstCaps 裡面可能包含許多的GstStructure，每一個都代表不同的”能力”。由於目前我們知道新產生的pad只會有一個capabilities，所以我們直接用gst_caps_get_structure()取得他的第一個GstStructure。最後再利用gst_structure_get_name()來取得這個GstStructure的名稱，這裡將會有關於pad傳出來的資料格式。假如我們拿到的pad輸出的資料格式不是audio/x-raw，那就不是我們要的pad。如果是的話我們就連接他。用gst_element_link()可以直接連接兩個pad，參數的順序是source在來sink，而且這兩個pad所在的element必須要在同一個bin裡面才可以連接。如此一來我們就完成了。/* Attempt the link */ret = gst_pad_link (new_pad, sink_pad);if (GST_PAD_LINK_FAILED (ret)) { g_print (\"Type is '%s' but link failed.\\n\", new_pad_type);} else { g_print (\"Link succeeded (type '%s').\\n\", new_pad_type);}GStreamer StatesGStreamer共有四種狀態 NULL: 無狀態或初始狀態 READY: element已經準備好進入PAUSED狀態 PAUSED: element已經暫停，並且準備好處理資料。sink element這時候只接受一個buffer，之後就阻塞 PLAYING: element正在撥放，clock正在運作，資料正在傳輸。注意，你只能從移動到鄰近的狀態。也就是不可以直接從NUL跳到PLAYING。當你設定pipeline 為PLAYING的時候，GSstreamer自動幫你處理這些事情。下面這段程式監聽message bus，每當狀態有改變的時候就印出來讓你知道。每一個element都會丟出目前狀態的訊息，所以我們過濾出pipeline的狀態訊息。case GST_MESSAGE_STATE_CHANGED: /* We are only interested in state-changed messages from the pipeline */ if (GST_MESSAGE_SRC (msg) == GST_OBJECT (data.pipeline)) { GstState old_state, new_state, pending_state; gst_message_parse_state_changed (msg, &amp;old_state, &amp;new_state, &amp;pending_state); g_print (\"Pipeline state changed from %s to %s:\\n\", gst_element_state_get_name (old_state), gst_element_state_get_name (new_state)); } break;時間管理在這節將會學習到GStreamer時間相關的功能包含 向pipeline詢問資訊例如目前串流的位置和長度。 尋找(跳躍)到串流上不同的位置(時間)GstQueryGstQuery是一個用來詢問element或是pad的資訊的機制。在這個範例我們將詢問pipeline是否可以可以搜尋時間(例如如果是串流就沒辦法搜尋時間)，如果可以我們就可以在影片時間軸上跳躍。這這個範例我們每隔一段時間就向pipeline詢問目前的影片時間位置，如此一來我們就可以將時間顯示在我們的螢幕上。範例我們將以範例basic-tutorial-4.c為例。#include &lt;gst/gst.h&gt;/* Structure to contain all our information, so we can pass it around */typedef struct _CustomData { GstElement *playbin; /* Our one and only element */ gboolean playing; /* Are we in the PLAYING state? */ gboolean terminate; /* Should we terminate execution? */ gboolean seek_enabled; /* Is seeking enabled for this media? */ gboolean seek_done; /* Have we performed the seek already? */ gint64 duration; /* How long does this media last, in nanoseconds */} CustomData;/* Forward definition of the message processing function */static void handle_message (CustomData *data, GstMessage *msg);int main(int argc, char *argv[]) { CustomData data; GstBus *bus; GstMessage *msg; GstStateChangeReturn ret; data.playing = FALSE; data.terminate = FALSE; data.seek_enabled = FALSE; data.seek_done = FALSE; data.duration = GST_CLOCK_TIME_NONE; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Create the elements */ data.playbin = gst_element_factory_make (\"playbin\", \"playbin\"); if (!data.playbin) { g_printerr (\"Not all elements could be created.\\n\"); return -1; } /* Set the URI to play */ g_object_set (data.playbin, \"uri\", \"https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm\", NULL); /* Start playing */ ret = gst_element_set_state (data.playbin, GST_STATE_PLAYING); if (ret == GST_STATE_CHANGE_FAILURE) { g_printerr (\"Unable to set the pipeline to the playing state.\\n\"); gst_object_unref (data.playbin); return -1; } /* Listen to the bus */ bus = gst_element_get_bus (data.playbin); do { msg = gst_bus_timed_pop_filtered (bus, 100 * GST_MSECOND, GST_MESSAGE_STATE_CHANGED | GST_MESSAGE_ERROR | GST_MESSAGE_EOS | GST_MESSAGE_DURATION); /* Parse message */ if (msg != NULL) { handle_message (&amp;data, msg); } else { /* We got no message, this means the timeout expired */ if (data.playing) { gint64 current = -1; /* Query the current position of the stream */ if (!gst_element_query_position (data.playbin, GST_FORMAT_TIME, &amp;current)) { g_printerr (\"Could not query current position.\\n\"); } /* If we didn't know it yet, query the stream duration */ if (!GST_CLOCK_TIME_IS_VALID (data.duration)) { if (!gst_element_query_duration (data.playbin, GST_FORMAT_TIME, &amp;data.duration)) { g_printerr (\"Could not query current duration.\\n\"); } } /* Print current position and total duration */ g_print (\"Position %\" GST_TIME_FORMAT \" / %\" GST_TIME_FORMAT \"\\r\", GST_TIME_ARGS (current), GST_TIME_ARGS (data.duration)); /* If seeking is enabled, we have not done it yet, and the time is right, seek */ if (data.seek_enabled &amp;&amp; !data.seek_done &amp;&amp; current &gt; 10 * GST_SECOND) { g_print (\"\\nReached 10s, performing seek...\\n\"); gst_element_seek_simple (data.playbin, GST_FORMAT_TIME, GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_KEY_UNIT, 30 * GST_SECOND); data.seek_done = TRUE; } } } } while (!data.terminate); /* Free resources */ gst_object_unref (bus); gst_element_set_state (data.playbin, GST_STATE_NULL); gst_object_unref (data.playbin); return 0;}static void handle_message (CustomData *data, GstMessage *msg) { GError *err; gchar *debug_info; switch (GST_MESSAGE_TYPE (msg)) { case GST_MESSAGE_ERROR: gst_message_parse_error (msg, &amp;err, &amp;debug_info); g_printerr (\"Error received from element %s: %s\\n\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message); g_printerr (\"Debugging information: %s\\n\", debug_info ? debug_info : \"none\"); g_clear_error (&amp;err); g_free (debug_info); data-&gt;terminate = TRUE; break; case GST_MESSAGE_EOS: g_print (\"End-Of-Stream reached.\\n\"); data-&gt;terminate = TRUE; break; case GST_MESSAGE_DURATION: /* The duration has changed, mark the current one as invalid */ data-&gt;duration = GST_CLOCK_TIME_NONE; break; case GST_MESSAGE_STATE_CHANGED: { GstState old_state, new_state, pending_state; gst_message_parse_state_changed (msg, &amp;old_state, &amp;new_state, &amp;pending_state); if (GST_MESSAGE_SRC (msg) == GST_OBJECT (data-&gt;playbin)) { g_print (\"Pipeline state changed from %s to %s:\\n\", gst_element_state_get_name (old_state), gst_element_state_get_name (new_state)); /* Remember whether we are in the PLAYING state or not */ data-&gt;playing = (new_state == GST_STATE_PLAYING); if (data-&gt;playing) { /* We just moved to PLAYING. Check if seeking is possible */ GstQuery *query; gint64 start, end; query = gst_query_new_seeking (GST_FORMAT_TIME); if (gst_element_query (data-&gt;playbin, query)) { gst_query_parse_seeking (query, NULL, &amp;data-&gt;seek_enabled, &amp;start, &amp;end); if (data-&gt;seek_enabled) { g_print (\"Seeking is ENABLED from %\" GST_TIME_FORMAT \" to %\" GST_TIME_FORMAT \"\\n\", GST_TIME_ARGS (start), GST_TIME_ARGS (end)); } else { g_print (\"Seeking is DISABLED for this stream.\\n\"); } } else { g_printerr (\"Seeking query failed.\"); } gst_query_unref (query); } } } break; default: /* We should not reach here */ g_printerr (\"Unexpected message received.\\n\"); break; } gst_message_unref (msg);}定義資料struct/* Structure to contain all our information, so we can pass it around */typedef struct _CustomData { GstElement *playbin; /* Our one and only element */ gboolean playing; /* Are we in the PLAYING state? */ gboolean terminate; /* Should we terminate execution? */ gboolean seek_enabled; /* Is seeking enabled for this media? */ gboolean seek_done; /* Have we performed the seek already? */ gint64 duration; /* How long does this media last, in nanoseconds */} CustomData;/* Forward definition of the message processing function */static void handle_message (CustomData *data, GstMessage *msg);首先定義這個範例會用的到資料struct，同時我們也定義一個handle_message來處理我們的資料。設定監聽消息的timeout這個範例我們將會設定gst_bus_timed_pop_filtered()的timeout，如果0.1秒鐘內沒有收到任何訊息，就會發出gst_bus_timed_pop_filtered()會回傳一個NULL。timeoout的設定必須用到GstClockTime，因此我們直接用GST_SECOND 或 GST_MSECOND來產生GstClockTime時間。msg = gst_bus_timed_pop_filtered (bus, 100 * GST_MSECOND, GST_MESSAGE_STATE_CHANGED | GST_MESSAGE_ERROR | GST_MESSAGE_EOS | GST_MESSAGE_DURATION);更新使用者介面首先檢查pipeline是PLAYING的才對pipeline做查詢以免出錯。/* We got no message, this means the timeout expired */if (data.playing) {接著用GstElement提供的方法取得時間。/* Query the current position of the stream */if (!gst_element_query_position (data.pipeline, GST_FORMAT_TIME, &amp;current)) { g_printerr (\"Could not query current position.\\n\");}如果無法取得就改成檢查是否可以詢問stream的長度/* If we didn't know it yet, query the stream duration */if (!GST_CLOCK_TIME_IS_VALID (data.duration)) { if (!gst_element_query_duration (data.pipeline, GST_FORMAT_TIME, &amp;data.duration)) { g_printerr (\"Could not query current duration.\\n\"); }}接下來就可以詢問影片長度/* Print current position and total duration */g_print (\"Position %\" GST_TIME_FORMAT \" / %\" GST_TIME_FORMAT \"\\r\", GST_TIME_ARGS (current), GST_TIME_ARGS (data.duration));下一段是在影片時間軸跳躍的程式，利用gst_element_seek_simple()來達成。/* If seeking is enabled, we have not done it yet, and the time is right, seek */if (data.seek_enabled &amp;&amp; !data.seek_done &amp;&amp; current &gt; 10 * GST_SECOND) { g_print (\"\\nReached 10s, performing seek...\\n\"); gst_element_seek_simple (data.pipeline, GST_FORMAT_TIME, GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_KEY_UNIT, 30 * GST_SECOND); data.seek_done = TRUE;} GST_FORMAT_TIME: 目標時間的格式 GstSeekFlags: 指令跳躍的行為 GST_SEEK_FLAG_FLUSH: 直接拋棄掉目標時間之前的所有畫面。 GST_SEEK_FLAG_KEY_UNIT: 移動到目標時間附近的key frame GST_SEEK_FLAG_ACCURATE: 精準的移動到目標時間上。 目標時間: 是指定要跳躍到的時間位置Message Pump首先如果影片長度改變我們就先讓pipeline不能被詢問影片時間。case GST_MESSAGE_DURATION: /* The duration has changed, mark the current one as invalid */ data-&gt;duration = GST_CLOCK_TIME_NONE; break;接下來這段程式如果pipeline狀態改變，確認pipeline為PAUSED或是PLAYING才可以在時間軸跳躍 case GST_MESSAGE_STATE_CHANGED: { GstState old_state, new_state, pending_state; gst_message_parse_state_changed (msg, &amp;old_state, &amp;new_state, &amp;pending_state); if (GST_MESSAGE_SRC (msg) == GST_OBJECT (data-&gt;playbin)) { g_print (\"Pipeline state changed from %s to %s:\\n\", gst_element_state_get_name (old_state), gst_element_state_get_name (new_state)); /* Remember whether we are in the PLAYING state or not */ data-&gt;playing = (new_state == GST_STATE_PLAYING); if (data-&gt;playing) { /* We just moved to PLAYING. Check if seeking is possible */ GstQuery *query; gint64 start, end; query = gst_query_new_seeking (GST_FORMAT_TIME); if (gst_element_query (data-&gt;playbin, query)) { gst_query_parse_seeking (query, NULL, &amp;data-&gt;seek_enabled, &amp;start, &amp;end); if (data-&gt;seek_enabled) { g_print (\"Seeking is ENABLED from %\" GST_TIME_FORMAT \" to %\" GST_TIME_FORMAT \"\\n\", GST_TIME_ARGS (start), GST_TIME_ARGS (end)); } else { g_print (\"Seeking is DISABLED for this stream.\\n\"); } } else { g_printerr (\"Seeking query failed.\"); } gst_query_unref (query); } } }gst_query_new_seeking()建立一個新的query物件，這個query物件利用gst_element_query()函式被發送到pipeline。如果咬讀去回傳結果可以用gst_query_parse_seeking()媒體格式和pad CapabilitiesPadsCapabilities 顯示在這個Pad上流動的資料的模樣。例如他可能是”解析度300x200的RGB影片，FPS 30”Pad可以有多種Capabilities，例如一個video sink可以同時支援RGB和YUV格式。Capabilities也可以是一個範圍，例如audio sink可以支援samples rates 1~48000。如果要將兩個element連接起來，他們必須要擁有共同的Capabilities。如果連接的時候Capabilities沒辦法對應，就會出現negotiation errorPad templatesPad 是從Pad templates產生的，他可以產生各種Capabilities 的Pad。Capabilities範例下面是一個sink pad。他支援整數型態的raw audio，包含unsigned 8-bit或是 signed, 16-bit little endian。[]裡面代表範圍例如channels可能是一個或兩個。SINK template: 'sink' Availability: Always Capabilities: audio/x-raw format: S16LE rate: [ 1, 2147483647 ] channels: [ 1, 2 ] audio/x-raw format: U8 rate: [ 1, 2147483647 ] channels: [ 1, 2 ]注意有些Capabilities跟平台是有相關性的，要直到READY state的時候才能確定能不能用。範例basic-tutorial-6.c#include &lt;gst/gst.h&gt;/* Functions below print the Capabilities in a human-friendly format */static gboolean print_field (GQuark field, const GValue * value, gpointer pfx) { gchar *str = gst_value_serialize (value); g_print (\"%s %15s: %s\\n\", (gchar *) pfx, g_quark_to_string (field), str); g_free (str); return TRUE;}static void print_caps (const GstCaps * caps, const gchar * pfx) { guint i; g_return_if_fail (caps != NULL); if (gst_caps_is_any (caps)) { g_print (\"%sANY\\n\", pfx); return; } if (gst_caps_is_empty (caps)) { g_print (\"%sEMPTY\\n\", pfx); return; } for (i = 0; i &lt; gst_caps_get_size (caps); i++) { GstStructure *structure = gst_caps_get_structure (caps, i); g_print (\"%s%s\\n\", pfx, gst_structure_get_name (structure)); gst_structure_foreach (structure, print_field, (gpointer) pfx); }}/* Prints information about a Pad Template, including its Capabilities */static void print_pad_templates_information (GstElementFactory * factory) { const GList *pads; GstStaticPadTemplate *padtemplate; g_print (\"Pad Templates for %s:\\n\", gst_element_factory_get_longname (factory)); if (!gst_element_factory_get_num_pad_templates (factory)) { g_print (\" none\\n\"); return; } pads = gst_element_factory_get_static_pad_templates (factory); while (pads) { padtemplate = pads-&gt;data; pads = g_list_next (pads); if (padtemplate-&gt;direction == GST_PAD_SRC) g_print (\" SRC template: '%s'\\n\", padtemplate-&gt;name_template); else if (padtemplate-&gt;direction == GST_PAD_SINK) g_print (\" SINK template: '%s'\\n\", padtemplate-&gt;name_template); else g_print (\" UNKNOWN!!! template: '%s'\\n\", padtemplate-&gt;name_template); if (padtemplate-&gt;presence == GST_PAD_ALWAYS) g_print (\" Availability: Always\\n\"); else if (padtemplate-&gt;presence == GST_PAD_SOMETIMES) g_print (\" Availability: Sometimes\\n\"); else if (padtemplate-&gt;presence == GST_PAD_REQUEST) { g_print (\" Availability: On request\\n\"); } else g_print (\" Availability: UNKNOWN!!!\\n\"); if (padtemplate-&gt;static_caps.string) { GstCaps *caps; g_print (\" Capabilities:\\n\"); caps = gst_static_caps_get (&amp;padtemplate-&gt;static_caps); print_caps (caps, \" \"); gst_caps_unref (caps); } g_print (\"\\n\"); }}/* Shows the CURRENT capabilities of the requested pad in the given element */static void print_pad_capabilities (GstElement *element, gchar *pad_name) { GstPad *pad = NULL; GstCaps *caps = NULL; /* Retrieve pad */ pad = gst_element_get_static_pad (element, pad_name); if (!pad) { g_printerr (\"Could not retrieve pad '%s'\\n\", pad_name); return; } /* Retrieve negotiated caps (or acceptable caps if negotiation is not finished yet) */ caps = gst_pad_get_current_caps (pad); if (!caps) caps = gst_pad_query_caps (pad, NULL); /* Print and free */ g_print (\"Caps for the %s pad:\\n\", pad_name); print_caps (caps, \" \"); gst_caps_unref (caps); gst_object_unref (pad);}int main(int argc, char *argv[]) { GstElement *pipeline, *source, *sink; GstElementFactory *source_factory, *sink_factory; GstBus *bus; GstMessage *msg; GstStateChangeReturn ret; gboolean terminate = FALSE; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Create the element factories */ source_factory = gst_element_factory_find (\"audiotestsrc\"); sink_factory = gst_element_factory_find (\"autoaudiosink\"); if (!source_factory || !sink_factory) { g_printerr (\"Not all element factories could be created.\\n\"); return -1; } /* Print information about the pad templates of these factories */ print_pad_templates_information (source_factory); print_pad_templates_information (sink_factory); /* Ask the factories to instantiate actual elements */ source = gst_element_factory_create (source_factory, \"source\"); sink = gst_element_factory_create (sink_factory, \"sink\"); /* Create the empty pipeline */ pipeline = gst_pipeline_new (\"test-pipeline\"); if (!pipeline || !source || !sink) { g_printerr (\"Not all elements could be created.\\n\"); return -1; } /* Build the pipeline */ gst_bin_add_many (GST_BIN (pipeline), source, sink, NULL); if (gst_element_link (source, sink) != TRUE) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (pipeline); return -1; } /* Print initial negotiated caps (in NULL state) */ g_print (\"In NULL state:\\n\"); print_pad_capabilities (sink, \"sink\"); /* Start playing */ ret = gst_element_set_state (pipeline, GST_STATE_PLAYING); if (ret == GST_STATE_CHANGE_FAILURE) { g_printerr (\"Unable to set the pipeline to the playing state (check the bus for error messages).\\n\"); } /* Wait until error, EOS or State Change */ bus = gst_element_get_bus (pipeline); do { msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_ERROR | GST_MESSAGE_EOS | GST_MESSAGE_STATE_CHANGED); /* Parse message */ if (msg != NULL) { GError *err; gchar *debug_info; switch (GST_MESSAGE_TYPE (msg)) { case GST_MESSAGE_ERROR: gst_message_parse_error (msg, &amp;err, &amp;debug_info); g_printerr (\"Error received from element %s: %s\\n\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message); g_printerr (\"Debugging information: %s\\n\", debug_info ? debug_info : \"none\"); g_clear_error (&amp;err); g_free (debug_info); terminate = TRUE; break; case GST_MESSAGE_EOS: g_print (\"End-Of-Stream reached.\\n\"); terminate = TRUE; break; case GST_MESSAGE_STATE_CHANGED: /* We are only interested in state-changed messages from the pipeline */ if (GST_MESSAGE_SRC (msg) == GST_OBJECT (pipeline)) { GstState old_state, new_state, pending_state; gst_message_parse_state_changed (msg, &amp;old_state, &amp;new_state, &amp;pending_state); g_print (\"\\nPipeline state changed from %s to %s:\\n\", gst_element_state_get_name (old_state), gst_element_state_get_name (new_state)); /* Print the current capabilities of the sink element */ print_pad_capabilities (sink, \"sink\"); } break; default: /* We should not reach here because we only asked for ERRORs, EOS and STATE_CHANGED */ g_printerr (\"Unexpected message received.\\n\"); break; } gst_message_unref (msg); } } while (!terminate); /* Free resources */ gst_object_unref (bus); gst_element_set_state (pipeline, GST_STATE_NULL); gst_object_unref (pipeline); gst_object_unref (source_factory); gst_object_unref (sink_factory); return 0;}印出capabilitiesprint_field、print_caps和print_pad_templates可以印出capabilities。gst_element_get_static_pad()可以用名稱取得Pad，之所以static是因為這個pad永遠都會出現在這個element裡面。gst_pad_get_current_caps()可以取得Pad目前的capabilities，這個capabilities是固定的也可能之後會改變，甚只有可能目前沒有capabilities，要看negotiation proces的狀態來決定。我們可以用gst_pad_query_caps()來取得在NULL state時的CapabilitiesGstElementFactoryGstElementFactory用來初始化指定的element。gst_element_factory_make() = gst_element_factory_find()+ gst_element_factory_create()gst_pad_get_current_caps() 和 gst_pad_query_caps() 的差別 gst_pad_get_current_caps() : 目前可用的Capabilities gst_pad_query_caps() : 包含所有可能的Capabilities多執行續和Pad Availability通常GStreamer會自己處理多執行續，但有時候會需要手動處理他。MultithreadingGStreamer 是一個Multithreading的框架。他會自己產生和消滅thread，甚至plugin可以在自己的process裡面產生新的thread，例如video decoder會自己產生四個thread。Multithreading範例下面是一個多執行續的pipeline，通常多個sink的pipeline是MultithreadingRequest pads在前面的範例我們已經知道uridecodebin在執行時才會確定產生多少個pad，這種pad稱為Sometimes Pads，而固定不變的pad稱為Always Pads。第三中Pad稱為Request Pad，是有需要的時候才建立。在tee裡面就有Request Pad。你必須主動建立才會產生Request Pad。Request Pad沒辦法自動連接，必須手動連接。另外如果在PLAYING或PAUSED的時候建立或是釋放Request Pad要特別小心，因為有時候會造成(Pad blocking)。通常在NULL 或 READY狀態的時候建立或釋放比較安全。範例basic-tutorial-7.c#include &lt;gst/gst.h&gt;int main(int argc, char *argv[]) { GstElement *pipeline, *audio_source, *tee, *audio_queue, *audio_convert, *audio_resample, *audio_sink; GstElement *video_queue, *visual, *video_convert, *video_sink; GstBus *bus; GstMessage *msg; GstPad *tee_audio_pad, *tee_video_pad; GstPad *queue_audio_pad, *queue_video_pad; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Create the elements */ audio_source = gst_element_factory_make (\"audiotestsrc\", \"audio_source\"); tee = gst_element_factory_make (\"tee\", \"tee\"); audio_queue = gst_element_factory_make (\"queue\", \"audio_queue\"); audio_convert = gst_element_factory_make (\"audioconvert\", \"audio_convert\"); audio_resample = gst_element_factory_make (\"audioresample\", \"audio_resample\"); audio_sink = gst_element_factory_make (\"autoaudiosink\", \"audio_sink\"); video_queue = gst_element_factory_make (\"queue\", \"video_queue\"); visual = gst_element_factory_make (\"wavescope\", \"visual\"); video_convert = gst_element_factory_make (\"videoconvert\", \"csp\"); video_sink = gst_element_factory_make (\"autovideosink\", \"video_sink\"); /* Create the empty pipeline */ pipeline = gst_pipeline_new (\"test-pipeline\"); if (!pipeline || !audio_source || !tee || !audio_queue || !audio_convert || !audio_resample || !audio_sink || !video_queue || !visual || !video_convert || !video_sink) { g_printerr (\"Not all elements could be created.\\n\"); return -1; } /* Configure elements */ g_object_set (audio_source, \"freq\", 215.0f, NULL); g_object_set (visual, \"shader\", 0, \"style\", 1, NULL); /* Link all elements that can be automatically linked because they have \"Always\" pads */ gst_bin_add_many (GST_BIN (pipeline), audio_source, tee, audio_queue, audio_convert, audio_resample, audio_sink, video_queue, visual, video_convert, video_sink, NULL); if (gst_element_link_many (audio_source, tee, NULL) != TRUE || gst_element_link_many (audio_queue, audio_convert, audio_resample, audio_sink, NULL) != TRUE || gst_element_link_many (video_queue, visual, video_convert, video_sink, NULL) != TRUE) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (pipeline); return -1; } /* Manually link the Tee, which has \"Request\" pads */ tee_audio_pad = gst_element_get_request_pad (tee, \"src_%u\"); g_print (\"Obtained request pad %s for audio branch.\\n\", gst_pad_get_name (tee_audio_pad)); queue_audio_pad = gst_element_get_static_pad (audio_queue, \"sink\"); tee_video_pad = gst_element_get_request_pad (tee, \"src_%u\"); g_print (\"Obtained request pad %s for video branch.\\n\", gst_pad_get_name (tee_video_pad)); queue_video_pad = gst_element_get_static_pad (video_queue, \"sink\"); if (gst_pad_link (tee_audio_pad, queue_audio_pad) != GST_PAD_LINK_OK || gst_pad_link (tee_video_pad, queue_video_pad) != GST_PAD_LINK_OK) { g_printerr (\"Tee could not be linked.\\n\"); gst_object_unref (pipeline); return -1; } gst_object_unref (queue_audio_pad); gst_object_unref (queue_video_pad); /* Start playing the pipeline */ gst_element_set_state (pipeline, GST_STATE_PLAYING); /* Wait until error or EOS */ bus = gst_element_get_bus (pipeline); msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_ERROR | GST_MESSAGE_EOS); /* Release the request pads from the Tee, and unref them */ gst_element_release_request_pad (tee, tee_audio_pad); gst_element_release_request_pad (tee, tee_video_pad); gst_object_unref (tee_audio_pad); gst_object_unref (tee_video_pad); /* Free resources */ if (msg != NULL) gst_message_unref (msg); gst_object_unref (bus); gst_element_set_state (pipeline, GST_STATE_NULL); gst_object_unref (pipeline); return 0;}初始化element/* Create the elements */audio_source = gst_element_factory_make (\"audiotestsrc\", \"audio_source\");tee = gst_element_factory_make (\"tee\", \"tee\");audio_queue = gst_element_factory_make (\"queue\", \"audio_queue\");audio_convert = gst_element_factory_make (\"audioconvert\", \"audio_convert\"); audio_resample = gst_element_factory_make (\"audioresample\", \"audio_resample\");audio_sink = gst_element_factory_make (\"autoaudiosink\", \"audio_sink\");video_queue = gst_element_factory_make (\"queue\", \"video_queue\");visual = gst_element_factory_make (\"wavescope\", \"visual\");video_convert = gst_element_factory_make (\"videoconvert\", \"video_convert\");video_sink = gst_element_factory_make (\"autovideosink\", \"video_sink\");調整element為了範例需求，微調屬性/* Configure elements */g_object_set (audio_source, \"freq\", 215.0f, NULL);g_object_set (visual, \"shader\", 0, \"style\", 1, NULL);將element放進pipeline將所有element放入pipeline並且連接所有Always Pads/* Link all elements that can be automatically linked because they have \"Always\" pads */gst_bin_add_many (GST_BIN (pipeline), audio_source, tee, audio_queue, audio_convert, audio_sink, video_queue, visual, video_convert, video_sink, NULL);if (gst_element_link_many (audio_source, tee, NULL) != TRUE || gst_element_link_many (audio_queue, audio_convert, audio_sink, NULL) != TRUE || gst_element_link_many (video_queue, visual, video_convert, video_sink, NULL) != TRUE) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (pipeline); return -1;}注意:gst_element_link_many()其實也可以自動連接Request Pads。因為它會自動請求新的pad。但是問題是你還是必須要手動釋放Request Pads。所以最好的做法是手動連接Request Pads。連接Request Pads要連接Request Pads必須要先跟element請求，而因為element有時候可以產生不同的request pads，所以要提供所需的Pad Template名稱。在tee的文件中可以看到他有兩個Pad Template，一個是”sink”，另一個是”src_%u”(也就是Request pads)，我們可以用gst_element_request_pad_simple()函式來請求兩個Pads(一個給audio一個給video)。Pad Templates: SRC template: 'src_%u' Availability: On request Capabilities: ANY SINK template: 'sink' Availability: Always Capabilities: ANY接著我們需要取得下游queue element的Always pad，因此用gst_element_get_static_pad()。我們用gst_pad_link()連接Pads。gst_pad_link()內部其實就是gst_element_link()和gst_element_link_many()我們用來儲存下游queue always pad的變數queue_audio_pad和queue_video_pad要記得釋放，以免佔用reference count。/* Manually link the Tee, which has \"Request\" pads */tee_audio_pad = gst_element_get_request_pad (tee, \"src_%u\");g_print (\"Obtained request pad %s for audio branch.\\n\", gst_pad_get_name (tee_audio_pad));queue_audio_pad = gst_element_get_static_pad (audio_queue, \"sink\");tee_video_pad = gst_element_get_request_pad (tee, \"src_%u\");g_print (\"Obtained request pad %s for video branch.\\n\", gst_pad_get_name (tee_video_pad));queue_video_pad = gst_element_get_static_pad (video_queue, \"sink\");if (gst_pad_link (tee_audio_pad, queue_audio_pad) != GST_PAD_LINK_OK || gst_pad_link (tee_video_pad, queue_video_pad) != GST_PAD_LINK_OK) { g_printerr (\"Tee could not be linked.\\n\"); gst_object_unref (pipeline); return -1;}gst_object_unref (queue_audio_pad);gst_object_unref (queue_video_pad);最後在程式結束後，要記得釋放request pad/* Release the request pads from the Tee, and unref them */gst_element_release_request_pad (tee, tee_audio_pad);gst_element_release_request_pad (tee, tee_video_pad);gst_object_unref (tee_audio_pad);gst_object_unref (tee_video_pad);gst_element_release_request_pad()從tee釋放requests pads，gst_object_unref釋放tee_audio_pad變數hort-cutting the pipeline Goalpipeline的資料並不是封閉的，我們可以從外界注入資料給pipeline，也可以從pipeline內取得資料appsrc、appsink把資料注入pipeline的element為appsrc，相反的從pipeline取得資料的element是appsink。這裡sink和source的概念是從GStreamer應用程式的角度來看，你可以想像appsrc也是一個source，只不過他的資料來源是來自於應用程式，相反的appsink就像普通的sink只是他最後流向應用程式。appsrc有多種模式，在pull模式每當需要的時候他將會向應用程式索取資料。在push模式則是應用程式主動推送資料進去。在push模式中應用程式還可以阻塞push function當已經推入足夠多的資料到pipeline裡面的時候，或者他可以監聽enough-data和need-data訊號。Buffers數據以Chunks方式進入pipeline的方式稱為Buffers，Buffers代表一單位的資料，但是每一個Buffers大小不一定一樣大。注意，我們不應該假設一個Buffers進入element就同時會有一個離開element。element可以隨意地讓Buffers停留在element內部。Source pad產生Buffers，而sink pad接收Buffers，Gstreamer將這些Buffers一流過每一個element。GstBuffer 和 GstMemoryGstBuffers 可能包含一個或一個以上的memory buffer，而真正的記憶體buffer被抽像化為GstMemory，因此一個GstBuffer可以包含一個或一個以上的GstMemory每一個buffer都有時間戳和長度，以及他需要被decode的長度。範例下面範例延續Multithreading and Pad Availability的範例並擴展。首先audiotestsrc被置換成appsrc來產生audio資料。第二個是增加一個新的tee分支，這隻分支會接著appsink，appsink會將資訊回傳給應用程式。範例basic-tutorial-8.c的程式如下#include &lt;gst/gst.h&gt;#include &lt;gst/audio/audio.h&gt;#include &lt;string.h&gt;#define CHUNK_SIZE 1024 /* Amount of bytes we are sending in each buffer */#define SAMPLE_RATE 44100 /* Samples per second we are sending *//* Structure to contain all our information, so we can pass it to callbacks */typedef struct _CustomData { GstElement *pipeline, *app_source, *tee, *audio_queue, *audio_convert1, *audio_resample, *audio_sink; GstElement *video_queue, *audio_convert2, *visual, *video_convert, *video_sink; GstElement *app_queue, *app_sink; guint64 num_samples; /* Number of samples generated so far (for timestamp generation) */ gfloat a, b, c, d; /* For waveform generation */ guint sourceid; /* To control the GSource */ GMainLoop *main_loop; /* GLib's Main Loop */} CustomData;/* This method is called by the idle GSource in the mainloop, to feed CHUNK_SIZE bytes into appsrc. * The idle handler is added to the mainloop when appsrc requests us to start sending data (need-data signal) * and is removed when appsrc has enough data (enough-data signal). */static gboolean push_data (CustomData *data) { GstBuffer *buffer; GstFlowReturn ret; int i; GstMapInfo map; gint16 *raw; gint num_samples = CHUNK_SIZE / 2; /* Because each sample is 16 bits */ gfloat freq; /* Create a new empty buffer */ buffer = gst_buffer_new_and_alloc (CHUNK_SIZE); /* Set its timestamp and duration */ GST_BUFFER_TIMESTAMP (buffer) = gst_util_uint64_scale (data-&gt;num_samples, GST_SECOND, SAMPLE_RATE); GST_BUFFER_DURATION (buffer) = gst_util_uint64_scale (num_samples, GST_SECOND, SAMPLE_RATE); /* Generate some psychodelic waveforms */ gst_buffer_map (buffer, &amp;map, GST_MAP_WRITE); raw = (gint16 *)map.data; data-&gt;c += data-&gt;d; data-&gt;d -= data-&gt;c / 1000; freq = 1100 + 1000 * data-&gt;d; for (i = 0; i &lt; num_samples; i++) { data-&gt;a += data-&gt;b; data-&gt;b -= data-&gt;a / freq; raw[i] = (gint16)(500 * data-&gt;a); } gst_buffer_unmap (buffer, &amp;map); data-&gt;num_samples += num_samples; /* Push the buffer into the appsrc */ g_signal_emit_by_name (data-&gt;app_source, \"push-buffer\", buffer, &amp;ret); /* Free the buffer now that we are done with it */ gst_buffer_unref (buffer); if (ret != GST_FLOW_OK) { /* We got some error, stop sending data */ return FALSE; } return TRUE;}/* This signal callback triggers when appsrc needs data. Here, we add an idle handler * to the mainloop to start pushing data into the appsrc */static void start_feed (GstElement *source, guint size, CustomData *data) { if (data-&gt;sourceid == 0) { g_print (\"Start feeding\\n\"); data-&gt;sourceid = g_idle_add ((GSourceFunc) push_data, data); }}/* This callback triggers when appsrc has enough data and we can stop sending. * We remove the idle handler from the mainloop */static void stop_feed (GstElement *source, CustomData *data) { if (data-&gt;sourceid != 0) { g_print (\"Stop feeding\\n\"); g_source_remove (data-&gt;sourceid); data-&gt;sourceid = 0; }}/* The appsink has received a buffer */static GstFlowReturn new_sample (GstElement *sink, CustomData *data) { GstSample *sample; /* Retrieve the buffer */ g_signal_emit_by_name (sink, \"pull-sample\", &amp;sample); if (sample) { /* The only thing we do in this example is print a * to indicate a received buffer */ g_print (\"*\"); gst_sample_unref (sample); return GST_FLOW_OK; } return GST_FLOW_ERROR;}/* This function is called when an error message is posted on the bus */static void error_cb (GstBus *bus, GstMessage *msg, CustomData *data) { GError *err; gchar *debug_info; /* Print error details on the screen */ gst_message_parse_error (msg, &amp;err, &amp;debug_info); g_printerr (\"Error received from element %s: %s\\n\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message); g_printerr (\"Debugging information: %s\\n\", debug_info ? debug_info : \"none\"); g_clear_error (&amp;err); g_free (debug_info); g_main_loop_quit (data-&gt;main_loop);}int main(int argc, char *argv[]) { CustomData data; GstPad *tee_audio_pad, *tee_video_pad, *tee_app_pad; GstPad *queue_audio_pad, *queue_video_pad, *queue_app_pad; GstAudioInfo info; GstCaps *audio_caps; GstBus *bus; /* Initialize custom data structure */ memset (&amp;data, 0, sizeof (data)); data.b = 1; /* For waveform generation */ data.d = 1; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Create the elements */ data.app_source = gst_element_factory_make (\"appsrc\", \"audio_source\"); data.tee = gst_element_factory_make (\"tee\", \"tee\"); data.audio_queue = gst_element_factory_make (\"queue\", \"audio_queue\"); data.audio_convert1 = gst_element_factory_make (\"audioconvert\", \"audio_convert1\"); data.audio_resample = gst_element_factory_make (\"audioresample\", \"audio_resample\"); data.audio_sink = gst_element_factory_make (\"autoaudiosink\", \"audio_sink\"); data.video_queue = gst_element_factory_make (\"queue\", \"video_queue\"); data.audio_convert2 = gst_element_factory_make (\"audioconvert\", \"audio_convert2\"); data.visual = gst_element_factory_make (\"wavescope\", \"visual\"); data.video_convert = gst_element_factory_make (\"videoconvert\", \"video_convert\"); data.video_sink = gst_element_factory_make (\"autovideosink\", \"video_sink\"); data.app_queue = gst_element_factory_make (\"queue\", \"app_queue\"); data.app_sink = gst_element_factory_make (\"appsink\", \"app_sink\"); /* Create the empty pipeline */ data.pipeline = gst_pipeline_new (\"test-pipeline\"); if (!data.pipeline || !data.app_source || !data.tee || !data.audio_queue || !data.audio_convert1 || !data.audio_resample || !data.audio_sink || !data.video_queue || !data.audio_convert2 || !data.visual || !data.video_convert || !data.video_sink || !data.app_queue || !data.app_sink) { g_printerr (\"Not all elements could be created.\\n\"); return -1; } /* Configure wavescope */ g_object_set (data.visual, \"shader\", 0, \"style\", 0, NULL); /* Configure appsrc */ gst_audio_info_set_format (&amp;info, GST_AUDIO_FORMAT_S16, SAMPLE_RATE, 1, NULL); audio_caps = gst_audio_info_to_caps (&amp;info); g_object_set (data.app_source, \"caps\", audio_caps, \"format\", GST_FORMAT_TIME, NULL); g_signal_connect (data.app_source, \"need-data\", G_CALLBACK (start_feed), &amp;data); g_signal_connect (data.app_source, \"enough-data\", G_CALLBACK (stop_feed), &amp;data); /* Configure appsink */ g_object_set (data.app_sink, \"emit-signals\", TRUE, \"caps\", audio_caps, NULL); g_signal_connect (data.app_sink, \"new-sample\", G_CALLBACK (new_sample), &amp;data); gst_caps_unref (audio_caps); /* Link all elements that can be automatically linked because they have \"Always\" pads */ gst_bin_add_many (GST_BIN (data.pipeline), data.app_source, data.tee, data.audio_queue, data.audio_convert1, data.audio_resample, data.audio_sink, data.video_queue, data.audio_convert2, data.visual, data.video_convert, data.video_sink, data.app_queue, data.app_sink, NULL); if (gst_element_link_many (data.app_source, data.tee, NULL) != TRUE || gst_element_link_many (data.audio_queue, data.audio_convert1, data.audio_resample, data.audio_sink, NULL) != TRUE || gst_element_link_many (data.video_queue, data.audio_convert2, data.visual, data.video_convert, data.video_sink, NULL) != TRUE || gst_element_link_many (data.app_queue, data.app_sink, NULL) != TRUE) { g_printerr (\"Elements could not be linked.\\n\"); gst_object_unref (data.pipeline); return -1; } /* Manually link the Tee, which has \"Request\" pads */ tee_audio_pad = gst_element_request_pad_simple (data.tee, \"src_%u\"); g_print (\"Obtained request pad %s for audio branch.\\n\", gst_pad_get_name (tee_audio_pad)); queue_audio_pad = gst_element_get_static_pad (data.audio_queue, \"sink\"); tee_video_pad = gst_element_request_pad_simple (data.tee, \"src_%u\"); g_print (\"Obtained request pad %s for video branch.\\n\", gst_pad_get_name (tee_video_pad)); queue_video_pad = gst_element_get_static_pad (data.video_queue, \"sink\"); tee_app_pad = gst_element_request_pad_simple (data.tee, \"src_%u\"); g_print (\"Obtained request pad %s for app branch.\\n\", gst_pad_get_name (tee_app_pad)); queue_app_pad = gst_element_get_static_pad (data.app_queue, \"sink\"); if (gst_pad_link (tee_audio_pad, queue_audio_pad) != GST_PAD_LINK_OK || gst_pad_link (tee_video_pad, queue_video_pad) != GST_PAD_LINK_OK || gst_pad_link (tee_app_pad, queue_app_pad) != GST_PAD_LINK_OK) { g_printerr (\"Tee could not be linked\\n\"); gst_object_unref (data.pipeline); return -1; } gst_object_unref (queue_audio_pad); gst_object_unref (queue_video_pad); gst_object_unref (queue_app_pad); /* Instruct the bus to emit signals for each received message, and connect to the interesting signals */ bus = gst_element_get_bus (data.pipeline); gst_bus_add_signal_watch (bus); g_signal_connect (G_OBJECT (bus), \"message::error\", (GCallback)error_cb, &amp;data); gst_object_unref (bus); /* Start playing the pipeline */ gst_element_set_state (data.pipeline, GST_STATE_PLAYING); /* Create a GLib Main Loop and set it to run */ data.main_loop = g_main_loop_new (NULL, FALSE); g_main_loop_run (data.main_loop); /* Release the request pads from the Tee, and unref them */ gst_element_release_request_pad (data.tee, tee_audio_pad); gst_element_release_request_pad (data.tee, tee_video_pad); gst_element_release_request_pad (data.tee, tee_app_pad); gst_object_unref (tee_audio_pad); gst_object_unref (tee_video_pad); gst_object_unref (tee_app_pad); /* Free resources */ gst_element_set_state (data.pipeline, GST_STATE_NULL); gst_object_unref (data.pipeline); return 0;}加入appsrc和appsink首先要先設定appsrc的caps，他決定了appsrc所輸出的資料類型。我們可以用字串來建立GstCaps物件，只需要用gst_caps_from_string()函式。另外我們還必須連接need-data和enough-data訊號。這兩個訊號是appsrc發出來的。/* Configure appsrc */gst_audio_info_set_format (&amp;info, GST_AUDIO_FORMAT_S16, SAMPLE_RATE, 1, NULL);audio_caps = gst_audio_info_to_caps (&amp;info);g_object_set (data.app_source, \"caps\", audio_caps, NULL);g_signal_connect (data.app_source, \"need-data\", G_CALLBACK (start_feed), &amp;data);g_signal_connect (data.app_source, \"enough-data\", G_CALLBACK (stop_feed), &amp;data);new-sample訊號另外我們還要接上app_sink的訊號new-sample，這個訊號預設是關閉的所以必須手動打開這個訊號，由emit-signals可以設定。/* Configure appsink */g_object_set (data.app_sink, \"emit-signals\", TRUE, \"caps\", audio_caps, NULL);g_signal_connect (data.app_sink, \"new-sample\", G_CALLBACK (new_sample), &amp;data);gst_caps_unref (audio_caps);callback function我們的callback function在每當appsrc內部的queue快要沒資料的時候被呼叫。他唯一做的事情就是註冊一個GLib的函式g_idle_add()，他將會給appsrc資料直到appsrc滿了為止。Glib的main event loop更進一步說明可以參考這裡我們將g_idle_add()回傳的id做個紀錄以便等一下可以停止他。/* This signal callback triggers when appsrc needs data. Here, we add an idle handler * to the mainloop to start pushing data into the appsrc */static void start_feed (GstElement *source, guint size, CustomData *data) { if (data-&gt;sourceid == 0) { g_print (\"Start feeding\\n\"); data-&gt;sourceid = g_idle_add ((GSourceFunc) push_data, data); }}下面這個callback function當appsrc內部的queue滿的時候會被呼叫。在這裡我們就直接用g_source_remove()移除idle function/* This callback triggers when appsrc has enough data and we can stop sending. * We remove the idle handler from the mainloop */static void stop_feed (GstElement *source, CustomData *data) { if (data-&gt;sourceid != 0) { g_print (\"Stop feeding\\n\"); g_source_remove (data-&gt;sourceid); data-&gt;sourceid = 0; }}接下來這個function是推送資料給appsrc的callback，是給GLib的g_idle_add()呼叫用的。首先他的工作是建立一個新的buffer並且給定大小(這個範例設為1024 bytes)，設定大小可以用gst_buffer_new_and_alloc()。接下例我們計算我們已經餵給appsrc的資料數目，並且用CustomData.num_samples紀錄，如此一來就可以給這個buffer時間戳，時皆戳可以用GstBuffer的GST_BUFFER_TIMESTAMP marco。因為我們每次都提供相同大小的buffer，他的長度都是相同的，我們可以用GstBuffer的GST_BUFFER_DURATIONmarco來設定duration。gst_util_uint64_scale()是用來放大或縮小大數字的函式，用這個函是就不用擔心overflows。buffer的大小可以用GstBuffer 可以用GST_BUFFER_DATA 取得。/* This method is called by the idle GSource in the mainloop, to feed CHUNK_SIZE bytes into appsrc. * The ide handler is added to the mainloop when appsrc requests us to start sending data (need-data signal) * and is removed when appsrc has enough data (enough-data signal). */static gboolean push_data (CustomData *data) { GstBuffer *buffer; GstFlowReturn ret; int i; gint16 *raw; gint num_samples = CHUNK_SIZE / 2; /* Because each sample is 16 bits */ gfloat freq; /* Create a new empty buffer */ buffer = gst_buffer_new_and_alloc (CHUNK_SIZE); /* Set its timestamp and duration */ GST_BUFFER_TIMESTAMP (buffer) = gst_util_uint64_scale (data-&gt;num_samples, GST_SECOND, SAMPLE_RATE); GST_BUFFER_DURATION (buffer) = gst_util_uint64_scale (num_samples, GST_SECOND, SAMPLE_RATE); /* Generate some psychodelic waveforms */ raw = (gint16 *)GST_BUFFER_DATA (buffer);最後就是把生成好的資料推送進appsrc裡面，並且會觸發push-buffer訊號。/* Push the buffer into the appsrc */g_signal_emit_by_name (data-&gt;app_source, \"push-buffer\", buffer, &amp;ret);/* Free the buffer now that we are done with it */gst_buffer_unref (buffer);而當appsink接收到資料的時候下面的函式會被呼叫。我們用pull-sample動作訊號來取得buffer並且應到螢幕上。利用GST_BUFFER_DATA取得資料的指針以及GST_BUFFER_SIZE取得資料大小。注意，在這裡的buffer不一定會跟我們在前面指定的buffer大小一樣，因為任何element都有可能去更動buffer，雖然在這個範例buffer並沒有被改動。Debugging toolsdebug logdebug log是由GST_DEBUG環境變數控制。下面是GST_DEBUG=2的時候的debug log。0:00:00.868050000 1592 09F62420 WARN filesrc gstfilesrc.c:1044:gst_file_src_start:&lt;filesrc0&gt; error: No such file \"non-existing-file.webm\"通常我們不會把debug log全部打開以免訊息塞爆文件或是訊息視窗。下面是各種等級的debug log會輸出的資料。| # | Name | Description ||---|---------|----------------------------------------------------------------|| 0 | none | No debug information is output. || 1 | ERROR | Logs all fatal errors. These are errors that do not allow the || | | core or elements to perform the requested action. The || | | application can still recover if programmed to handle the || | | conditions that triggered the error. || 2 | WARNING | Logs all warnings. Typically these are non-fatal, but || | | user-visible problems are expected to happen. || 3 | FIXME | Logs all \"fixme\" messages. Those typically that a codepath that|| | | is known to be incomplete has been triggered. It may work in || | | most cases, but may cause problems in specific instances. || 4 | INFO | Logs all informational messages. These are typically used for || | | events in the system that only happen once, or are important || | | and rare enough to be logged at this level. || 5 | DEBUG | Logs all debug messages. These are general debug messages for || | | events that happen only a limited number of times during an || | | object's lifetime; these include setup, teardown, change of || | | parameters, etc. || 6 | LOG | Logs all log messages. These are messages for events that || | | happen repeatedly during an object's lifetime; these include || | | streaming and steady-state conditions. This is used for log || | | messages that happen on every buffer in an element for example.|| 7 | TRACE | Logs all trace messages. Those are message that happen very || | | very often. This is for example is each time the reference || | | count of a GstMiniObject, such as a GstBuffer or GstEvent, is || | | modified. || 9 | MEMDUMP | Logs all memory dump messages. This is the heaviest logging and|| | | may include dumping the content of blocks of memory. |+------------------------------------------------------------------------------+設置element的debug log如果要設置個別element的debug level，範例如下。如此一來audiotestsrc的level是6，其他的都是2GST_DEBUG=2,audiotestsrc:6GST_DEBUG格是GST_DEBUG的第一個參數是optional的，他會設定全域的debug level。參數之間以逗號,區隔，除了第一個參數，每一個設定的格式都是category:level。*也可以被用在GST_DEBUG裡面，例如GST_DEBUG=2,audio*:6會把所有開頭為audio的element都設為level 6，其他保持level 2。增加自訂除錯訊息如果要讓category 看起來更有意義，可以加入下面兩行GST_DEBUG_CATEGORY_STATIC (my_category);#define GST_CAT_DEFAULT my_category以及下面這行在gst_init()被呼叫之後。GST_DEBUG_CATEGORY_INIT (my_category, \"my category\", 0, \"This is my very own\");取得pipeline的圖gstreamer可以將你的pipeline輸出成.dot檔可以用例如GraphViz來開啟。如果在程式內想開啟這項功能可以用GST_DEBUG_BIN_TO_DOT_FILE() 和 GST_DEBUG_BIN_TO_DOT_FILE_WITH_TS()marco來開啟這個功能。範例:可以在程式中加入下面程式碼來儲存pipeline圖官方文件圖案參數參考來源GST_DEBUG_BIN_TO_DOT_FILE(pipeline, GST_DEBUG_GRAPH_SHOW_ALL, \"pipeline\"); //三個參數分別為 pipeline的instance, 圖案參數, 檔案名稱這行程式記得加在將pipeline state設定為playing之前，這樣才能完整看到pipeline的樣子。然後執行程式之前先設定環境變數GST_DEBUG_DUMP_DOT_DIR來指定儲存位置export GST_DEBUG_DUMP_DOT_DIR=./tracing/mkdir tracing接下來就會在tracing看到pipeline.dot檔安裝xdot來讀取.dot檔sudo apt install xdotxdot pipeline.dotgst-launch-1.0可以用用GST_DEBUG_DUMP_DOT_DIR來設定儲存圖片的資料夾並開啟這項功能。每當pipeline的狀態改變的時候都會畫一張圖，如此一來就可以看到pipeline的變化gst-debugger遠端除錯gstreamer安裝protochttp://google.github.io/proto-lens/installing-protoc.htmlStreaming這裡將介紹streaming要注意的點 開啟buffering 斷線重連通常網路串流會因為網路連線的關係造成串流封包沒有準時到達而造成跨面卡住。而這個問題的解法就是使用buffer。buffer讓一些影音chunks儲存在queue裡面，如此一來雖然剛開始影片會稍微延遲一點，但是如果網路連線不穩的話話面不會卡住，因為queue裡面還有chunks。clock應用程式應該隨時監看buffer的狀態，如果buffer太少，就應該暫停撥放。為了達到所有的sink都可以同步，GStreamer有一個global clock，所有的element都會共用這個global clock。有時候如果切換streaming或是切換輸出裝置，clock會消失，這時候就必須重選clock，下面的範例將會解說這個步驟。當clock消失的時候應用程式會接收到訊息，這時候只需要將pipeline設為PAUSED再設為PLAYING就可以選擇新的clock。範例範例basic-tutorial-12.c#include &lt;gst/gst.h&gt;#include &lt;string.h&gt;typedef struct _CustomData { gboolean is_live; GstElement *pipeline; GMainLoop *loop;} CustomData;static void cb_message (GstBus *bus, GstMessage *msg, CustomData *data) { switch (GST_MESSAGE_TYPE (msg)) { case GST_MESSAGE_ERROR: { GError *err; gchar *debug; gst_message_parse_error (msg, &amp;err, &amp;debug); g_print (\"Error: %s\\n\", err-&gt;message); g_error_free (err); g_free (debug); gst_element_set_state (data-&gt;pipeline, GST_STATE_READY); g_main_loop_quit (data-&gt;loop); break; } case GST_MESSAGE_EOS: /* end-of-stream */ gst_element_set_state (data-&gt;pipeline, GST_STATE_READY); g_main_loop_quit (data-&gt;loop); break; case GST_MESSAGE_BUFFERING: { gint percent = 0; /* If the stream is live, we do not care about buffering. */ if (data-&gt;is_live) break; gst_message_parse_buffering (msg, &amp;percent); g_print (\"Buffering (%3d%%)\\r\", percent); /* Wait until buffering is complete before start/resume playing */ if (percent &lt; 100) gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED); else gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING); break; } case GST_MESSAGE_CLOCK_LOST: /* Get a new clock */ gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED); gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING); break; default: /* Unhandled message */ break; }}int main(int argc, char *argv[]) { GstElement *pipeline; GstBus *bus; GstStateChangeReturn ret; GMainLoop *main_loop; CustomData data; /* Initialize GStreamer */ gst_init (&amp;argc, &amp;argv); /* Initialize our data structure */ memset (&amp;data, 0, sizeof (data)); /* Build the pipeline */ pipeline = gst_parse_launch (\"playbin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm\", NULL); bus = gst_element_get_bus (pipeline); /* Start playing */ ret = gst_element_set_state (pipeline, GST_STATE_PLAYING); if (ret == GST_STATE_CHANGE_FAILURE) { g_printerr (\"Unable to set the pipeline to the playing state.\\n\"); gst_object_unref (pipeline); return -1; } else if (ret == GST_STATE_CHANGE_NO_PREROLL) { data.is_live = TRUE; } main_loop = g_main_loop_new (NULL, FALSE); data.loop = main_loop; data.pipeline = pipeline; gst_bus_add_signal_watch (bus); g_signal_connect (bus, \"message\", G_CALLBACK (cb_message), &amp;data); g_main_loop_run (main_loop); /* Free resources */ g_main_loop_unref (main_loop); gst_object_unref (bus); gst_element_set_state (pipeline, GST_STATE_NULL); gst_object_unref (pipeline); return 0;}說明在這個範例中比較特別的是下面這一段，注意如果收到GST_STATE_CHANGE_NO_PREROLL而不是GST_STATE_CHANGE_SUCCESS，這代表目前正再撥放直撥串流。因為直撥串流是不能暫停的，所以就算把pipeline的狀態設為PAUSED他的行為還是跟PLAYING一樣。而且即使我們嘗試將pipeline設為PLAYING也會收到這個訊息。因為我們想要關閉直撥串流的buffering，所以我們用gst_element_set_state()在data裡面做記號/* Start playing */ret = gst_element_set_state (pipeline, GST_STATE_PLAYING);if (ret == GST_STATE_CHANGE_FAILURE) { g_printerr (\"Unable to set the pipeline to the playing state.\\n\"); gst_object_unref (pipeline); return -1;} else if (ret == GST_STATE_CHANGE_NO_PREROLL) { data.is_live = TRUE;}callback接下來我們看一下message parsing callback，首先如果發現是直撥串流，就不要打開buffering。接下來用gst_message_parse_buffering()來取得 buffering level。然後我們印出 buffering level並且設定當 buffering level小於100%的時候就暫停pipeline，如果超過就設為PLAYING。程式執行的時候會看到buffer慢慢攀升到100%，然後如果網路不穩到buffer小於100%，就會暫停撥放直到回復100%後才重新撥放。case GST_MESSAGE_BUFFERING: { gint percent = 0; /* If the stream is live, we do not care about buffering. */ if (data-&gt;is_live) break; gst_message_parse_buffering (msg, &amp;percent); g_print (\"Buffering (%3d%%)\\r\", percent); /* Wait until buffering is complete before start/resume playing */ if (percent &lt; 100) gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED); else gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING); break;}lost clock另一個我們要處理的消息是遺失clock，我們只需要將pipeline設為PAUSED再設為PLAYING就可以了。case GST_MESSAGE_CLOCK_LOST: /* Get a new clock */ gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED); gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING); break;" }, { "title": "DeepStream動態增減串流", "url": "/posts/deepstream%E5%8B%95%E6%85%8B%E5%A2%9E%E6%B8%9B%E4%B8%B2%E6%B5%81/", "categories": "", "tags": "", "date": "2022-12-18 18:04:00 +0800", "snippet": "本篇文章參考:https://developer.nvidia.com/blog/managing-video-streams-in-runtime-with-the-deepstream-sdk/https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/master/runtime_source_add_deleteGlib定時執行函式為了到動態增減串流，必須在main thread之外有一個thread定期的察看目前串流的表。Glib提供了g_timeout_add_seconds這個函式讓我們可以定期呼叫函式。g_timeout_add_seconds可以讓我們設定每間隔多少時間呼叫一次函數。guint g_timeout_add_seconds (guint interval, GSourceFunc function, gpointer data)g_timeout_add_seconds有三個參數分別是Interval: 每間隔多少秒呼叫函數一次function: 要被呼叫的函式data: 要傳送給函式的參數在我們動態增減的範例中，我們可以寫一個watchDog函式來讀去資料庫目前有無需要新增或刪減串流。" }, { "title": "Linux 核心設計實作摘要", "url": "/posts/linux-%E6%A0%B8%E5%BF%83%E8%A8%AD%E8%A8%88%E5%AF%A6%E4%BD%9C%E6%91%98%E8%A6%81/", "categories": "", "tags": "", "date": "2022-12-02 22:40:00 +0800", "snippet": "C語言指標理解C Traps and Pitfalls 的 “Understanding Declarations”小節提到如何解讀指標。每一個C的變數宣告可以拆成兩個部分。 型態 一串將會回傳這個型態的表達式float f, g;代表f, g將會回傳floatfloat ff();代表ff()將會回傳float，因此ff是一個function並且會回傳floatfloat *pf;代表*pf江會回傳float，因此pf是一個pointerfloat *g(), (*h)();首先()的優先度大於*因此*g() 可以改寫成*(g())，由此可知g是function並且會回傳一個pointer to a float的指標。而(*h)()代表h是一個pointer to a function指標，而且這個function會回傳float。 知道如何宣告變數後就可以寫出，就可以知道如何寫出這個類型強制轉型的寫法，只需要把變數名稱和分號移除，最後再加上括號float *g();在這裡的g是一個回傳pointer的function，這個pointer指向float。而g強制轉型的寫法即為(float *())Byte和Bit1 Byte = 8 Bits指標運算符號 Address-of operator&amp;稱為 Address-of operator Dereference operator*稱為 Dereference operator將pointer所指向的值給另一個變數(This is called a “load” operation.) int bar = *foo_ptr; 將值儲存到pointer所指的位置(This is called a “store” operation.) *foo_ptr = 42; Sets foo to 42 -&gt;操作符定義一個struct foo和一個foo的指針foo_ptrstruct foo {\tsize_t size;\tchar name[64];\tint answer_to_ultimate_question;\tunsigned shoe_size;};如果要查看foo_ptr所指向的內容，可以用(*foo_ptr).size = new_size;或者是用-&gt;操作符foo_ptr-&gt;size = new_size;陣列Array宣告陣列int array[] = { 45, 67, 89 };在C語言，你宣告了一個陣列array之後，當你使用的時候，array這個變數其實是一個指向這個陣列第一個元素的指針，我們把這個行為稱為decaying，因為陣列被decays成指針了。不過他還是和針的指針有一點不同，其中就是如果用sizeof(array)來看陣列的話，回傳的將會是陣列的總長度(在這個範例就是(sizeof(int) = 4) × 3 = 12)而不是單一個指針的長度。下面這三種狀況對陣列來說都是一樣的array == &amp;array == &amp;array[0]他們分別代表“array”, “pointer to array”, 和 “pointer to the first element of array”，但在C這三個東西是一樣的陣列++對於一般變數來說variable += 1代表對變數+1，但是對於指標來說代表對目前指標的位置加上資料型態的大小。以我們上一個例子來說我們的陣列儲存的是int，而array被decays成pointer了，所以array + 1就是加上sizeof(int)，等同於我們把指針移動到下一個元素。Indexing首先看一下以下例子int array[] = { 45, 67, 89 };int *array_ptr = &amp;array[1];printf(\"%i\\n\", array_ptr[1]);這段程式宣告的一個三個元素的陣列array，還有一個int指針array_ptr，可以用下面這張圖可以看到array[1]和array_ptr[0]指向同一個記憶體。我們可以看到其實[]是指針的操作符，array[1]等同於*(array + 1)參考:Everything you need to know about pointers in Chttps://boredzo.org/pointers/" }, { "title": "GDB除錯Python C extension", "url": "/posts/gdb%E9%99%A4%E9%8C%AFpython-c-extension/", "categories": "", "tags": "", "date": "2022-11-29 16:02:00 +0800", "snippet": "測試範例#include &lt;Python.h&gt;static PyObject *method_myadd(PyObject *self, PyObject *args){ int x, y, z = -1; /* Parse arguments */ if(!PyArg_ParseTuple(args, \"ii\", &amp;x, &amp;y)){ return NULL; } /* The actual bit of code I need */ z = x + y; return PyLong_FromLong(z);}static PyMethodDef myaddMethods[] = { {\"myadd\", method_myadd, METH_VARARGS, \"Python interface for myadd C library function\"}, {NULL, NULL, 0, NULL}};static struct PyModuleDef myaddmodule = { PyModuleDef_HEAD_INIT, \"myadd\", \"Python interface for the myadd C library function\", -1, myaddMethods};PyMODINIT_FUNC PyInit_myadd(void) { return PyModule_Create(&amp;myaddmodule);}import myaddprint(\"going to ADD SOME NUMBERS\")x = myadd.myadd(5,6)print(x)from distutils.core import setup, Extensiondef main(): setup(name=\"myadd\", version=\"1.0.0\", description=\"Python interface for the myadd C library function\", author=\"Nadiah\", author_email=\"nadiah@nadiah.org\", ext_modules=[Extension(\"myadd\", [\"myadd.cpp\"])], )if __name__ == \"__main__\": main()安裝GCCsudo apt-get install build-essential安裝python標頭檔apt-get install python3-dev安裝venv最好要使用venv來開發c extension，因為如果沒有使用venv，python3 setup.py install編譯好的套件apt install python3-venv編譯範例程式python3 setup.py install安裝Python debug symbol下面指令python的版本可以改成你自己的python版本apt-get install python3.10-dbg以GDB執行Pythongdb python注意!!必須先正確安裝Python的debug symbol再執行這一步，完成後你應該要可以看到成功載入Python debug symbol，gdb的顯示類似如下GNU gdb (Ubuntu 12.1-0ubuntu1~22.04) 12.1Copyright (C) 2022 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;.....For help, type \"help\".Type \"apropos word\" to search for commands related to \"word\"...Reading symbols from python...Reading symbols from /usr/lib/debug/.build-id/75/c83caa11a9418b8e5ae8feb0bb8f2e5d00c47b.debug...如果你看到(No debugging symbols found in python)表示GDB找不到Python debug symbols。GDB下中斷點這一步會預先建立一個中斷點，引為此時我們的extension還沒被Python載入。再這個範例我們把中斷點下在myadd.cpp第12行z = x + y的位置(gdb)b myadd.cpp:12這時候GDB會問你是不是要建立一個未來使用的中斷點，回答是就可以(gdb) b myadd.cpp:12No source file named myadd.cpp.Make breakpoint pending on future shared library load? (y or [n]) Python呼叫extension最後在GDB裡面執行myscript.py程式，就可以看到程式停在我們的中斷點(gdb) run myscript.pydebug Python 好用的指令參考:編譯教學https://uwpce-pythoncert.github.io/Py300/notes/BuildingExtensions.html安裝debug symbolhttps://wiki.python.org/moin/DebuggingWithGdbgdb除錯參考:https://scipy-lectures.org/advanced/debugging/index.html#debugging-segmentation-faults-using-gdb加入gdb路徑https://devguide.python.org/advanced-tools/gdb/index.html#gdb-7-and-later範例程式https://nadiah.org/2020/03/01/example-debug-mixed-python-c-in-visual-studio-code/除錯https://developers.redhat.com/articles/2021/09/08/debugging-python-c-extensions-gdb#python_commands_in_gdb" }, { "title": "統計學課本重點摘要", "url": "/posts/%E7%B5%B1%E8%A8%88%E5%AD%B8%E8%AA%B2%E6%9C%AC%E9%87%8D%E9%BB%9E%E6%91%98%E8%A6%81/", "categories": "", "tags": "", "date": "2022-11-29 10:49:00 +0800", "snippet": "CH1統計學基本元素Population, Sample, Experimental unitVariableMeasurementInferenital Statistical Problem最大的重點，計算reliabilityQuantitative data和Qualitative dataQuantitative data: 可以測量的資料，例如高度、溫度Qualitative data:無法測量的資料，例如滿意度、車子種類，為了方便計算可以給予數值，但數值本身沒有任何意義，只是一個代號Representative samplerepresentative sample的特遮會和母體的特徵一樣。CH2 描述一組資料資料集data set: \\(x_1, x_2, x_3, \\cdots , x_n\\)，每個元素都是一個量測結果。例如我們量測5個商品的長度，並且記錄結果為\\(x_1=5, x_2=3, x_3=8, x_4=5, x_5=4\\)加總符號如果要表達所有元素的加總，我們可以寫成\\(x_1 + x_2 + x_3 + \\cdots + x_n\\)，或是我們可以用符號\\(\\sum\\)代表\\[x_1 + x_2 + x_3 + \\cdots + x_n = \\sum_{i=1}^nx_i\\]如果我們要計算每個元素的平方和，可以表達成下面方式\\[x_1^2 + x_2^2 + x_3^2 + \\cdots + x_n^2 = \\sum_{i=1}^nx_i^2\\]描述資料的方式通常描述資料會有兩中方式 集中趨勢(central tendency) 變異性(variability) (補集中趨勢和變異性的圖)集中趨勢(Central Tendency) 我們最常用的Central Tendency計算方式就是平均值，我們用\\(\\bar{x}\\)(音:x bar)代表”樣本平均數”，他的計算方式如下\\[\\bar{x} = \\frac{\\sum_{i=1}^nx_i}{n}\\]而我們用\\(\\mu\\)代表母體平均數。通常我們用英文字母代表樣本，希臘字母代表母體。 中位數，比起平均數更能夠對付極端值。變異性(variability) deviation: 每一個資料點和平均的”距離”和”方向”，注意deviation是有正負號的，所以直接相加平均正負會相消。 sample variance(變異數): 為了解決正負相消的問題，我們可以將每一個deviation平方後相加再除以元數個數-1。\\[s^2 = \\frac{\\sum_{i=1}^n(x_i - \\bar{x})^2}{n-1}\\] sample standard devitaion: 為了得到有意義的變異測量值，將sample variance開根號後就可以得到sample standard devitaion\\[s = \\sqrt{s^2}\\]\\(s^2 =\\) sample variance(樣本變異數)\\(s =\\) sample standard devitaion(樣本標準差)\\(\\sigma^2 =\\) population variance(母體變異數)\\(\\sigma =\\) population standard devitaion(母體標準差)用標準差來描述單一樣本(單一資料集)前面我們已經知道如果比較兩個樣本，standard devitaion越大表示變異性越大，也就是我們知道用standard devitaion來比較兩個樣本的相對變異程度。這節我們要用standard devitaion來描述單一個樣本。如果對於frequency distributionj為對稱鐘形，根據經驗法則， 通常68%的Experimental unit會落在平均的正負一個標準差之內，也就是對於樣本來說\\((\\bar{x} - s, \\bar{x} + s)\\)，對於母體來說\\((\\mu - \\sigma, \\mu + \\sigma)\\) 通常95%的Experimental unit會落在平均的正負兩個標準差之內，也就是對於樣本來說\\((\\bar{x} - 2s, \\bar{x} + 2s)\\)，對於母體來說\\((\\mu - 2\\sigma, \\mu + 2\\sigma)\\) 通常99.7%的Experimental unit會落在平均的正負三個標準差之內，也就是對於樣本來說\\((\\bar{x} - 3s, \\bar{x} + 3s)\\)，對於母體來說\\((\\mu - 3\\sigma, \\mu + 3\\sigma)\\)描述單一個測量值在全部測量值的位置如果要描述一個測量值在所有測量值的位置，例如個人所得在所有勞工所得的位置。我們可以用z-score來描述。z-score利用平均和標準差來描述一個側量值所在的位置。其公式如下。對於樣本:\\[z = \\frac{x - \\bar{x}}{s}\\]對於母體:\\[z = \\frac{x - \\mu}{\\sigma}\\]z-score是有正負號的，正值越大代表這個測量值大於平均值越多，反之越少。(補上p79的圖)CH3機率事件、樣本空間、和機率以丟硬幣為例 observation, measurement:紀錄丟硬幣出現的結果 experiment: 完成投擲多次硬幣並且記錄丟硬幣的結果的過程。 sample point: 整個experiment最基礎的出現結果，以硬幣來說，正面反面各是一個sample point，以骰子來說1,2,3,4,5,6都分別是一個sample point。已丟兩個硬幣為例，總共有4個sample point，分別為正正、正反、反正、反反 sample space:包含所有sample point的集合丟一個硬幣的sample space為 S:{正, 反}丟兩個硬幣的sample space為 S:{正正、正反、反正、反反}丟骰子的sample space為 S:{1,2,3,4,5,6}sample point的機率規定 每一個sample point的機率一定要介於0和1之間。 sample space裡面所有sample point的機率加總必須為1event事件event是一組sample point，他可以只包含一個sample point，也可以包含多個sample pointevent的機率就是event內所有的sample point的總和聯集Unions和交集Intersections聯集(or)(P131的圖)交集(and)(P131的圖)Complementary Event補集合event A的補集合的事件就是由所有不包含A事件sample point所構成。\\(A\\)的補集合記為\\(A^s\\)\\[P(A)+P(A^s)=1\\]互斥事件的加法法則(Mutually Exclusive Events)加法法則 \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)互斥事件代表兩個事件不會同時發生，例如丟硬幣正面和反面不會同時出現，因此\\(P(A \\cap B)=0\\)。因此對於互斥事件，\\(P(A \\cup B) = P(A) + P(B)\\)條件機率給定A事件發生的條件下，B事件發生的機率。例如丟一個骰子，在丟出來的數字小於3的條件下，出現偶數的機率。\\[P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\\]乘法定律與獨立事件(Independent Event)從前面的條件機率經過移項後就可以得到\\[P(A \\cap B) = P(B)P(A \\mid B)\\]而如果A和B的機率不會互相影響，A B兩個事件就是獨立事件，也就是\\[P(A \\mid B) = P(A)\\]\\(P(B \\mid A) = P(B)\\)獨立事件有三個重點 獨立事件沒辦法用作圖或是直覺判斷，必須透過計算來驗證他是獨立事件。 互斥事件(Mutually Exclusive Events)不是獨立事件(Independent Event)，假設A，B為互斥事件，因為互斥事件的關係，如果B發生則\\(P(A \\mid B) = 0\\)，而因此\\(P(A) \\neq P(A \\mid B)\\)，所以不可能滿足獨立事件的條件\\(P(A \\mid B) = P(A)\\)。 計算獨立事件的交集十分簡單，\\(P(A \\cap B) = P(A)P(B \\mid A)\\)，因為獨立事件的關係\\(P(B \\mid A)=P(B)\\)，所以獨立事件的交集事件為\\(P(A \\cap B) = P(A)P(B)\\)隨機抽樣每一個樣本被抽中的機率都相同貝氏定律\\(P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\\)​CH4隨機變數random variable和機率分布隨機變數的兩種類型 隨機變數的定義隨機變數是把實驗會出現的所有結果用數字表達，每一個sample point都會有一個數字。例如以丟兩個銅板為例，我們可以計算出現人頭的數量，因此我們的random variable就會有0, 1, 2 三個。random在這裡代表的意義是這些數字在每次實驗中都是隨機出現的。兩種類型的random variable discrete random variable 例如丟兩個銅板出現頭的個數 continuous random variable 例如鑽油井挖到多深會挖到石油probability distribution of diserete random variablediserete random variable 的probability distribution可以是一個圖、表或是公式。他描述的是每一個random variable的發生的機率。以丟兩個硬幣為例，我們以觀察到頭的個數作為random variable並計為x，x總共有三種可能，分別是頭出現0次，1次，2次(0, 1, 2)。丟硬幣可能出現的sampling point共有HH, HT, TH, TT四種(H:頭, T:字)。計算probability distribution如下\\[P(x=0)=P(TT) = \\frac{1}{4}\\]\\[P(x=1)=P(TH) + P(HT) = \\frac{1}{2}\\]\\[P(x=2)=P(HH) = \\frac{1}{4}\\]probability distribution的必要條件Discrete Random Variable x 的probability distribution必要條件 \\[p(x) \\geq 0\\] \\(\\sum{p(x)} = 1\\)，其中 \\(\\sum{p(x)}\\) 是把所有可能的random variable x都算進去加總期望值Expected Value期望值其實就是population mean以隨機變數Random Variable x為例\\(\\mu = E(x) = \\sum{xp(x)}\\)注意，期望值不一定會是Random Variable可能出現的值，以擲骰子為例，期望值不一定會是1~6其中一個整數期望值的直觀解釋https://www.probabilisticworld.com/intuitive-explanation-expected-value/隨機變數的變異數(Variance)\\(\\sigma^2 = E[(x - \\mu)^2] = \\sum{(x - \\mu)^2p(x)}\\)隨機變數的標準差(Standard deviation)\\(\\sigma = \\sqrt{\\sigma^2}\\)Sample Distributions parameters: 用來描述母體probability distributions的數值，例如用來描述binomial distributaion的成功機率p， 或者是描述normal distribution的\\(\\mu\\)平均和\\(\\sigma\\)標準差都是parameters。因為是描述母體，所以parameters是固定的數值，但是通常也是未知的或是永遠無法確切知道的 sample statistic: 用來描述sample的數值，他是由sample的oberservation計算而來的。例如\\(\\bar{x}\\)平均、\\(s^2\\)以及s標準差。藉由這些sample statistic內含的一些資訊，我們可以用來推斷母體的parameter。 sample statistic能夠直接拿來推論parameters嗎?我們從由sample取得的一個oberservation可以算出sample statistic。每次的oberservation所計算的sample statistic也不完全相同。舉例來說，我們想要推斷丟公平骰子出現點數的期望值\\(\\mu\\)，而我們也已知\\(\\mu = 3.5\\)(在現實情況下\\(\\mu\\)幾乎都是未知的)。假設每次oberservation都丟三次，第一次的觀察結果是2, 2, 6，\\(\\bar{x} = 3.33\\) 中位數m為3，我們可以看到\\(\\bar{x}\\)比較接近母體的\\(\\mu\\)。第二次oberservation結果為3, 4, 6，\\(\\bar{x} = 4.33\\)，m=4，這次反而是中位數比較接近母體的\\(\\mu\\)。由此可知我們沒辦法直接比較哪一個sample statistic比較適合拿來推論parameters，而其根本的原因是因為sample statistic本身也是random variable，因為不同的sample本身就會產生出不同的sample statistic。也因為sample statistic是random variable的原因，要比較他們就必須用他們的probility distributionsample statistic的sampling distributionsample statistic的probility distribution稱為sampling distribution。舉例來說，假設一間工廠生產的鐵條長度\\(\\mu = 0.3\\)標準差為0.005。假設一個實驗每次隨機抽出25根鐵條，並且量測每一根的長度後計算平均長度\\(\\bar{x}\\)。假如這個實驗做很多次的話，每一次實驗的\\(\\bar{x}\\)都會不太一樣，而這些大量實驗所產生的\\(\\bar{x}\\)的分布圖就是\\(\\bar{x}\\)的sampling distribution。sampling distribution是經由重複操作”抽取n個measurements”的實驗所計算的sample statistic的分布圖例:https://onlinestatbook.com/stat_sim/sampling_dist/index.htmlSample Distribution形狀的特性假如被抽樣的母體是常態分布，而且也只有母體是常態分布的情況下，則不管實驗抽樣的n的大小，他的Sample Distribution也一定是常態分佈中央極限定理(Central Limit Theorem)假設我們想要推論一個母體的平均數\\(\\bar{x}\\)，於是我們進行抽樣並且每次實驗都抽取n個樣本來計算平均，這個實驗重複非常多次而得到Sample Distribution，我們可以觀察到\\(\\bar{x}\\)的Sample Distribution的母體平均數\\(\\mu_\\bar{x}\\)、標準差\\(\\sigma_\\bar{x}\\)，以及被抽樣的母體的平均數\\(\\mu\\)和標準差\\(\\sigma\\)的關係為 Sample Distribution的平均 = 母體的平均，\\(\\mu_\\bar{x} = E(\\bar{x}) = \\mu\\) \\(Sample Distribution的標準差等於 = \\frac{母體標準差}{\\sqrt{n}}\\)，也就是\\(\\sigma_\\bar{x} = \\frac{\\sigma}{\\sqrt{n}}\\)不管母體的分布是什麼，當n月大的時候Sample Distribution就越接近常態分佈，而且並議會越小越，資料越集中。CH5 Inference Based on a Single Sample本章的重點在於如何運用一組資料(Single Sample)來進行預測target parameter對於母體我們有興趣但是未知的參數我們稱為target parameter例如母體平均數。point estimator利用樣本的一個數值來預測母體的target parameter稱為point estimator。例如我們利用樣本的平均\\(\\bar{x}\\)來推估。例如:假設我們想要估計一個城市的平均收入，但我們無法調查每一個人。因此，我們可以從這個城市隨機抽取一些人（樣本），並計算他們的平均收入（樣本平均值）。然後，我們可以使用這個樣本平均值作為整個城市平均收入的點估計。interval estimatorinterval estimator是一個公式，它告訴我們如何使用樣本數據來計算一個區間，以估計目標參數。母體平均的信賴區間 : Normal (z) Statistic假設銀行要推估所有欠債兩個月以上的帳號平均欠債的金額，於是做了一次實驗抽出一百個欠債兩個月以上的帳號並計算樣本平均\\(\\bar{x}\\)。接下來要計算樣本平均\\(\\bar{x}\\)推估母體平均的準確度。先回顧一下根據中央極限定理，樣本平均的Sample Distribution在每次抽樣的樣本數n夠大的時候會接近常態分佈。而interval estimator如下:\\(\\bar{x} \\pm 1.96\\sigma_\\bar{x}= \\bar{x} \\pm \\frac{1.96\\sigma}{\\sqrt{n}}\\)從Sample Distribution得圖上來看，我們畫了一個上下邊界在Sample Distribution上，而邊界的中心是母體標準差。(根據中央極限定理，Sample Distribution的平均數會近似於母體平均數)。回到我們計算欠債平均金額的實驗中，我們這次實驗取得的樣本會落在這上下邊界範圍內的機率是多少?因為如果我們取得的樣本可以落在這上下邊界之內，我們所算出來的interval estimator就會包含母體平均，超過邊界則interval estimator內不會包含母體平均。從常態分佈下抽取一個樣本落在距離平均一個標準差內機率0.95。可以參考下面網站 簡單來說，我們在這裡算出一個interval estimator，而真正的母體平均數會落在這個interval estimator內的機率是confidence coefficient。confidence level 和 confidence coefficientconfidence coefficient是我們隨機抽取的樣本所匯出的confidence interval包含母體平均的機率，而confidence level則是confidence coefficient以百分比的方式呈現。例如confidence coefficient為0.95，則confidence level為95%。使用Normal (z) Statistic的條件 樣本數n要大於30，因為根據中央極限定理當n大於30時，Sample Distribution會接近常態分佈。 樣本必須是從母體中隨機抽取的\\(\\alpha\\)與confidence coefficient可以參考這裡的圖為了方便表示不同的confidence coefficient，我們定義了\\(\\alpha\\)\\(alpha\\)值代表的是confidence coefficient以外的面積，也就是頭尾兩端的面積。所以1-confidence coefficient就是\\(alpha\\)值。 當confidence coefficient為0.95時，\\(\\alpha\\)為0.05。當confidence coefficient為0.99時，\\(\\alpha\\)為0.01。由於常態分佈頭尾對稱，所以頭部或是尾部的面積為\\(\\frac{\\alpha}{2}\\)。如此一來我們可以改寫confidence interval的公式為:\\[\\bar{x} \\pm (z_{\\frac{\\alpha}{2}})\\sigma_{\\bar{x}}= \\bar{x} \\pm z_{\\frac{\\alpha}{2}}(\\frac{\\sigma}{\\sqrt{n}})\\]其中\\(z_{\\frac{\\alpha}{2}}\\)為z值在頭部面積為\\(\\frac{\\alpha}{2}\\)的時候的值。而\\(\\sigma_{\\bar{x}}\\) 是sample statistic \\(\\bar{x}\\) 的Sample Distribution，計算方式是母體標準差除以樣本數的平方根。當樣本數夠大的時候(通常大於30)，可以用單次抽樣的標準差sample statistic s代替母體標準差$\\sigma$。也就是說當樣本數大於30時，式子可以改寫成\\(\\bar{x} \\pm (z_{\\frac{\\alpha}{2}})\\frac{s}{\\sqrt{n}}\\)概念釐清 特別注意，這個章節我們的目標是只做一次experiment，進而推斷出母體平均數。所以我們Sample Distribution是未知的，因為Sample Distribution要做很多次實驗才能得到。這也就是為什麼\\(\\sigma_{\\bar{x}}\\)是未知的，而且\\(\\sigma_{\\bar{x}}\\)所指的母體是Sample Distribution，跟我們要推估的母體不是同一個母體。5.3 Student’s t Statistic有些狀況下我們可以抽取的樣本數很少，例如藥物的人體實驗，這是後使用z statistic就會變得不準確。這裡將介紹t Statistic來處理這個狀況。當樣本數小於30的時候我們面臨兩個問題 樣本數小於30，不能使用中央極限定理，也因此不能直接假設Sample Distribution為常態分佈。 解法:在前面我們可以發現到，如果母體為常態分佈，那即使樣本很少，Sample Distribution也會接近常態分佈。引此我們假設母體為常態分布。 母體標準差$\\sigma$是未知的而且我們不能再用單次抽樣的標準差s來代替，因為樣本數太少了。所以z statistic的公式也不能使用，因為他需要$\\sigma$良好的估計值。 解法:我們定義t statistic來處理這個問題。t statistic的公式如下\\(t=\\frac{\\bar{x}-\\mu}{s/\\sqrt{n}}\\) 在這裡sample statistic s是單次抽樣的標準差，取代了母體標準差$\\sigma$。假如我們是從常態分佈的母體抽樣，那麼t statistic的分佈會接近常態分佈。而t statistic和z statistic的差別在於t statistic多了一個random quantities s，也因此他的變動會比z statistic大。t的Sample Distribution中實際變異量取決於樣本大小n。我們通常將他表示為自由度(degrees of freedom)為n-1的t分佈。回顧一下(n-1)是計算$s^2$的分母，所以如果n越小那sample distribution的變異量就越大。對於small-sample 的confidence interval有以下結論 對於平均數$\\mu$，small-sample的confidence interval如下，其中$t_{\\frac{\\alpha}{2}}$為(n-1)自由度$\\bar{x} \\pm t_{\\frac{\\alpha}{2}}\\frac{s}{\\sqrt{n}}$ 計算small-sample的confidence interval有以下條件 樣本是隨機從母體抽出 母體的分布必須接近常態分布 5.3 Large-Sample Confidence Interval for a Population Proportion以市場調查為例，一間公司想知道消費者會選擇自己的品牌或是其他品牌。注意在這裡選擇品牌是一個qualitative variable，所以我們要用proportion來描述，而且這個問題是一個二元問題，因此我們要計算的是binoimal experiment中的p，也就是成功比例。要估計p我們可以利用計算樣本的成功比$\\hat p$\\[\\hat p=\\frac{x}{n}=\\frac{消費者選擇這間公司的品牌的人數}{問卷總人數}\\]而為了要計算$\\hat p$的可靠度，我們將$\\hat p$視為平均數，也就是說選擇這間公司品牌的人p計為1，選擇其他品牌的人q計為0，全部相加後除與總抽樣人數n，如此一來就可以用前面計算平均數的方法來推估$\\hat p$的可靠度。 $\\hat p$ 的Sampling Distribution $\\hat p$的Sampling Distribution的平均數為p $\\hat p$的Sampling Distribution的標準差為$\\sqrt{\\frac{pq}{n}}$，也就是$\\sigma_{\\hat p} = \\sqrt{\\frac{pq}{n}}$ 對於large samples，$\\hat p$的Sampling Distribution接近常態分佈。large samples的定義為np&gt;5且nq&gt;5。 常用參考資料https://cqeacademy.com/cqe-body-of-knowledge/quantitative-methods-tools/point-estimates-and-confidence-intervals/" }, { "title": "理解convolution", "url": "/posts/%E7%90%86%E8%A7%A3convolution/", "categories": "", "tags": "", "date": "2022-11-22 14:09:00 +0800", "snippet": "參考:But what is a convolution?https://www.youtube.com/watch?v=KuXjwB4LzSA" }, { "title": "BatchNormalization論文閱讀與實作", "url": "/posts/batchnormalization%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80%E8%88%87%E5%AF%A6%E4%BD%9C/", "categories": "", "tags": "", "date": "2022-11-22 13:59:00 +0800", "snippet": "參考:論文https://arxiv.org/pdf/1502.03167.pdfTraining Deep Neural Networks with Batch Normalizationhttps://zaffnet.github.io/batch-normalization反向傳播Computational GraphsCalculus on Computational Graphs: Backpropagationhttps://colah.github.io/posts/2015-08-Backprop/Neural Network Batch Normalization Fusionhttps://leimao.github.io/blog/Neural-Network-Batch-Normalization-Fusion/http://d2l.ai/chapter_convolutional-modern/batch-norm.htmlFUSING CONVOLUTION AND BATCH NORM USING CUSTOM FUNCTIONhttps://pytorch.org/tutorials/intermediate/custom_function_conv_bn_tutorial.html實作https://github.com/renan-cunha/BatchNormalization" }, { "title": "gdb教學二顯示Matrix或是Tensor", "url": "/posts/gdb%E6%95%99%E5%AD%B8%E4%BA%8C%E9%A1%AF%E7%A4%BAmatrix%E6%88%96%E6%98%AFtensor/", "categories": "", "tags": "", "date": "2022-11-21 17:32:00 +0800", "snippet": "參考:設定.gdbinithttps://interrupt.memfault.com/blog/using-pypi-packages-with-gdbGDB python modules https://sourceware.org/gdb/onlinedocs/gdb/Python.html#Python撰寫GDB pretty printerhttps://undo.io/resources/gdb-watchpoint/debugging-pretty-printers-gdb-part2/GDB array to numpyhttps://github.com/TorosFanny/gdb_numpy/blob/master/gdb_numpy.py" }, { "title": "gdb教學一基本操作", "url": "/posts/gdb%E6%95%99%E5%AD%B8%E4%B8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/", "categories": "開發工具", "tags": "cpp", "date": "2022-11-21 17:31:00 +0800", "snippet": "本篇文章修改參考這篇文章製作範例和教學，首先我們先寫一個有bug的程式factorial.c基本操作編譯程式給GDB如果要給GDB除錯，一定要加上-g選項gcc -g &lt;any other flags e.g. -Wall&gt; -o &lt;file&gt; &lt;file.c&gt;開啟GDB session在終端機輸入gdb和執行檔名稱即可開啟gdb sessiongdb &lt;program_name&gt;GNU gdb (Ubuntu 12.1-0ubuntu1~22.04) 12.1Copyright (C) 2022 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;...For help, type \"help\".Type \"apropos word\" to search for commands related to \"word\"...Reading symbols from factorial...(gdb) run指令用run指令執行程式。(gdb) run如果有程式有接收參數，可以直接放在run後面(gdb) run &lt;arg1&gt; &lt;arg2&gt; ... &lt;arg n&gt;如果要用檔案作為輸入，可以用&lt;(gdb) run &lt; &lt;data&gt;start指令用start指令執行程式，並且在main函式的第一行停下來。(gdb) start如果有程式有接收參數，可以直接放在run後面(gdb) start &lt;arg1&gt; &lt;arg2&gt; ... &lt;arg n&gt;如果要用檔案作為輸入，可以用&lt;(gdb) start &lt; &lt;data&gt;quit指令離開GDB可以用quit指令(gdb) quit範例以下面程式為範例//This program calculates and prints out the factorials of 5 and 17#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int factorial(int n);int main(void) {\t\tint n = 5;\tint f = factorial(n);\tprintf(\"The factorial of %d is %d.\\n\", n, f);\tn = 17;\tf = factorial(n);\tprintf(\"The factorial of %d is %d.\\n\", n, f);\treturn 0;\t\t}//A factorial is calculated by n! = n * (n - 1) * (n - 2) * ... * 1//E.g. 5! = 5 * 4 * 3 * 2 * 1 = 120int factorial(int n) {\tint f = 1;\tint i = 1;\twhile (i &lt;= n) {\t\tf = f * i;\t\ti++;\t}\treturn f;\t}用以下指令編譯gcc -Wall -g -o factorial factorial.c接下來開啟GDB sessiongdb factorial在GDB session中執行程式，會發現程式輸出錯誤的值(gdb) run如果要結束GDB session指令可以用quit。(gdb) quit中斷點break指令如果要放置中斷點在特定檔案的某一行，可以用break &lt;filename&gt;:&lt;line number&gt;指令(gdb) break &lt;filename&gt;:&lt;line number&gt;你也可以直接指定要放在哪一個function(gdb) break &lt;filename&gt;:&lt;function&gt;(gdb) break &lt;filename&gt;:&lt;function&gt;列出全部中斷點要列出全部的中斷點可以用以下指令(gdb) info breakdelete指令如果要刪除中斷點可以先用info break所有中斷點的號碼再刪除(gdb) delete &lt;breakpoint number&gt;範例接著前面的例子，我們懷疑程式的第15行有錯誤，因此在GDB session中把中斷點放在第15行並且執行程式(gdb) break 15(gdb) run我們應該會看到類似以下的輸出，你可以看到GDB輸出我們的第15行程式，代表現在程式停在第15行。注意!!這時候程式並還沒有執行第15行。GDB告訴我們的是他下一行將要執行的程式。[Thread debugging using libthread_db enabled]Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".The factorial of 5 is 120.Breakpoint 1, main () at factorial.c:1515 f = factorial(n);查看資料print指令印出變數(gdb) print &lt;variable_name&gt;info locals指令印出當前所有的local variable，除了輸入函式的參數以外。(gdb) info localsinfo args指令印出輸入給函式的參數(gdb) info args範例接續前面的範例，們想查看程式運作到中斷點時變數的值。首先查看f和n的值(gdb) print f$1 = 120(gdb) print n$2 = 17我們也可以用info locals來查看所有區域變數。(gdb) info localsn = 17f = 120查看程式運作當程式在中斷點停下後，利用step, next and continue可以控制程式運作以便我們逐行觀察程式運作的情形。step指令執行下一行程式，如果下一行程式是呼叫function，gdb就會進到function裡面。(gdb) stepnext指令執行下一行程式，與step不同的是，如果下一行是function，則將function執行完而不進入function。(gdb) nextcontinue指令執行程式直到碰到下一個中斷點(gdb) continuewhere指令印出function call stack(gdb) wherelist指令印出目前所在的行數以及前後各兩行。(gdb) list範例接續前面的範例。我們想要查看我們的factorial函式如何運作的。因此用step指令進入factorial函式。(gdb) stepfactorial (n=17) at factorial.c:2424 int f = 1;接下來我們想一步一步看看factorial函式如和運作的(gdb) next25 int i = 1;(gdb) next26 while (i &lt;= n) {(gdb) next27 f = f * i;(gdb) next28 i++;除了不斷輸入重複的指令，你也可以直接按Enter，GDB會重複你上一個指令。接下來我們預期執行到這裡，i和f應該要等於1(gdb) print i$2 = 1(gdb) print f$3 = 1如果我們想查看目前在程式哪一行，可以用where指令來印出call stack(gdb) where#0 factorial (n=17) at factorial.c:28#1 0x0000555555555196 in main () at factorial.c:15如果要印出目前行數前後的程式可以用list(gdb) list23 int factorial(int n) {24 int f = 1;25 int i = 1;26 while (i &lt;= n) {27 f = f * i;28 i++;29 }我們也可以用continue指令和中斷點來加速除錯，首先先下一個中斷點在第28行。(gdb) break 28Breakpoint 2 at 0x5555555551e1: file factorial.c, line 28.接下來用continue指令直接跳到這個中斷點(gdb) continueContinuing.Breakpoint 2, factorial (n=17) at factorial.c:2828 i++;然後依次印出所有區域變數info locals我們不斷重複這個動作，可以發現前面都還運作正常，直到i=13時，答案開始出出錯了，如果繼續執行會發現答案越來越小，甚至變成負的。這個錯誤原因是int這個資料型態無法儲存這麼大的值，我們必須使用更大的資料型態才能儲存。Call Stackcall Stack是由stack frames所組成。stack frames是用來儲存呼叫函式的時候函式的區域變數。如果函式內又呼叫另一個函式，新的一個stack frames會被放當前函式的stack frames的上面。當一個函式完成後，就會移除一個stack frames。where指令印出call stack並且包含檔名和行數。up指令往上移動stack一層frame(gdb) up(gdb) up &lt;n_frames&gt;down指令往下移動stack一層frame(gdb) down(gdb) down &lt;n_frames&gt;frame指令移動到指定的frame(gdb) frame &lt;frame_number&gt;範例如果錯誤出現在函式庫的程式碼，這時候用call stack來debug就會很有用，我們可以利用call stack來尋找我們的程式在什麼地方出錯。用下面範例corrupted_linked_list.c來講解。//Makes a linked list of length 7 and prints it out#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;struct node { int data; struct node *next;};struct node *create_node(int data);struct node *create_list(int length);void print_list(struct node *list);int main(void){ struct node *list1 = create_list(7); print_list(list1); return 0;}struct node *create_node(int data){ struct node *new = malloc(sizeof(struct node)); assert(new != NULL); new-&gt;data = data; new-&gt;next = NULL; return new;}struct node *create_list(int length) { struct node *head = NULL; if (length &gt; 0) { head = create_node(0); int i = 1; struct node *curr = head; while (i &lt; length) { curr-&gt;next = create_node(i); curr = curr-&gt;next; i++; } } return head;}void print_list(struct node *list){ struct node *curr = list; while (curr != NULL) { printf(\"%d-&gt;\", curr-&gt;data); curr == curr-&gt;next; } printf(\"X\\n\");}首先我們編譯並且執行程式，我們會發現程式進入無窮迴圈，於是我們強制程式停下來。$ gcc -g -o corrupted_linked_list corrupted_linked_list.c./corrupted_linked_list0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;**ctrl + c**我們預期程式的輸出應該像下面這樣./corrupted_linked_list0-&gt;1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6-&gt;X為了要了解程式到底錯在哪裡，我們在GDB session裡面執行程式。並且中斷程式$ gdb corrupted_linked_list(gdb) run0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0**ctrl + c**Program received signal SIGINT, Interrupt.0x00007fffff1272c0 in __write_nocancel () at ../sysdeps/unix/syscall-template.S:8484 ../sysdeps/unix/syscall-template.S: No such file or directory.中斷後我們可以用where指令看一下目前所在的位置，輸出會類似如下(gdb) where#0 0x00007fffff1272c0 in __write_nocancel () at ../sysdeps/unix/syscall-template.S:84#1 0x00007fffff0a8bff in _IO_new_file_write (f=0x7fffff3f5620 &lt;_IO_2_1_stdout_&gt;, data=0x6020f0, n=512) at fileops.c:1263#2 0x00007fffff0aa409 in new_do_write (to_do=512, data=0x6020f0 \"0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-\"..., fp=0x7fffff3f5620 &lt;_IO_2_1_stdout_&gt;) at fileops.c:518#3 _IO_new_do_write (fp=0x7fffff3f5620 &lt;_IO_2_1_stdout_&gt;, data=0x6020f0 \"0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-&gt;0-\"..., to_do=512) at fileops.c:494#4 0x00007fffff0a947d in _IO_new_file_xsputn (f=0x7fffff3f5620 &lt;_IO_2_1_stdout_&gt;, data=&lt;optimised out&gt;, n=2) at fileops.c:1331#5 0x00007fffff07d92d in _IO_vfprintf_internal (s=0x7fffff3f5620 &lt;_IO_2_1_stdout_&gt;, format=&lt;optimised out&gt;, ap=ap@entry=0x7ffffffedf08) at vfprintf.c:1663#6 0x00007fffff085899 in __printf (format=&lt;optimised out&gt;) at printf.c:33#7 0x000000000040071b in print_list (list=0x602010) at corrupted_linked_list.c:50#8 0x0000000000400628 in main () at corrupted_linked_list.c:17可以看到程式被中斷在標準函式庫的程式，不過我們想看一看輸入函式庫的參數是什麼。因此我們可以用up指令從frame 0 移動到 frame 1。或者我們直接用frame指令移動到我們要的地方(gdb) frame 7#7 0x000000000040071b in print_list (list=0x602010) at corrupted_linked_list.c:5050 printf(\"%d-&gt;\", curr-&gt;data);首先我們先看一下區域變數(gdb) info localscurr = 0x602010可以用ptype指令查看curr的型態，可以發現他是一個node struct的指針。(gdb) ptype currtype = struct node { int data; struct node *next;} *我們dereference查看一下內容(gdb) print *curr$1 = {data = 0, next = 0x602030}也可以查看其他的內容(gdb) print *(curr-&gt;next)$2 = {data = 1, next = 0x602050}(gdb) print *(curr-&gt;next-&gt;next)$3 = {data = 2, next = 0x602070}(gdb)Core Dumps程式當機當下程式的狀態對於除錯十分有幫助，我們可以利用core dump檔來記錄這些狀態。對於一些不定時發生的錯誤，這些除錯資訊就十分珍貴了。Core Dumps設定首先查看Core Dumps記錄功能有沒有被開啟，如果回傳0代表沒有打開Core Dumps記錄功能ulimit -c用以下指令設定打開Core Dumps記錄功能ulimit -c unlimited通常Core Dumps檔產生的位置會記路在/proc/sys/kernel/core_pattern這個設定，用以下指令查看Core Dumps檔的位置。產生Core Dump當Core Dumps紀錄功能打開後，如果程式遇到Segmentation fault的錯誤，就會產生Core Dump檔。用GDB查看Core Dump檔要查看Core Dump檔可以用以下指令。注意當我們利用Core Dump檔來除錯的時候，程式實際上並沒有在運作，所以step, next 和 continue 這些指令這時候是沒有功能的。gdb &lt;binary-file&gt; &lt;core-dump-file&gt;範例利用下面範例broken_linked_list.c將說明如何使用Core Dump除錯。//Makes a linked list of length 7 and prints it out#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;struct node { int data; struct node *next;};struct node *create_node(int data);struct node *create_list(int length);void print_list(struct node *list, int length);int main(void){ int length1 = 7; struct node *list1 = create_list(length1); print_list(list1, length1); return 0;}struct node *create_node(int data){ struct node *new = malloc(sizeof(struct node)); assert(new != NULL); new-&gt;data = data; new-&gt;next = NULL; return new;}struct node *create_list(int length) { struct node *head = NULL; if (length &gt; 0) { head = create_node(0); int i = 1; struct node *curr = head; while (i &lt; length) { curr-&gt;next = create_node(i); curr = curr-&gt;next; i++; } } return head;}void print_list(struct node *list, int length){ struct node *curr = list; int i = 0; while (i &lt;= length) { printf(\"%d-&gt;\", curr-&gt;data); curr = curr-&gt;next; i++; } printf(\"X\\n\");}編譯並且執行程式，可以看到程式出現Segmentation fault (core dumped)錯誤$ gcc -g -o broken_linked_list broken_linked_list.c$ ./broken_linked_listSegmentation fault (core dumped)接下來讀取Core Dump檔gdb broken_linked_list coreGDB將會顯示程式出錯的位置Program terminated with signal SIGSEGV, Segmentation fault.#0 0x000055be9593e283 in print_list (list=0x55be96c20260, length=7) at broken_linked_list.c:5151 printf(\"%d-&gt;\", curr-&gt;data);從這裡可以知道我們在第51行正在嘗試存取一個非法的記憶體位置。因此我們可以推測可能是curr的位址不正確或者是data是不可以讀取的位址。於是先嘗試印出curr的值(gdb) print curr$1 = (struct node *) 0x0可以看到curr是一個NULL址針。接下來我們在印出當前狀況的區域變數(gdb) info localscurr = 0x0i = 7可以看到i是7，也就是現在是第8次執行for迴圈，但是我們的Linking list只有7個節點，而且依照我們的建立Linking list的方式，第8個節點會是NULL址針，所以程式會出錯。我們在檢查一下Linking list本身是否有問題。(gdb) print *list$2 = {data = 0, next = 0x55be96c20280}可以看到Linking list的位址沒問題，因此可以更加確定問題就是迴圈多執行了一次。我們可以用list指令看一下程式現在所在的位置。(gdb) list4647 void print_list(struct node *list, int length){48 struct node *curr = list;49 int i = 0;50 while (i &lt;= length) {51 printf(\"%d-&gt;\", curr-&gt;data);52 curr = curr-&gt;next;53 i++;54 }55 printf(\"X\\n\");GDB Init File如果單純使用GDB的指令，有些變數就會變得難以查看，例如如果想要查看linked list的所有成員就會變得很麻煩。而GDB提供讓使用者自定義指令讓我們可以容易議處想要的結果。GDB User Initialization FileGEB啟動時會載入User Initialization File所記錄的指令，你可以建立一個新的User Initialization File，他的檔名是.gdbinit，放置的位置是home directory~/.gdbinit建立之後在檔案內加入下面指令，如此一來就可以在每一個專案下各自建立專屬的initialization file .gdbinitGDB專案自己的initialization file位在專案的跟目錄下，使用者可以自訂義指令或是GDB啟動的行為。~/&lt;file_path&gt;/.gdbinit基礎用法例如你的專案想要每次使用GDB的時候都會放一個breakpoint在某一個function，你就可以在.gdbinit寫入下面這行。break &lt;function_name&gt;GDB腳本語法定義命令你可以用以下命令定義一個自訂義命令define &lt;command&gt; &lt;code&gt;end增加命令說明你可以用以下命令為自訂義命令增加註解document &lt;command&gt; &lt;information about the command&gt;end如果要查看命令說明可以用以下命令(gdb) help &lt;command&gt;&lt;information about the command&gt;命令參數如果需要傳入參數給自訂義命令可以用以下方式(gdb) &lt;command&gt; &lt;arg0&gt; &lt;arg1&gt; &lt;arg2&gt; ...如果要在指令內使用參數可以用以下方式$argc$arg0$arg1$arg2...方便的內建變數可以用以下方式定義$&lt;variable_name&gt;設定變數用以下指令設定變數set $&lt;variable_name&gt; = &lt;value_or_expression&gt;if 聲明用以下方式可以做if聲明if &lt;condition&gt; &lt;code&gt;else &lt;code&gt;endwhile loopwhile &lt;condition&gt; &lt;code&gt;endPrintingGDB的print語法跟c十分相似printf \"&lt;format string&gt;\", &lt;arg0&gt;, &lt;arg1&gt;, ...使用自訂義命令使用者自訂義命令的用法跟內建指令的用法相同。(gdb) &lt;command&gt; &lt;arg0&gt; &lt;arg1&gt; &lt;arg2&gt; ...範例:除錯Linked lists下面將以除錯Linked list作為範例linked_list.c//Makes a linked list of length 7 and prints it out#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;struct node { int data; struct node *next;};struct node *create_node(int data);struct node *create_list(int length);void print_list(struct node *list);int main(void){ struct node *list1 = create_list(7); print_list(list1); return 0;}struct node *create_node(int data){ struct node *new = malloc(sizeof(struct node)); assert(new != NULL); new-&gt;data = data; new-&gt;next = NULL; return new;}struct node *create_list(int length) { struct node *head = NULL; if (length &gt; 0) { head = create_node(0); int i = 1; struct node *curr = head; while (i &lt; length) { curr-&gt;next = create_node(i); curr = curr-&gt;next; i++; } } return head;}void print_list(struct node *list){ struct node *curr = list; while (curr != NULL) { printf(\"%d-&gt;\", curr-&gt;data); curr = curr-&gt;next; } printf(\"X\\n\");}首先先把下面這行加入~/.gdbinitset auto-load safe-path /接下來撰寫自訂義命令，在專案根目錄也建立一個.gdbinitdefine p_generic_list set var $n = $arg0 while $n print *($n) set var $n = $n-&gt;next endenddocument p_generic_list p_generic_list LIST_HEAD_POINTER Print all the fields of the nodes in the linked list pointed to by LIST_HEAD_POINTER. Assumes there is a next field in the struct.enddefine indentby printf \"\\n\" set $i_$arg0 = $arg0 while $i_$arg0 &gt; 10 set $i_$arg0 = $i_$arg0 - 1 printf \"%c\", ' ' endend在命令裡面，我們建立一個變數來儲存第一個參數($arg0)，也就是linked list的指針set var $n = $arg0接下來印出 linked list的內容。print *($n)接下來把把linked list的指針指向下一個元素set var $n = $n-&gt;next運行結果如下$ gcc -g -o linked_list linked_list.c$ gdb -q ./linked_listReading symbols from ./linked_list...(gdb) br 18Breakpoint 1 at 0x11c3: file linked_list.c, line 18.(gdb) rStarting program: /home/steven/tmp/gcc_practice/linked_list [Thread debugging using libthread_db enabled]Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".Breakpoint 1, main () at linked_list.c:1818 print_list(list1);(gdb) p_generic_list list1$1 = {data = 0, next = 0x5555555592c0}$2 = {data = 1, next = 0x5555555592e0}$3 = {data = 2, next = 0x555555559300}$4 = {data = 3, next = 0x555555559320}$5 = {data = 4, next = 0x555555559340}$6 = {data = 5, next = 0x555555559360}$7 = {data = 6, next = 0x0}(gdb) watch and displaywatch可以監看一個變數，每當這個變數數值改變的時候就暫停程式。display 則是每當程式停止的時候顯示變數。watch使用以下指令設定想要監看的變數(gdb) watch &lt;variable_name&gt;查看Watchpoints查看Watchpoints的方式跟查看breakpoints的方式一樣(gdb) info breakpoints移除Watchpoints使用以下指令移除Watchpoints(gdb) disable &lt;watchpoint_number&gt;display使用以下指令設定display(gdb) display expression查看所有display查看所有display(gdb) info display移除display用以下指令移除display(gdb) delete display &lt;display_number&gt;範例以下將以計算階乘的程式factorial.c來做示範。程式在計算階層//This program calculates and prints out the factorials of 5 and 17#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int factorial(int n);int main(void) {\t\tint n = 5;\tint f = factorial(n);\tprintf(\"The factorial of %d is %d.\\n\", n, f);\tn = 17;\tf = factorial(n);\tprintf(\"The factorial of %d is %d.\\n\", n, f);\treturn 0;\t\t}//A factorial is calculated by n! = n * (n - 1) * (n - 2) * ... * 1//E.g. 5! = 5 * 4 * 3 * 2 * 1 = 120int factorial(int n) {\tint f = 1;\tint i = 1;\twhile (i &lt;= n) {\t\tf = f * i;\t\ti++;\t}\treturn f;\t}接著編譯程式並且用gdb讀取$ gcc -g -o factorial factorial.c$ gdb factorialReading symbols from factorial...done.首先先設定中斷點，可以看到n=5的時候晟是正常運作，讓嘗試繼續執行讓n=17(gdb) br factorialBreakpoint 1 at 0x11a5: file factorial.c, line 24.(gdb) rStarting program: ~/factorialBreakpoint 1, factorial (n=5) at factorial.c:2424 int f = 1;(gdb) cContinuing.The factorial of 5 is 120.Breakpoint 1, factorial (n=17) at factorial.c:2424 int f = 1;接下來設定watch和display，我們希望i初始化之後再設定watch和display，(gdb) n25 int i = 1;(gdb) n26 while (i &lt;= n) {然後設定watch和display(gdb) watch fHardware watchpoint 2: f(gdb) display i1: i = 1然後我們就可以觀察程式計算(gdb) cContinuing.Hardware watchpoint 2: fOld value = 1New value = 2factorial (n=17) at factorial.c:2828 i++;1: i = 2(gdb) cContinuing.Hardware watchpoint 2: fOld value = 2New value = 6factorial (n=17) at factorial.c:2828 i++;1: i = 3(gdb) cContinuing.Hardware watchpoint 2: fOld value = 6New value = 24factorial (n=17) at factorial.c:2828 i++;1: i = 4(gdb) cContinuing.Hardware watchpoint 2: fOld value = 24New value = 120factorial (n=17) at factorial.c:2828 i++;1: i = 5(gdb) cContinuing.Hardware watchpoint 2: fOld value = 120New value = 720factorial (n=17) at factorial.c:2828 i++;1: i = 6(gdb) cContinuing.Hardware watchpoint 2: fOld value = 720New value = 5040factorial (n=17) at factorial.c:2828 i++;1: i = 7(gdb) cContinuing.Hardware watchpoint 2: fOld value = 5040New value = 40320factorial (n=17) at factorial.c:2828 i++;1: i = 8(gdb) cContinuing.Hardware watchpoint 2: fOld value = 40320New value = 362880factorial (n=17) at factorial.c:2828 i++;1: i = 9(gdb) cContinuing.Hardware watchpoint 2: fOld value = 362880New value = 3628800factorial (n=17) at factorial.c:2828 i++;1: i = 10(gdb) cContinuing.Hardware watchpoint 2: fOld value = 3628800New value = 39916800factorial (n=17) at factorial.c:2828 i++;1: i = 11(gdb) cContinuing.Hardware watchpoint 2: fOld value = 39916800New value = 479001600factorial (n=17) at factorial.c:2828 i++;1: i = 12(gdb) cContinuing.Hardware watchpoint 2: fOld value = 479001600New value = 1932053504factorial (n=17) at factorial.c:2828 i++;1: i = 13我們可以觀察到當n=13的時候程式就開始出錯。條件式Breakpoints利用conditional breakpoints可以讓程式達到特定條件的時候才停下來。設定條件式Breakpoints的方法 建立一個中斷點如同前面所教的方法先建立一個中斷點。 (gdb) break &lt;file_name&gt; : &lt;line_number&gt;(gdb) break &lt;function_name&gt; 查看所有中斷點下面指令可以查看目前已經設定過的中斷點。 (gdb) info breakpoints 設定條件首先我們必須要知道中斷點的編號，並且用以下指令設定條件 (gdb) condition &lt;breakpoint_number&gt; condition 移除中斷點的停止條件如果想要移除中斷點的停止條件，可以用以下指令 (gdb) condition &lt;breakpoint_number&gt; 範例下面將繼續沿用階層計算程式factorial.c來示範conditional breakpoints//This program calculates and prints out the factorials of 5 and 17#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int factorial(int n);int main(void) {\t\tint n = 5;\tint f = factorial(n);\tprintf(\"The factorial of %d is %d.\\n\", n, f);\tn = 17;\tf = factorial(n);\tprintf(\"The factorial of %d is %d.\\n\", n, f);\treturn 0;\t\t}//A factorial is calculated by n! = n * (n - 1) * (n - 2) * ... * 1//E.g. 5! = 5 * 4 * 3 * 2 * 1 = 120int factorial(int n) {\tint f = 1;\tint i = 1;\twhile (i &lt;= n) {\t\tf = f * i;\t\ti++;\t}\treturn f;\t}編譯程式並啟動GDB$ gcc -g -o factorial factorial.c$ gdb factorialReading symbols from factorial...done.設定conditional breakpoints我們已經知道程式在i &lt;= 5 之前都正常運作，所以我們不必在確認i &lt;= 5 之前的輸出結果。因此我們設定的條件是 i &gt; 5。$ gdb factorialReading symbols from factorial...done.(gdb) br 28Breakpoint 1 at 0x11bf: file factorial.c, line 28.(gdb) condition 1 i &gt; 5開始除錯接下來就可以執行程式並且觀察不同i之下的輸出變化(gdb) rStarting program: ~/factorialThe factorial of 5 is 120.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 720i = 6(gdb) cContinuing.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 5040i = 7(gdb) cContinuing.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 40320i = 8(gdb) cContinuing.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 362880i = 9(gdb) cContinuing.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 3628800i = 10(gdb) cContinuing.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 39916800i = 11(gdb) cContinuing.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 479001600i = 12(gdb) cContinuing.Breakpoint 1, factorial (n=17) at factorial.c:2828 i++;(gdb) info localsf = 1932053504i = 13(gdb)我們可以發現i=13之後數值就開始出現異常了。除錯shared librarygcc印出所使用到的shared librarygcc -Wl,-t your_program.c -o your_program &gt; ld_output.txtgdb查看被載入的shared libraryinfo share每當有新的shared library被載入的時候就暫停set stop-on-solib-events 1https://jasonblog.github.io/note/gdb/li_yong_gdb_jin_xing_shared_library_de_chu_cuo.html參考:https://www.cse.unsw.edu.au/~learn/debugging/modules/gdb_basic_use/" }, { "title": "Python檢查記憶體用量", "url": "/posts/python%E6%AA%A2%E6%9F%A5%E8%A8%98%E6%86%B6%E9%AB%94%E7%94%A8%E9%87%8F/", "categories": "", "tags": "", "date": "2022-11-18 10:53:00 +0800", "snippet": "參考:介紹resident memory 和 allocated memoryhttps://pythonspeed.com/articles/measuring-memory-python/" }, { "title": "實作yolov2(YOLO9000)", "url": "/posts/%E5%AF%A6%E4%BD%9Cyolov2/", "categories": "深度學習", "tags": "yolo", "date": "2022-11-09 17:31:00 +0800", "snippet": "yolov2 詳細說明https://senliuy.gitbook.io/advanced-deep-learning/chapter1/yolo9000-better-faster-strongerDarknet-19與YOLOv2 目前Github上的YOLOv2已經被修改過，和論文上的描述並不一樣，必須參考最原始的cfg，而且必須要是voc的版本。https://github.com/pjreddie/darknet/blob/c6afc7ff1499fbbe64069e1843d7929bd7ae2eaa/cfg/yolo_voc.cfg論文的第三章Faster提到Darknet-19是一個classification model，他是YOLOv2的基礎。在Training for detection提到YOLOv2是刪掉Darknet-19的最後一個conv layers(以及他後面的其他layer)，並且用3個3 x 3 x 1024 conv layer 最後搭配 1 x 1 x 類別數量的conv layer。We modify this network for detection by removing the last convolutional layer and instead adding on three 3 × 3 convolutional layers with 1024 filters each followed by a final 1 × 1 convolutional layer with the number of outputs we need for detection.Darknet源碼註解region layer的biases就是anchors的值實作Conv2dBatchLeakyConvactivation為linear時沒有做任何事 https://github.com/AlexeyAB/darknet/blob/0faed3e60e52f742bbef43b83f6be51dd30f373e/src/gemm.c#L2337BatchNormal問題:在pytorch有momentum，在darknet有沒有?Leakyregion layerPytorch實作下面以圖片作為輸入來舉例 CONV2D: 輸入的tensor每一個維度所對應的是\\((N,C_{in},H,W)\\) \\(N\\): 照片張數，一次一張照片為1 \\(C_{in}\\):照片channel，彩色照片為3 \\(H\\): 照片高度 \\(W\\): 照片寬度 https://kikaben.com/yolo-v2-yolo9000/參考:yolov2架構講解(架構圖1x1 conv的地方有錯)https://kikaben.com/yolo-v2-yolo9000/完整yolov2實作(高參考價值)https://github.com/Tencent/ObjectDetection-OneStageDethttps://zhuanlan.zhihu.com/p/45039781http://yuenshome.space/timeline/2018-11/yolov2-region-source-code/https://github.com/tztztztztz/yolov2.pytorchhttps://github.com/gwinndr/YOLOv4-Pytorch/tree/master/model/layershttps://github.com/ruiminshen/yolo2-pytorch/blob/master/model/yolo2.py韓文Darknet介紹https://jjeamin.github.io/darknet_book/part3_src/batchnorm_layer.html" }, { "title": "實作yolov1", "url": "/posts/%E5%AF%A6%E4%BD%9Cyolov1/", "categories": "深度學習", "tags": "yolo", "date": "2022-11-08 10:18:00 +0800", "snippet": "計算layer輸出 首先可以看到輸入的圖片是448 x 448，然後經過7 x 7 x 64 stripe 2 的conv layer，以及2 x 2 stripe 2 的Maxpool layer。如果直接計算輸出的dimension，會發現計算有問題!!因為\\({ 輸入寬度 - kernel寬度 \\over stripe} \\ne 224\\)。查詢後發現如果去看yolov1.cfg，第一層的padding=1，也就是這層conv有paddind。首先先看到darknet/src/parser.c的parse_convolutional可以發現if(pad) padding = size/2;，也就是如果cfg的padding=1，padding的大小就是\\(\\lfloor {kernel \\ size \\over 2} \\rfloor\\) 取整數。所以第一層的padding是\\(\\lfloor {7 \\over 2} \\rfloor\\)取整數3。再去看darknet/src/convolutional_layer.c的make_convolutional_layer呼叫的convolutional_out_width，就可以看到詳細計算。conv的輸出尺寸是\\[\\lfloor{ {輸入長(寬) + 2 \\times padding - kernel \\ 長(寬)} \\over stride}\\rfloor + 1 = \\lfloor{447 \\over 2}\\rfloor + 1 = 224\\] 接下來是2 x 2 Maxpool layer，輸出尺寸為112，輸出channel是64!!不過如果直接對照圖看，會發現圖上寫112 x 112 x 192，這很可能是論文的圖寫錯了，因為如果用darknet幫你計算每一層的輸出的話應該是如下圖。 1 x 1 的conv稱為reduction layers Pytorch實作 下面以圖片作為輸入來舉例 CONV2D: 輸入的tensor每一個維度所對應的是\\((N,C_{in},H,W)\\) \\(N\\): 照片張數，一次一張照片為1 \\(C_{in}\\):照片channel，彩色照片為3 \\(H\\): 照片高度 \\(W\\): 照片寬度 darknet的conv layer程式碼疑問: for(i = 0; i &lt; l.nweights; ++i) l.weights[i] = scale*rand_normal(); #209其他紀錄計算總共有多少個weightslayer定義h:輸入高w:輸入寬c:輸入channeln:輸出channelsize:kernel sizenweights = (c / groups) * n * size * sizedarknet載入權重src -&gt; parser.c -&gt; load_convolutional_weights 讀取biases，每一個conv的filter都有一個，如yolov1第一層有64個 讀取batch_normalize 讀取scales，數量等於輸出channel 讀取rolling_mean，數量等於輸出channel 讀取rolling_variance，數量等於輸出channel 讀取weights計算weight數量史丹佛cs231n的這張圖解釋得非常清楚，權重的總數為輸入channel x kernel 寬 x kernel 高 x 輸出channellocal layer參考:Dive into Deep learninghttps://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html#strideCS231https://cs231n.github.io/convolutional-networks/#compDeep learninghttp://neuralnetworksanddeeplearning.comcaculate weights number : Convolution Demohttps://cs231n.github.io/convolutional-networks/Batch-Normalizationhttps://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338Locally Connected Layers說明https://www.cs.toronto.edu/~lczhang/aps360_20191/lec/w03/convnet.htmlUnderstanding Convolutionshttp://colah.github.io/posts/2014-07-Understanding-Convolutions/local connected layerhttp://sintesis.ugto.mx/WintemplaWeb/01Neural%20Lab/09Convolutional%20NN/10Locally%20Connected/index.htmlocal connected layer 實作https://github.com/pytorch/pytorch/pull/1583/fileslocal connected layer 實作https://github.com/nsoul97/yolov1_pytorch/blob/main/code/model.pylocal connected layer 實作https://github.com/pytorch/pytorch/issues/499GDBhttps://cotonne.github.io/gdb/2019/07/14/gdb-beginner-guide.htmlGDB https://condor.depaul.edu/glancast/373class/docs/gdb.htmlMath Syntaxhttps://www.rapidtables.com/math/symbols/Basic_Math_Symbols.htmlGDB指令:p sizeof(array)/sizeof(*array) ptype array 印出array長度印出指標array的長度p *l.biases@10 印出array的前10個元素" }, { "title": "CMake教學系列三建立CMake專案", "url": "/posts/cmake%E6%95%99%E5%AD%B8%E7%B3%BB%E5%88%97%E4%B8%89%E5%BB%BA%E7%AB%8Bcmake%E5%B0%88%E6%A1%88/", "categories": "環境設定與部屬", "tags": "cmake", "date": "2022-11-03 16:50:00 +0800", "snippet": "下載範例下面指令將會下載本文所需的範例git clone https://gitlab.com/CLIUtils/modern-cmake.gitcd modern-cmake/examples/simple-project/CMakeLists.txt解說 在第29行add_library(MyLibExample simple_lib.cpp simple_lib.hpp)增加了一個名為MyLibExample的target並且將會編譯一個MyLibExamplelibrary 第34行增加了一個add_executable(MyExample simple_example.cpp)增加了一個名為MyExample的target並且將會編譯一個MyExample的執行檔 第38行target_link_libraries(MyExample PRIVATE MyLibExample)連接了MyLibExample和MyExample這兩個target，注意你必須先製作target才能夠連接他們建置專案、編譯接下來你可以用以下指令建置專案並且編譯。CMake會產生一個build資料夾，在裡面你應該會看到libMyLibExample.alibrary和MyExample執行檔。你可以查看CMakeCache.txt看有哪些cache variable，接下來用./build/MyExample執行MyExample執行檔cmake -S . -B buildcmake --build build -j 8常見錯誤路徑中有空白set(VAR a b v)這個寫法會讓VAR變成一個list，並且擁有a b c三個元素，因此如果你的路徑像這樣，你的路徑就會被拆成兩段。set(MY_DIR \"/path/with spaces/\")target_include_directories(target PRIVATE ${MY_DIR})解決方法就是在${MY_DIR}外面再包一個引號set(MY_DIR \"/path/with spaces/\")target_include_directories(target PRIVATE \"${MY_DIR}\")除錯印出變數雖然message指令也可以印出變數，不過你有更好的選擇，cmake_print_properties、cmake_print_variables，記得要先include(CMakePrintHelpers)。如此一來你可以更加容易的印出target的屬性include(CMakePrintHelpers)cmake_print_variables(MY_VARIABLE)cmake_print_properties( TARGETS my_target PROPERTIES POSITION_INDEPENDENT_CODE)–trace-source 和 –trace-expand--trace-source讓你可以指定只要看你想看的CMakeLists.txt，--trace-expand變數全部展開，例如原本是add_library(simple_lib ${SOURCES} ${HEADERS} )加了--trace-expand變成add_library(simple_lib simple_lib.c simple_lib.h )下載這個範例，並且試看看cmake -S . -B build --trace-source=CMakeLists.txt 、 cmake -S . -B build --trace-source=CMakeLists.txt --trace-expand有什麼不一樣git clone git@github.com:hsf-training/hsf-training-cmake-webpage.gitcd hsf-training-cmake-webpage/code/04-debug除錯CMake的find_…模組沿用上面的範例，在這個範例你可以看到第16行有一個find_library(MATH_LIBRARY m)git clone git@github.com:hsf-training/hsf-training-cmake-webpage.gitcd hsf-training-cmake-webpage/code/04-debug試看看cmake -S . -B build --debug-find。記得要先清除build資料夾否會出現debug訊息。你也可以用CMAKE_FIND_DEBUG_MODE來針對你想要debug的find_…模組來除錯set(CMAKE_FIND_DEBUG_MODE TRUE)find_program(...)set(CMAKE_FIND_DEBUG_MODE FALSE)設定build types如果你想要執行C++ debugger，你會需要設定很多flag，CMake提供四種build types來幫你設定這些flag。 CMAKE_BUILD_TYPE=Debug : 輸出所有除錯訊息 CMAKE_BUILD_TYPE=RelWithDebInfo : release build 不過有一些額外的除錯訊息 CMAKE_BUILD_TYPE=Release : 最佳化release build CMAKE_BUILD_TYPE=MinSizeRel : minimum size release下面範例示範如何用CMake的Debug模式編譯，並且用GDB除錯 cd hsf-training-cmake-webpage/code/04-debugcmake -S . -B build-debug -DCMAKE_BUILD_TYPE=Debugcmake --build build-debuggdb build-debug/simple_example GDB指令 # GDB break my_sin r watch sign c 尋找套件find_package(MyPackage 1.2)這個命令會首先尋找CMAKE_MODULE_PATH這份路徑清單，在這些路徑底下尋找FindMyPackage.cmake這個檔案，注意他是直接把find_package第一個參數MyPackage產生出FindMyPackage.cmake這個搜尋目標，所以如果我們寫成find_package(OpenCV 3)，那搜尋目標就是FindOpenCV.cmake。如果找不到FindMyPackage.cmake他就會接著尋找MyPackageConfig.cmake，如果MyPackage_DIR存在的話也會搜尋這個路徑。在CMake3.12+之後，如果你的套件不是安裝在系統預設路徑，你可以設定環境變數&lt;PackageName&gt;_ROOT讓CMake搜尋。以下以Bash命令設定環境變數為例export HDF5_ROOT=$HOME/software/hdf5-1.12.0或者是設定CMAKE環境變數，以下以Bash命令設定環境變數為例export CMAKE_PREFIX_PATH=$HOME/software/hdf5-1.12.0:$HOME/software/boost-1.74.0:$CMAKE_PREFIX_PATHFindPackage.cmake這是舊方法(MODULE方法)，這裡有CMake提供的FindPackage清單PackageConfig這是由package開發者所提供，簡而言之如果你是package開發者，你應該提供&lt;package&gt;Config.cmake並且自行維護。CMake結合PkgConfig參考:https://hsf-training.github.io/hsf-training-cmake-webpage/08-debugging/index.htmlhttps://hsf-training.github.io/hsf-training-cmake-webpage/09-findingpackages/index.html現代CMake觀念https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right/CMake結合PkgConfighttps://stackoverflow.com/a/74038236" }, { "title": "CMake教學系列二 CMake的觀念", "url": "/posts/cmake%E6%95%99%E5%AD%B8%E7%B3%BB%E5%88%97%E4%BA%8C/", "categories": "環境設定與部屬", "tags": "cmake", "date": "2022-11-02 16:31:00 +0800", "snippet": "在第一篇我們已經學會如何編譯單一檔案的C++程式，接下來將介紹一些CMake的觀念關於Targets在CMake有兩種方式建立target，target的名稱必須是唯一的 add_executable(myexample simple.cpp) : 建立了一個名為myexample的target，並且命名輸出的執行檔為myexample add_library(mylibrary simplelib.cpp) : 建立了一個名為myexample的target，並且命名輸出的函式庫為myexampletarget很像程式裡面物件的概念，他擁有許多屬性，例如SOURCES在這個範例他會擁有simple.cpp這個檔案，target所有的屬性可以在這裡查到特別的targets有些C++函式庫只有標頭檔(例如函式庫Eigen)，這種情況下你沒辦法真正的輸出一個library檔，但是他又被製作成target讓其他target使用。這種函式庫我們叫做interface libraries而再CMake我們可以用下面指令把他製作成target。注意到跟前面不同的是他只需要設為INTERFACE屬性而且他不需要輸入*.cpp檔。add_library(some_header_only_lib INTERFACE)另一種狀況是你要直接使用預先編譯好的pre-built library，這種情況你也不會有*.cpp可以給CMake編譯。這種library在CMake裡我們稱為imported library，我們可以用關鍵字IMPORTED來告訴CMake。add_library(some_library STATIC IMPORTED)連接一旦你有了target就可以用target_link_libraries連接所需要的東西，連接的時候有PUBLIC, PRIVATE, 和 INTERFACE三種屬性可以選擇，他有點像程式語言中的存取控制。如果TargetB引用TargetA，則TargetA的PUBLIC屬性都會傳遞給TargetB。範例1: Include directories target_include_directories(TargetA PRIVATE mydir)連接TargetA和mydir資料夾屬性為PRIVATE，這時候TargetA的INCLUDE_DIRECTORIES屬性就會包含mydir資料夾 target_include_directories(TargetA INTERFACE mydir)連接TargetA和mydir資料夾屬性為INTERFACE，這時候TargetA的INTERFACE_INCLUDE_DIRECTORIES屬性就會包含mydir資料夾 target_include_directories(TargetA PUBLIC mydir)連接TargetA和mydir資料夾屬性為PUBLIC，則INCLUDE_DIRECTORIES INTERFACE_INCLUDE_DIRECTORIES都會包含mydir資料夾CMake變數為了方便起見，接下來的範例會直接執行example.cmake檔，而不是建立一個CMakeLists.txt。首先你需要先建立一個example.cmake，如果要執行example.cmake可以利用CMake的 -p 選項。這樣可以節省去許多編譯設定，也比較容易實驗# Assuming you have a file called example.cmake:cmake -P example.cmakeLocal variables在example.cmake輸入以下指令，然後執行cmake -P example.cmake就可以看到終端機輸出你的變數。在這裡set指令設定變數，message指令印出變數，這裡我們使用的是STATUSmessage，還有其他的狀態你可以到官網查看set(MY_VARIABLE \"I am a variable\")message(STATUS \"${MY_VARIABLE}\")Cached variablescached variables在CMake十分重要，通常我們會用CMake圖形介面或是CMake命令介面設定許多cached variables，這些變數都會被寫到CMakeCache.txt檔案裡面。當你執行CMake的時候CMake會先讀取這些Cached variables。下面這個範例會設定一個Cached variables，不過因為我們用-P執行*.cmake，所以不會真的輸出一個CMakeCache.txt，你可以參考上一篇的範例觀察CMake如何產生CMakeCache.txt。set(MY_VARIABLE \"I am a variable\")message(STATUS \"${MY_VARIABLE}\")而因為Cached variables幾乎都是可以讓使用者設定的選項，所以有一個更方便的指令optionoption(MY_OPTION \"On or off\" OFF)Other variables 你可以藉由$ENV{my_env}來取得環境變數my_env的值，你也可以利用if(DEFINED ENV{my_env})來檢查my_env這個環境變數是不是有被設定(注意這個指令沒有$) target的屬性其實也是一種變數，你可以利用get_property和set_property，或者是get_target_properties和set_target_properties來查看和設定target屬性，除此之外還有CMake本身的屬性，可以從cmake-properties這份清單查詢。Target properties and variables你已經知道target的屬性可以控制target的行為，如果你仔細觀察會發現，有許多target屬性(例如CXX_EXTENSIONS)會有一個對應的CMake變數，並且以CMAKE_為開頭(例如CMAKE_CXX_EXTENSIONS)，這些CMake變數是用來初始化對應的target屬性用的。因此你可以先設定這些CMake變數，這樣就可以快速設定target對應屬性的初始值。搜尋工具CMake有一些方便的glob指令可以用來處理[string](https://cmake.org/cmake/help/latest/command/string.html、file和list。例如下面指令會幫你產生一個list，裡標包含所有附檔名為*.cxx的檔案，並且把它儲存到OUTPUT_VAR裡面。你也可以用GLOB_RECURSE讓你可以連仔資料夾都尋找。這些工具可以在這份文件找到。file(GLOB OUTPUT_VAR *.cxx)在這裡要提到一個很重要的flagCONFIGURE_DEPENDS(CMake 3.12+)，如果沒有這個flag則在重新執行建置的時候，cmake不會再次用glob去搜尋，如此一來如果這些被搜尋的資料夾放入的新的檔案也不會被CMake發現。因此如果你想要在每一次建置專案的時候都重新搜尋，記得加上這個flagfile(GLOB OUTPUT_VAR *.cxx CONFIGURE_DEPENDS)參考:CMake Fundamentals Part 4https://jeremimucha.com/2021/02/cmake-fundamentals-part4/Modern CMake is like inheritancehttps://kubasejdak.com/modern-cmake-is-like-inheritanceCMake doc : Importing Librarieshttps://cmake.org/cmake/help/latest/guide/importing-exporting/index.html#importing-librarieshttps://cliutils.gitlab.io/modern-cmake/chapters/basics.htmlhttps://hsf-training.github.io/hsf-training-cmake-webpage/04-targets/index.htmlhttps://hsf-training.github.io/hsf-training-cmake-webpage/05-variables/index.html" }, { "title": "安裝Vagrant製作測試環境", "url": "/posts/%E5%AE%89%E8%A3%9Dvagrant%E8%A3%BD%E4%BD%9C%E6%B8%AC%E8%A9%A6%E7%92%B0%E5%A2%83/", "categories": "環境設定與部屬", "tags": "Vagrant", "date": "2022-11-01 13:50:00 +0800", "snippet": "安裝Ubuntu22.04安裝Vagrantwget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpgecho \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.listsudo apt update &amp;&amp; sudo apt install vagrant安裝VirtualBox在/etc/apt/sources.list最下面加上這一行deb [arch=amd64 signed-by=/usr/share/keyrings/oracle-virtualbox-2016.gpg] https://download.virtualbox.org/virtualbox/debian jammy contrib然後下載和註冊public keywget -O- https://www.virtualbox.org/download/oracle_vbox_2016.asc | sudo gpg --dearmor --yes --output /usr/share/keyrings/oracle-virtualbox-2016.gpg顯示fingerprint，應該要為B9F8 D658 297A F3EF C18D 5CDF A2F6 83C5 2980 AECFgpg --show-keys --with-fingerprint /usr/share/keyrings/oracle-virtualbox-2016.gpg最後安裝sudo apt-get updatesudo apt-get install virtualbox-6.1建立一個Ubuntu20.04 boxvagrant init ubuntu/focal64vagrant upvagrant sshx11 forwardinghttps://jcook0017.medium.com/how-to-enable-x11-forwarding-in-windows-10-on-a-vagrant-virtual-box-running-ubuntu-d5a7b34363f共享資料夾https://developer.hashicorp.com/vagrant/tutorials/getting-started/getting-started-synced-folders參考:安裝VirtualBoxhttps://www.virtualbox.org/wiki/Linux_Downloads顯示gpg fingerprint https://superuser.com/a/1747762" }, { "title": "Linux安裝prebuild函式庫以OpenCV為例", "url": "/posts/Linux%E5%AE%89%E8%A3%9Dprebuild%E5%87%BD%E5%BC%8F%E5%BA%AB%E4%BB%A5OpenCV%E7%82%BA%E4%BE%8B/", "categories": "環境設定與部屬", "tags": "cpp", "date": "2022-10-30 22:02:00 +0800", "snippet": " 我的部落格文章轉錄–Linux環境撰寫Shared Library有詳細介紹如何製作和安裝Shared Library，如果想要了解更多Shared Library安裝和製作方式可以參考這篇。在這篇我們想直接使用OpenCV預編譯的函式庫，省去自己編譯函式庫的時間，首先我們先到官網提到的Third-party packages的System packages in popular Linux distributions，找到自己的Linux distributions，在這裡我們是使用Ubuntu22，而我們要下載的是development files for opencv也就是libopencv-dev_4.5.4+dfsg-9ubuntu4_amd64.deb這個連結，在Install Howto的地方可以看到安裝指令。 如果你不想弄亂你的環境，建議你可以用Vagrant建立一台測試環境來測試一下安裝後的結果，或是做一些實驗。安裝Vagrant的方法在安裝vagrant製作測試環境sudo apt-get updatesudo apt-get install libopencv-dev在Files的地方可以看到他幫我們裝了什麼東西以及他們被安裝的位置。在Requires的地方可以看到他還幫我們安裝了哪些相依套件。在這裡我們比較一下libopencv-core-dev和libopencv-core4.5d這兩個函式庫。在這兩個package的Files的地方可以發現libopencv-core-dev幫我們在/usr/include/opencv4多裝了很多標頭檔(*.hpp)，因為如果要在我們自己的C++中使用OpenCV，必須要include OpenCV的標頭檔，而dev套件已經幫我們幫把標頭檔都放在/usr/include/opencv4讓我們可以引用了。而在編寫OpenCV的C++專案的時候，要記得把這個include資料夾放到你的專案裡。pkg-config幫我們列出全部的標頭檔位置和opencv的名稱標頭檔路徑只需要加上g++選項-I/usr/include/opencv4就可以了，不過如果要把所有用到的library都手動寫出來實在很麻煩，這時候pkg-config可以幫我們把全部的opencv library全部列出來，我們可以試看看在終端機輸入下面指令pkg-config --libs --cflags opencv4(如果安裝的是opencv 2.x或3.x要輸入pkg-config --libs --cflags opencv)，終端機的回應應該會長的像下面這樣。$ pkg-config --libs --cflags opencv4-I/usr/include/opencv4 -lopencv_stitching -lopencv_alphamat -lopencv_aruco -lopencv_barcode -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_shape -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_ml -lopencv_videostab -lopencv_videoio -lopencv_viz -lopencv_wechat_qrcode -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_coreg++的指令是長這樣/usr/bin/g++ -g main.cpp -o main `pkg-config --libs --cflags opencv4`你可以到linux下設定vscode-cmake-gcc-gdb來開發c-專案查看如何用VSCode連接和編譯OpenCV library。參考:https://blog.gtwang.org/programming/ubuntu-linux-install-opencv-cpp-python-hello-world-tutorial/https://pkgs.org/search/?q=opencvhttps://ubuntu.pkgs.org/22.04/ubuntu-universe-amd64/libopencv-dev_4.5.4+dfsg-9ubuntu4_amd64.deb.html" }, { "title": "文章轉錄--Linux環境撰寫Shared Library", "url": "/posts/%E6%96%87%E7%AB%A0%E8%BD%89%E9%8C%84-Linux%E7%92%B0%E5%A2%83%E6%92%B0%E5%AF%ABShared-Library/", "categories": "環境設定與部屬", "tags": "cpp", "date": "2022-10-29 20:43:00 +0800", "snippet": "撰寫範例程式bool isPalindrome(char* word);#include \"pal.h\"#include &lt;string.h&gt; bool isPalindrome(char* word){ bool ret = true; char *p = word; int len = strlen(word); char *q = &amp;word[len-1]; for (int i = 0 ; i &lt; len ; ++i, ++p, --q) { if (*p != *q) { ret = false; } } return ret;}編譯shared library在終端機輸入以下GCC指令，注意這裡我們有-c選項，這告訴GCC不要進行linking stage，如果沒加GCC就會報錯，因為一個應用程式一定會有main()函式，但是Library不需要main()函式。這行指令將會產生一個pal.o檔g++ -fPIC -c -Wall pal.cpp接下來我們要用pal.o檔和以下指令產生真正的library。ld是linker program，通常會被g++呼叫。-shared告訴ld製作一個shared object，以pal.o為輸入輸出名為libpal.so。在Linux通常shared libraries的副檔名都是.so。ld -shared pal.o -o libpal.so使用shared library首先建立一個main.cpp來呼叫我們的library的isPalindrome函式。在程式中我們include函式庫的標頭檔pal.h#include \"pal.h\"#include &lt;iostream&gt; using namespace std; int main(){ while (1) { char buffer[64] = {0}; cin &gt;&gt; buffer; if (isPalindrome(buffer)) { cout &lt;&lt; \"Word is a palindrome\" &lt;&lt; endl; } else { cout &lt;&lt; \"Word is not a palindrome\" &lt;&lt; endl; } } return 0;}接下來我們可能直接用g++ -Wall main.cpp -lpal這行指令連接我們的shared library，c但是如果這麼做我們會得到下面錯誤訊息。這是因為ld在預設的搜尋路徑下找不到libpal.so/usr/bin/ld: cannot find -lpal: No such file or directorycollect2: error: ld returned 1 exit status其中一種解法是用g++告入ld函式庫的位置g++ -Wall -L&lt;libpal.so的路徑&gt; -Wl,-rpath=&lt;libpal.so的路徑&gt; main.cpp -lpal例如g++ -Wall -L/home/faye -Wl,-rpath=/home/faye/ main.cpp -lpal其中: -Wall是用來檢查所有編譯警告的 L式shared library的路徑，讓ld知道要去那裡尋找 -Wl是一連串用逗號分隔的linker指令，在這裡有 -rpath表示library 的路徑會被嵌入到主程式的執行檔，因此loader在執行主程式的時候可以找到library -L與-rpath的區別是: -L是給linker用的 -rpath是被嵌入到執行檔給loader看的最後g++會幫我們產生a.out執行檔，執行方式和結果如下$ ./a.out adaWord is a palindrometeamWord is not a palindrome安裝自己開發的Shared Libraries用剛剛的方式連接Shared Libraries的方法有個缺點，也就是你的編譯指令直接給其他人的話可能會出錯，因為Shared Libraries在每個人的電腦上的位置可能都不一樣。因此rpath和-L選項的路徑也會不一樣。而我們的解決方法之一就是LD_LIBRARY_PATHLD_LIBRARY_PATH如果我們直接在終端機輸入指令echo $LD_LIBRARY_PATH看LD_LIBRARY_PATH的值，他應該會是空的，除非你以前曾經設定過他。要是用LD_LIBRARY_PATH我們只需要以下指令export LD_LIBRARY_PATH=&lt;Shared Library所在資料夾&gt;:$LD_LIBRARY_PATH例如export LD_LIBRARY_PATH=/home/faye:$LD_LIBRARY_PATH這時在輸入一次echo $LD_LIBRARY_PATH應該就會輸出/home/faye:。而這時候我們編譯main.cpp的時候就算沒有-rpath選項編譯出來的執行檔也不會找不到libpal.sog++ -Wall -L/home/faye/sotest main.cpp -lpal 你可以先嘗試看看在還沒設定LD_LIBRARY_PATH之前或是利用unset LD_LIBRARY_PATH指令清空LD_LIBRARY_PATH變數，所編譯出來的執行檔會出現什麼問題。你應該會發現編譯的過程沒有任何錯誤訊息，但是一旦你執行編譯出來的執行檔a.out就會跳出錯誤訊息./a.out: error while loading shared libraries: libpal.so: cannot open shared object file: No such file or directory，這表示執行檔loader找不到libpal.so檔不過LD_LIBRARY_PATH其實只適合在開發階段拿來測試library用，因為它不需要root權限，但是函式庫發布給大家使用的時候，要求每個人都去設定LD_LIBRARY_PATH並不是個好方法。ldconfig : 安裝Shared Libraries正統方法首先我們先清除上一個教學的LD_LIBRARY_PATH設定，可以用unset LD_LIBRARY_PATH指令來清除。接下來我們必須把我們的函式庫複製到/usr/lib資料夾。複製函式庫到/usr/lib必須擁有root權限，因此我們用sudo來幫助我們。sudo mv &lt;函式庫所在資料夾&gt;/libpal.so /usr/lib例如sudo mv /home/faye/libpal.so /usr/lib接下來更新系統中儲存可用libraries的cache。sudo ldconfig你可以用下面指令來確定cache已經被更新了而且系統可以找到你的函式庫ldconfig -p | grep libpal系統應該會回應你libpal.so (libc6,x86-64) =&gt; /lib/libpal.so接下來你就可以用下面指令編譯我們的執行檔了，而且這次我們不需要-rpath，也不需要-L選項!!因為現在我們的函式庫已經位於系統預設的函式庫搜尋路徑下了。g++ -Wall main.cpp -lpal參考:https://www.fayewilliams.com/2015/07/07/creating-a-shared-library/https://www.fayewilliams.com/2015/07/14/installing-and-accessing-shared-libraries/相關文章:Linux安裝prebuild函式庫以OpenCV為例" }, { "title": "Linux下設定VScode、CMake、GCC、GDB來開發C++專案", "url": "/posts/linux%E4%B8%8B%E8%A8%AD%E5%AE%9Avscode-cmake-gcc-gdb%E4%BE%86%E9%96%8B%E7%99%BCc-%E5%B0%88%E6%A1%88/", "categories": "IDE", "tags": "VSCode", "date": "2022-10-28 17:52:00 +0800", "snippet": "安裝套件 cmake extension c++ extension 安裝編譯器GCC、除錯器DBG sudo apt-get updatesudo apt-get install build-essential gdbgcc -v #確認GCC安裝成功 注意:GDB 12.09 版本在VSCode除錯的時候會有錯誤，可以參考下面方式將GDB升級到12.10以上版本升級GDBGDB issue 安裝CMake直接用sudo apt install cmake，安裝的版本會比較舊，因此如果想用CMake最新的功能可以按照官方網站的安裝方式，安裝後我們可以測試一下CMake安裝成功，在這裡我們CMake的版本至少要大於3.15 cmake --version 編譯C++檔用以下指令建立一個專案資料夾，最後一行code .會直接打開一個新的VScode並且以這個資料夾作為工作目錄mkdir projectscd projectsmkdir helloworldcd helloworldcode .在helloworld資料夾建立helloworld.cpp檔案並且寫入以下程式碼，然後按下編譯按鈕，並且選擇g++作為編譯器(如下圖所示)#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace std;int main(){ vector&lt;string&gt; msg {\"Hello\", \"C++\", \"World\", \"from\", \"VS Code\", \"and the C++ extension!\"}; for (const string&amp; word : msg) { cout &lt;&lt; word &lt;&lt; \" \"; } cout &lt;&lt; endl;}成功編譯後，你會在Terminal看到程式成功輸出文字第一次按下執行compiler後，VScode會幫你建立一個.vscode資料夾和一個，tasks.json。或是你可以自己建立一個.vscode資料夾並且放入tasks.json。{ \"tasks\": [ { \"type\": \"cppbuild\", \"label\": \"C/C++: gcc-9 build active file\", \"command\": \"/usr/bin/gcc-9\", \"args\": [ \"-fdiagnostics-color=always\", \"-g\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"Task generated by Debugger.\" } ], \"version\": \"2.0.0\"}在這個資料夾下可以有三種檔案，每個檔案各有自己的用處，關於tasks.json詳細設定可以參考這裡 tasks.json (compiler build settings) launch.json (debugger settings) c_cpp_properties.json (compiler path and IntelliSense settings)在tasks.json裡面有幾個的比較重要的點 args是給GCC的參數，要符合GCC參數的順序 在這裡我們用${file}這個變數告訴GCC目前打開的檔案讓他編譯 ${fileDirname}這個變數告訴GCC目前的資料夾位置，讓他在這個位置產生我們的執行檔 ${fileBasenameNoExtension}變數取出目前開啟的檔名但是不包含副檔名，我們用這個名字作為我們的執行檔名，也就是helloworld label會顯示在task清單 detail 會顯示在task清單的詳細描述。先按下Ctrl+P並且輸入task (task後面有空白)，就會顯示task清單，包含我們建立的task(如下圖所示) 如果有多個task，可以利用group裡面isDefault屬性設定預設task除錯、設中斷點 在程式碼下一個中斷點，並且點及旁邊的執行按鈕並且選擇Debug就可以開始除錯了設定在啟動程式時傳入參數給程式如果像在啟動程式時傳入一些參數，可以利用launch.json，要建立launch.json只需要案價旁邊的齒輪並選擇G++，VSCode就會自動幫你建立一份在launch.json裡面有幾個的比較重要的點 program是要執行的執行檔名稱，也就是我們編譯後產生的helloworld檔 args是執行時要傳給執行檔的參數C/C++的其他設定通常編寫C/C++的時候也會用到很多函式庫，我們可以指定這些函式庫的路徑讓VSCode的Intelligence Scope懂這些函式庫。首先按下Ctrl+Shift+P並且輸入C/C++，按下C/C++: Edit Configurations (UI)，後VSCode會幫我們產生一個c_cpp_properties.json。在Include path的地方加入我們要包含的路徑。或者我們也可以在c_cpp_properties.jsonconfigurations下的includePath直接做修改g++ include OpenCV函式庫首先我們先按照Linux安裝prebuild函式庫以OpenCV為例這篇文章安裝prebuild的OpenCV library。接下來建立一個ShowImage.cpp#include &lt;opencv2/core.hpp&gt;#include &lt;opencv2/imgcodecs.hpp&gt;#include &lt;opencv2/highgui.hpp&gt;#include &lt;iostream&gt;using namespace cv;int main(){ std::string image_path = samples::findFile(\"starry_night.jpg\"); Mat img = imread(image_path, IMREAD_COLOR); if(img.empty()) { std::cout &lt;&lt; \"Could not read the image: \" &lt;&lt; image_path &lt;&lt; std::endl; return 1; } imshow(\"Display window\", img); int k = waitKey(0); // Wait for a keystroke in the window if(k == 's') { imwrite(\"starry_night.png\", img); } return 0;}我們可以發現VSCode的Intelligence scope找不到OpenCV標頭檔而顯示紅色虛線。這時候我們需要修改前面步驟提到的c_cpp_properties.jsoninclude OpenCV的路徑就可以了，而因為我們是安裝prebuild的OpenCV，所以我們的標頭檔已經被安裝在/usr/include/opencv4/裡面，因此修改後的c_cpp_properties.json如下。我們在includePath的清單中加入了/usr/include/opencv4/**，之後你就可以看到Intelligence scope成功認出OpenCV，而且OpenCV的函示可以順利顯示說明文字{ \"configurations\": [ { \"name\": \"Linux\", \"includePath\": [ \"${workspaceFolder}/**\", \"/usr/include/opencv4/**\" ], \"defines\": [], \"compilerPath\": \"/usr/bin/gcc\", \"cStandard\": \"gnu17\", \"cppStandard\": \"gnu++17\", \"intelliSenseMode\": \"linux-gcc-x64\" } ], \"version\": 4}不過這時候g++依然不知道OpenCV的標頭檔在哪裡，所以如果直接編譯還是會出錯。pkg-config幫我們列出全部的標頭檔位置和opencv的名稱標頭檔路徑只需要加上g++選項-I/usr/include/opencv4就可以了，不過如果要把所有用到的library都手動寫出來實在很麻煩，這時候pkg-config可以幫我們把全部的opencv library全部列出來，我們可以試看看在終端機輸入下面指令pkg-config --libs --cflags opencv4(如果安裝的是opencv 2.x或3.x要輸入pkg-config --libs --cflags opencv)，終端機的回應應該會長的像下面這樣。$ pkg-config --libs --cflags opencv4-I/usr/include/opencv4 -lopencv_stitching -lopencv_alphamat -lopencv_aruco -lopencv_barcode -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_shape -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_ml -lopencv_videostab -lopencv_videoio -lopencv_viz -lopencv_wechat_qrcode -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core我們可以發現回傳的文字可以直接當成g++的選項來用，因此我們修改tasks.json，在給g++的參數args的list加入\"`pkg-config --libs --cflags opencv4`\"改好後tasks.json如下，注意pkg-config --libs --cflags opencv4被兩個引號包圍，因為原本g++的指令是長這樣/usr/bin/g++ -g main.cpp -o main `pkg-config --libs --cflags opencv4`{ \"tasks\": [ { \"type\": \"cppbuild\", \"label\": \"C/C++: g++ build active file\", \"command\": \"/usr/bin/g++\", \"args\": [ \"-fdiagnostics-color=always\", \"-g\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\", \"`pkg-config --libs --cflags opencv4`\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"Task generated by Debugger.\" } ], \"version\": \"2.0.0\"}接下來VSCode就可以順利編譯程式並產生執行檔了。用CMake管理跨Windows和Linux的C++專案以Darknet為例如果開發團隊中有人用Windows OS開發，有人用Linux OS開發，而Windows的人只熟悉Visual Studio。這時候要一起合作完成專案在編譯的時候就會遇到困難。CMake跨平台的專案產生器就是專門解決這個問題。只要寫好一次CMake檔，他就可以在Windows幫你產生Visual Studio專案檔.sln，或是在Linux產生Makefile。很多時候我們會想要直接編譯別人的開源程式，這裡我們將以Darknet作為範例。開始這個範例之前你必須先在電腦上安裝好OPenCV下載Darknetgit clone git@github.com:AlexeyAB/darknet.gitcd darknet建立CMake的task.json按下ctrl + shift + p並且輸入task，選擇Tasks: Configure task，然後再選擇CMake: build，就task設定就會產生在${workspaceFolder}/.vscode/tasks.json{\t\"version\": \"2.0.0\",\t\"tasks\": [\t\t{\t\t\t\"type\": \"cmake\",\t\t\t\"label\": \"CMake: build\",\t\t\t\"command\": \"build\",\t\t\t\"targets\": [\t\t\t\t\"all\"\t\t\t],\t\t\t\"group\": \"build\",\t\t\t\"problemMatcher\": [],\t\t\t\"detail\": \"CMake template build task\"\t\t}\t]}這個檔案會編譯所有的CMake Targets，你也可以指定你想編譯的targets。設定build參數首先我們先查看Darknet有哪些CMake項可以設定，輸入cmake -S . -B build -LH就可以看到選項。在這個範例不想要使用CUDA，所以要把ENABLE_CUDA:BOOL=ON設為OFF。我們可以建立一個設定檔在${workspaceFolder}/.vscode/settings.json，並且輸入以下內容。更多其他的CMake設定可以在這裡查到。另外因為Darknet已經存在build資料夾，所以我們指定其他資料夾作為build資料夾cmake.buildDirectory\": \"${workspaceFolder}/local-build，不過通常我們可以直接用預設值，並不需要另外設定cmake.buildDirectory{ \"cmake.configureArgs\": [ \"-DENABLE_CUDA=OFF\", \"-DVCPKG_BUILD_OPENCV_WITH_CUDA=OFF\" ], \"cmake.buildDirectory\": \"${workspaceFolder}/local-build\"}CMake Config首先我們要先跑一次CMake Config，按下ctrl + shift + p輸入cmake選擇CMake:Configure，在Output的地方會看到有沒有錯誤，如果出現錯誤歡迎在下面留言板留言。建立launch.json接下來要設定啟動，先建立一個launch.json位於${workspaceFolder}/.vscode/launch.json，並且複製以下內容。在這裡用到許多CMake extension提供的變數，可以在這裡查詢更多的變數。{ \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"(gdb) Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", // Resolved by CMake Tools: \"program\": \"${command:cmake.launchTargetPath}\", \"args\": [], \"stopAtEntry\": false, \"cwd\": \"${workspaceFolder}\", \"environment\": [ { // add the directory where our target was built to the PATHs // it gets resolved by CMake Tools: \"name\": \"PATH\", \"value\": \"${env:PATH}:${command:cmake.getLaunchTargetDirectory}\" }, { \"name\": \"OTHER_VALUE\", \"value\": \"Something something\" } ], \"console\": \"externalTerminal\", \"MIMode\": \"gdb\", \"setupCommands\": [ { \"description\": \"Enable pretty-printing for gdb\", \"text\": \"-enable-pretty-printing\", \"ignoreFailures\": true } ] } ]}{= file:’launch.json’}設定啟動時參數首先要先下載yolov1.cfg和yolov1.weights並且放到cfg資料夾Darknet執行檔啟動時需要參數，我們可以在launch.json的args設定。\"args\": [\"detect\", \"cfg/yolov1.cfg\", \"cfg/yolov1.weights\", \"data/dog.jpg\"],執行參考:Build with CMake Toolshttps://github.com/microsoft/vscode-cmake-tools/blob/f4804bcd2d376b4ad850c537d6ebdae46cfdcf3c/docs/build.mdhttps://code.visualstudio.com/docs/cpp/config-linuxDisplay an image in an OpenCV windowhttps://docs.opencv.org/4.x/db/deb/tutorial_display_image.htmlpkg-config尋找opencv函式庫https://answers.opencv.org/question/227890/using-l-in-g-command-line/Get started with CMake Tools on Linuxhttps://code.visualstudio.com/docs/cpp/cmake-linuxCMake Tools for Visual Studio Code documentationhttps://github.com/microsoft/vscode-cmake-tools/blob/main/docs/README.mdGuide: “A modern, open source C++ dev environment with Visual Studio Code, vcpkg, and CMake”https://www.reddit.com/r/cpp/comments/j1dh9w/guide_a_modern_open_source_c_dev_environment_with/" }, { "title": "Ubuntu NTP 校時", "url": "/posts/%E8%A8%AD%E5%AE%9AUbuntu-NTP-%E6%A0%A1%E6%99%82/", "categories": "環境設定與部屬", "tags": "Ubuntu", "date": "2022-10-28 12:20:00 +0800", "snippet": "timedatectl 時間管理工具 顯示目前的設定狀態 # 顯示目前狀態timedatectl Local time: 三 2023-04-26 11:00:22 CST Universal time: 三 2023-04-26 03:00:22 UTC RTC time: 三 2023-04-26 03:00:22 Time zone: Asia/Taipei (CST, +0800) System clock synchronized: yes NTP service: active RTC in local TZ: no 啟動網路校時輸入下面指令後，就會打開網路校時功能 # 啟用 NTP 校時timedatectl set-ntp yes Ubuntu使用的是systemd-timesyncd，因此等一下要設定systemd-timesyncd 檢查systemd-timesyncd服務狀態 # 檢查 systemd-timesyncd 服務狀態systemctl status systemd-timesyncd ● systemd-timesyncd.service - Network Time Synchronization Loaded: loaded (/lib/systemd/system/systemd-timesyncd.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2023-04-26 10:58:34 CST; 1min 19s ago Docs: man:systemd-timesyncd.service(8) Main PID: 221565 (systemd-timesyn) Status: \"Synchronized to time server 91.189.89.198:123 (ntp.ubuntu.com).\" Tasks: 2 (limit: 38317) Memory: 1.2M CGroup: /system.slice/systemd-timesyncd.service └─221565 /lib/systemd/systemd-timesyncd 設定校時伺服器要設定校時伺服器可以用root權限編輯以下檔案/etc/systemd/timesyncd.conf[Time]# NTP 伺服器（以空白分隔多個伺服器）NTP=tw.pool.ntp.org jp.pool.ntp.org# 備用 NTP 伺服器（以空白分隔多個伺服器）FallbackNTP=sg.pool.ntp.org ntp.ubuntu.com 重新啟動systemd-timesyncd服務重啟服務讓更改生效 # 重新啟動 systemd-timesyncd 服務systemctl restart systemd-timesyncd 檢查一下是不是有跟NTP校時了用指令systemctl status systemd-timesyncd看一下目前服務狀態，如果有更新成功會顯示出來錯誤排除 出現Server has too large root distance. Disconnecting.訊息表示機器跟ntp server之間回應的時間太久，因此可以去修改/etc/systemd/timesyncd.conf並加入RootDistanceMaxSec=，通常30秒已經很夠用了 # See timesyncd.conf(5) for details.[Time]NTP=10.10.1.30#FallbackNTP=RootDistanceMaxSec=30#PollIntervalMinSec=32#PollIntervalMaxSec=2048 詳細說明如下https://unix.stackexchange.com/a/655489 參考:https://www.cnblogs.com/pipci/p/12833228.htmlhttps://officeguide.cc/ubuntu-linux-timedatectl-time-synchronization-tutorial/https://www.digitalocean.com/community/tutorials/how-to-set-up-time-synchronization-on-ubuntu-20-04https://www.tenable.com/audits/items/CIS_Ubuntu_18.04_LTS_Server_v2.1.0_L1.audit:26286d27c59292cfdb9c7b04593edbedhttps://serverfault.com/questions/1024770/ubuntu-20-04-time-sync-problems-and-possibly-incorrect-status-information" }, { "title": "實作Google登入按鈕", "url": "/posts/%E5%AF%A6%E4%BD%9Cgoogle%E7%99%BB%E5%85%A5%E6%8C%89%E9%88%95/", "categories": "", "tags": "", "date": "2022-10-26 11:01:00 +0800", "snippet": "參考:https://developer.okta.com/blog/2019/10/21/illustrated-guide-to-oauth-and-oidchttps://developers.google.com/identity/protocols/oauth2/web-server#python" }, { "title": "FastAPI 印出422 unprocessable entity詳細資料", "url": "/posts/fastapi-%E5%8D%B0%E5%87%BA422-unprocessable-entity%E8%A9%B3%E7%B4%B0%E8%B3%87%E6%96%99/", "categories": "", "tags": "", "date": "2022-10-22 20:27:00 +0800", "snippet": "import loggingfrom fastapi import FastAPI, Request, statusfrom fastapi.exceptions import RequestValidationErrorfrom fastapi.responses import JSONResponseapp = FastAPI()@app.exception_handler(RequestValidationError)async def validation_exception_handler(request: Request, exc: RequestValidationError):\texc_str = f'{exc}'.replace('\\n', ' ').replace(' ', ' ')\tlogging.error(f\"{request}: {exc_str}\")\tcontent = {'status_code': 10422, 'message': exc_str, 'data': None}\treturn JSONResponse(content=content, status_code=status.HTTP_422_UNPROCESSABLE_ENTITY)參考:https://github.com/tiangolo/fastapi/issues/3361#issuecomment-1002120988" }, { "title": "X11 Server顯示遠端GUI", "url": "/posts/x11-server%E9%A1%AF%E7%A4%BA%E9%81%A0%E7%AB%AFgui/", "categories": "環境設定與部屬", "tags": "Linux", "date": "2022-10-18 11:27:00 +0800", "snippet": "X Window 的Client和Server角色一般來說如果遠端連線到一台電腦，通常遠端那台電腦是Server，但是對於X Window來說，顯示畫面的才是Server，因此如果你要遠端觀看遠端的電腦畫面，你手上的電腦是X Server，遠端的電腦是X ClientX Server的Port當你啟動X Server的時候，他會開始監聽6000port，更詳細的來說X Server會給定display number，而每個display number所監聽的port為6000+display numberX11 forwdarding如果你的電腦在防火牆後，這時候6000port不一定有打開，而X11 forwdarding不只幫打開一條通道讓遠端電腦可以連到你的6000port，同時還幫你處理好X serve連線的事情。step1. Ubuntu 安裝x11套件sudo apt install x11-appsstep2. 設定遠端電腦開啟x11修改遠端電腦的/etc/ssh/sshd_config檔案，確認檔案內X11Forwarding yesstep3. 檢查x11設定用以下指令確認設定正確sudo cat /etc/ssh/sshd_config |grep -i X11Forwarding在Windows下安裝VcXsrv Windows X Server在windows下必須安裝x server，可以到以下連結下載https://sourceforge.net/projects/vcxsrv/問題排除 Warning: untrusted X11 forwarding setup failed: xauth key data not generatedhttps://serverfault.com/a/355986測試Docker container 透過ssh x11 forwarding傳送影像到遠端電腦以DeepStream container 為例docker run --gpus all -it --rm --net=host --privileged -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$DISPLAY --volume=\"$HOME/.Xauthority:/root/.Xauthority:rw\" -w /opt/nvidia/deepstream/deepstream-6.1 nvcr.io/nvidia/deepstream:6.1.1-devel 參考:X window解說https://www.cs.odu.edu/~zeil/cs252/latest/Public/xtrouble/index.htmlWhat You Need to Know About X11 Forwardinghttps://goteleport.com/blog/x11-forwarding/How to enable X11 forwarding from Red Hat Enterprise Linux (RHEL), Amazon Linux, SUSE Linux, Ubuntu server to support GUI-based installations from Amazon EC2https://aws.amazon.com/tw/blogs/compute/how-to-enable-x11-forwarding-from-red-hat-enterprise-linux-rhel-amazon-linux-suse-linux-ubuntu-server-to-support-gui-based-installations-from-amazon-ec2/Built-in SSH X11 forwarding in PowerShell or Windows Command Prompthttps://x410.dev/cookbook/built-in-ssh-x11-forwarding-in-powershell-or-windows-command-prompt/https://dreamanddead.github.io/post/ssh-x11-forward/https://juejin.cn/post/7009593663894323231https://stackoverflow.com/questions/65468655/vs-code-remote-x11-cant-get-display-while-connecting-to-remote-serverhttps://zhuanlan.zhihu.com/p/461378596X11 Forwarding on Windows with Cygwinhttps://www.csusb.edu/sites/default/files/cse_x11_forwarding_on_windows_with_cygwin.pdfCygwin/Xhttps://x.cygwin.com/ssh optionhttps://www.microfocus.com/documentation/rsit-server-client-unix/8-4-0/unix-guide/ssh_options_ap.htmlWhat exactly is X/Xorg/X11?https://www.reddit.com/r/linuxquestions/comments/3uh9n9/what_exactly_is_xxorgx11/SSH X11 Forwarding Of Gnome-Boxes Under Wayland &amp; Mixed Wayland &amp; X11 Environmentshttps://www.dbts-analytics.com/notesxfwdgb.html X11 forwarding docker container裡面的影像docker run 指令要多加 –volume=”$HOME/.Xauthority:/root/.Xauthority:rw”X11 forwarding of a GUI app running in dockerhttps://stackoverflow.com/a/51209546Run X application in a Docker container reliably on a server connected via SSH without “–net host”https://stackoverflow.com/questions/48235040/run-x-application-in-a-docker-container-reliably-on-a-server-connected-via-ssh-w" }, { "title": "git 筆記", "url": "/posts/git%E7%AD%86%E8%A8%98/", "categories": "環境設定與部屬", "tags": "git", "date": "2022-10-07 16:10:00 +0800", "snippet": " git alias git config --global alias.slog \"log --graph --all --topo-order --pretty='format:%h %ai %s%d (%an)'\" 移動git tag 位置 git tag --force &lt;tag名稱&gt;git push origin &lt;tag名稱&gt; --force #強迫推送到遠端 " }, { "title": "Python呼叫C++系列(二)scikit-build", "url": "/posts/python%E5%91%BC%E5%8F%ABc-%E7%B3%BB%E5%88%97-%E4%BA%8C-scikit-build/", "categories": "模型部屬", "tags": "pythoncpp", "date": "2022-09-28 17:08:00 +0800", "snippet": "第一篇連結本篇重點我們將建立一個可安裝的c++ extension套件，可以用pip install 安裝，本篇教學將延續第一篇的範例example.cpp準備環境 安裝所需套件和scikit-build 安裝編譯所需套件 sudo apt install build-essential 安裝CMake sudo apt install cmake 使用方式 建立一個setup.py檔並且放入下面這行 新增一個CMakeLists.txt並且放入下面內容 新增一個pyproject.toml並且放入下面內容 測試安裝套件pip install -v Debug" }, { "title": "tar gz 解壓縮", "url": "/posts/tar-gz-%E8%A7%A3%E5%A3%93%E7%B8%AE/", "categories": "環境設定與部屬", "tags": "Linux", "date": "2022-09-21 16:32:00 +0800", "snippet": "tar –xvzf documents.tar.gz參考:https://phoenixnap.com/kb/extract-tar-gz-files-linux-command-line" }, { "title": "Linux crontab 自動化例行性工作", "url": "/posts/linux-crontab-%E8%87%AA%E5%8B%95%E5%8C%96%E4%BE%8B%E8%A1%8C%E6%80%A7%E5%B7%A5%E4%BD%9C/", "categories": "環境設定與部屬", "tags": "Linux", "date": "2022-09-15 21:20:00 +0800", "snippet": "查看例行性工作# 查看自己的 crontabcrontab -l建立例行性工作# 編輯 crontab 內容crontab -e如果要用高權限執行例行性工作可以加上sudosudo crontab -e工作設定的格式每個例行工作會有時間搭配要下達的指令，*代表所對應的時間只要一改變就執行，例如下面範例每分鐘都會執行一次python3 test.py指令(因為全部是*號)* * * * * python3 test.pyMIN(分鐘) HOUR（小時） DOM（日） MON（月） DOW（星期幾） 指令(CMD)指令sudo crontab -e01 14 * * * /home/joe/myscript &gt;&gt; /home/log/myscript.log 2&gt;&amp;1參考:https://ithelp.ithome.com.tw/articles/10293218https://blog.gtwang.org/linux/linux-crontab-cron-job-tutorial-and-examples/https://askubuntu.com/a/121560" }, { "title": "三個重要工具結合Python和C++", "url": "/posts/%E4%B8%89%E5%80%8B%E9%87%8D%E8%A6%81%E5%B7%A5%E5%85%B7%E7%B5%90%E5%90%88python%E5%92%8Cc/", "categories": "模型部屬", "tags": "pybind11, scikit-build, cibuildwheel", "date": "2022-09-05 17:20:00 +0800", "snippet": "參考:https://iscinumpy.dev/post/scikit-build-proposal/https://zenodo.org/record/6946769#.YxW-dHZBw2w" }, { "title": "CMake教學系列一使用CMake編譯專案", "url": "/posts/cmake%E6%95%99%E5%AD%B8%E7%B3%BB%E5%88%97%E4%B8%80/", "categories": "環境設定與部屬", "tags": "cmake", "date": "2022-09-03 22:46:00 +0800", "snippet": " 安裝最新版的CMake，越新越好，因為新版的CMake提供更多的工具幫你尋找函式庫或套件，尤其如果你需要用到CUDA，新版的CMake可以省去你許多的麻煩安裝CMakeUbuntu可以跟著這篇官方教學安裝最新的CMakesudo apt-get updatesudo apt-get install ca-certificates gpg wgettest -f /usr/share/doc/kitware-archive-keyring/copyright ||wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2&gt;/dev/null | gpg --dearmor - | sudo tee /usr/share/keyrings/kitware-archive-keyring.gpg &gt;/dev/null# Ubuntu 20.04echo 'deb [signed-by=/usr/share/keyrings/kitware-archive-keyring.gpg] https://apt.kitware.com/ubuntu/ focal main' | sudo tee /etc/apt/sources.list.d/kitware.list &gt;/dev/nullsudo apt-get updatetest -f /usr/share/doc/kitware-archive-keyring/copyright ||sudo rm /usr/share/keyrings/kitware-archive-keyring.gpgsudo apt-get install kitware-archive-keyringsudo apt-get install cmake嘗試用CMake編譯程式讓我們嘗試用CMake編譯一個開源專案git clone https://github.com/CLIUtils/CLI11.git # 下載專案cd CLI11 #進入資料夾然後我們就可以開始編譯，過程中你會發現CMake幫你建立了一個build資料夾，第一行指令-S表示source directory，B會幫你建立一個build資料夾如果他不存在的話，CMake產生的東西會全部放在build資料夾裡面，你隨時可以刪除他而且他也不需要被版本控制。第二行的-j讓你可以指定要用多少核心來加速編譯。第三行-t代表執行測試程式，如果你沒有測試程式也可以不需要這行指令。cmake -S . -B buildcmake --build build -j 8cmake --build build -t test 你很容易在網路上看到CMake傳統的編譯方式，不過在CMake 3.15之後你可以用前面提到的新的方法，他可以幫你處理掉一些小麻煩。 mkdir buildcd buildcmake ..makemake test 查看編譯選項在CLI11資料夾中，你可以用cmake -S . -L列出所有你可以設定的選項，有些是CMake內建的選項，有些是這著專案中設定讓你可以選的選項。cmake -S . -LH不但會列出所有選項，還把說明文字也印出來。在許多開源專案用CMake編譯的時候經常會需要知道他提供哪些選項，這個指令會非常有幫助。$ cmake -S . -B build -LH-- CMake 3.22.1-- Could NOT find Doxygen (missing: DOXYGEN_EXECUTABLE) -- Doxygen not found, building docs has been disabled-- Configuring done-- Generating done-- Build files have been written to: /home/steven/CLI11/build-- Cache values// Build the testing tree.BUILD_TESTING:BOOL=OFF// Path to a file.Boost_INCLUDE_DIR:PATH=Boost_INCLUDE_DIR-NOTFOUND// Turn on boost test (currently may fail with Boost 1.70)CLI11_BOOST:BOOL=ON// Build CLI11 examplesCLI11_BUILD_EXAMPLES:BOOL=ON// Build CLI11 json exampleCLI11_BUILD_EXAMPLES_JSON:BOOL=OFF// Build the tests with NVCC to check for warnings there - requires CMake 3.9+CLI11_CUDA_TESTS:BOOL=OFF// Install the CLI11 folder to include during install processCLI11_INSTALL:BOOL=OFF...以下省略如果你想要設定選項值，你可以在CMake指令中用-D加上選項名稱來設定，例如cmake -DCLI11_INSTALL=ON -S . -B build這時候被設定的值會被保存在build資料夾裡面的CMakeCache.txt。你可以打開這份文件並且找到這個選項被設定的值。你可以看到CLI11_INSTALL:BOOL=ON...以上省略//Build the tests with NVCC to check for warnings there - requires// CMake 3.9+CLI11_CUDA_TESTS:BOOL=OFF//Install the CLI11 folder to include during install processCLI11_INSTALL:BOOL=ON//Value Computed by CMakeCLI11_IS_TOP_LEVEL:STATIC=ON...以下省略如果在設定一次就可以發現他的值被改成OFFcmake -DCLI11_INSTALL=OFF -S . -B build...以上省略//Build the tests with NVCC to check for warnings there - requires// CMake 3.9+CLI11_CUDA_TESTS:BOOL=OFF//Install the CLI11 folder to include during install processCLI11_INSTALL:BOOL=OFF//Value Computed by CMakeCLI11_IS_TOP_LEVEL:STATIC=ON...以下省略另外還有一些常見的CMake標準選項你可以設定 CMAKE_BUILD_TYPE CMAKE_INSTALL_PREFIX:安裝的位置，UNIX系統預設為/usr/local BUILD_SHARED_LIBS:是否建立 shared libraries BUILD_TESTINGCMake除錯技巧這節特別重要，如果要自己撰寫CMakeLists.txt話十分有用。--trace-source選項讓你指定你有興趣的檔案，並且依照他執行的順序依序印出他所執行的行數cmake build --trace-source=\"CMakeLists.txt\"動手寫第一個CMakeLists.txt我們將製作一個簡單的C語言程式，並且寫一個CMakeLists.txtmkdir cmakeQuickStartcd cmakeQuickStartcode .在cmakeQuickStart資料夾內建立一個CMakeLists.txt和一個simple.cpp。 cmake_minimum_required指定使用這份CMakeLists.txt最小所需的CMake版本。 project指定專案名稱，而專案使用的語言預設為C++和C。如果要指定專案語言可以輸入LANGUAGES參數。 最後你要輸出執行檔或是library。add_executable指令輸出執行檔，add_library指令輸出library，輸出的執行檔或是library檔名在跟第一個參數一樣。在這裡特別注意，add_executableadd_library第一個參數為兩個東西命名，首先他命名了輸出檔案的檔案名稱，其次是他命名了一個CMake的target，target在後面會很常用到。/* simple.c or simple.cpp */#include &lt;stdio.h&gt;int main() { printf(\"Hello, World!\\n\"); return 0;}cmake_minimum_required(VERSION 3.15)project(MyProject)add_executable(myexample simple.cpp)你也可以把CMakeLists.txt改成下面這樣，他指定了CMake的版本範圍，並且為專案增加說明和版本號cmake_minimum_required(VERSION 3.15...3.21)project(MyProject VERSION 1.0 DESCRIPTION \"Very nice project\" LANGUAGES CXX)add_executable(myexample simple.cpp)接下來你就可以編譯你的程式了，編譯後你會看到build資料夾出現一個myexample檔，跟你在add_executable指定的名稱一樣cmake -S . -B buildcmake --build buildMore Modern CMakehttps://hsf-training.github.io/hsf-training-cmake-webpage/An Introduction to Modern CMakehttps://cliutils.gitlab.io/modern-cmake/" }, { "title": "Python的class method使用情境", "url": "/posts/python%E7%9A%84class-method%E4%BD%BF%E7%94%A8%E6%83%85%E5%A2%83/", "categories": "", "tags": "", "date": "2022-08-25 12:11:00 +0800", "snippet": "參考:https://iscinumpy.gitlab.io/post/factory-classmethods-in-python/" }, { "title": "Python呼叫C++系列(一)環境設定", "url": "/posts/Python%E5%91%BC%E5%8F%ABCpp%E7%B3%BB%E5%88%97%E4%B8%80%E7%92%B0%E5%A2%83%E8%A8%AD%E5%AE%9A/", "categories": "模型部屬", "tags": "pythoncpp", "date": "2022-08-24 12:30:00 +0800", "snippet": " 我製作了一個SORT: Simple online and realtime tracking的C++的Python binding歡迎參考看看sort-cpp-pybind11第二篇連結 作業系統: Ubuntu 22.04 IDE: VSCode CMake 3.22.1 python 3.10.4摘要本系列文章將介紹如何利用Pybind11以及scikit-build來幫助我們製作Python的C++ extension，並且介紹如何把用C++實作的追蹤演算法SORT轉換成python extensionC++ 重點提示 編譯與直譯 Python屬於直譯式語言，而C++是屬於編譯語言。因為我們用文字寫的程式電腦是看不懂的，必須有個工具幫我們將程式翻譯成電腦懂的機器碼，他就像我們跟電腦之間的翻譯員。直譯語言用的是直譯器(Interpreter)他像是個即時翻譯員，當我們在命令提示字元或是Bash，輸入Python的時候，打開的就是直譯器，我們每輸入一行(或一段)的程式，直譯器會馬上幫我們翻譯成機器碼，所以我們可以直接看到輸出結果。而編譯語言使用的是編譯器(Compiler)，他向翻譯社一樣，要把所有的程式全部都寫完後，送進編譯器一口起全部翻成機器碼。 標頭檔(head file) 用來描述function或是class介面的檔案，介面的意思就是function會需要什麼參數，然後回傳直會是什麼，又或者是class有哪些method、member variable和method使用的參數和回傳值。而程式實作方式(Implement)都放在原碼檔。就像上圖的Num.h那樣。 原碼檔(source file) 紀錄程式實作方式的檔案，所有的實作方式都會被記錄在原碼檔。 動態/靜態函式庫 有時候程式提供者不想揭露實作方式的時候，可能就會給動態/靜態函式庫以及標頭檔，因為動態/靜態函式庫是機械碼所以人類是看不懂的，要使用動態/靜態函式庫我們必須利用標頭檔來了解有哪些函式可以呼叫，並且利用標頭檔來呼叫和使用動態/靜態函式庫。 以下面的程式為例，我們有兩個原始碼檔和一個標頭檔，標頭檔紀錄Num類別的成員變數和方法的輸入和輸出，原始碼檔紀錄getNum函式的運作主程式的運作Num的標頭檔(Num.h)// Num.h 的內容class Num{ private: int num; public: Num(int n); int getNum();};Num的原始碼檔(Num.cpp)// Num.cpp 的內容#include \"Num.h\"Num::Num() : num(0) { }Num::Num(int n): num(n) {}int Num::getNum(){ return num;} 主程式main的原始碼檔(main.cpp)// main.cpp 的內容#include &lt;iostream&gt;#include \"Num.h\"using namespace std;int main(){ Num n(35); cout &lt;&lt; n.getNum() &lt;&lt; endl; return 0;} CMake管理C++專案如果曾經使用過Visual Studio寫過C++的話，就會看過Visual Studio幫我們製造一個.sln檔，這個檔案記錄了專案的設定。不過不同的軟體編輯器有不同的專案檔，大家常用的軟體編輯器也都不一樣。因此CMake就扮演軟體編輯器通譯的角色，只要我們可以跟CMake說我們專案的設定，CMake就能夠幫我們製造不同軟體編輯器的專案檔，而且CMake是跨平台的，因此不管開發者是在Windows還是Linux上開發，CMake都可以幫我們產生是和的專案檔，讓開發者合作順暢。站在CMake之上來管理Python C++混和呼叫的專案上:scikit-buildPython C++混和的專案面臨到更多複雜的設定，單純使用CMake並不好寫，而scikit-build幫我們處理好Python C++混和型的專案常用的工具或是編譯流程，省去我們重新造輪子的工。環境設定設定VScode和開發環境可以參考這篇安裝Pybind11官方提供多樣的安裝方式，可以參考官方文件，這裡我們採用pip安裝，注意要先用venv建立虛擬環境python3 -m venv venv. venv/bin/activatepip install pybind11測試安裝 首先建立一個簡單的python c++ extension程式example.cppinclude &lt;pybind11/pybind11.h&gt;int add(int i, int j) { return i + j;}PYBIND11_MODULE(example, m) { m.doc() = \"pybind11 example plugin\"; // optional module docstring m.def(\"add\", &amp;add, \"A function that adds two numbers\");} 編譯extension，注意venv必須已經啟動並且已經安裝pybind11，接著輸入以下指令，你會發現資料夾多了一個example.cpython-310-x86_64-linux-gnu.so檔案，代表動態函式庫已經編譯完成，你已經成功製作了一個python C++ extension c++ -O3 -Wall -shared -std=c++11 -fPIC $(python3 -m pybind11 --includes) example.cpp -o example$(python3-config --extension-suffix) 嘗試從python內呼叫extension $ pythonPython 3.9.10 (main, Jan 15 2022, 11:48:04)[Clang 13.0.0 (clang-1300.0.29.3)] on darwinType \"help\", \"copyright\", \"credits\" or \"license\" for more information.import exampleexample.add(1, 2)3&gt;&gt;&gt; 恭喜你完成了第一個extension!! 注意剛剛編譯的步驟我們下了一行很長的指令(c++ -O3 -Wall -shared …….)，你可能會想在Linux可以這樣編譯，那如果我的電腦是Windows或是masOS怎麼辦呢? CMake專門幫我們處理這些問題，後面我們會介紹更多CMake的用法。參考:https://zhuanlan.zhihu.com/p/52874931https://developer.lsst.io/https://blog.csdn.net/zzh123353/article/details/121582409下面的連結有些marco是舊的https://people.duke.edu/~ccc14/cspy/18G_C++_Python_pybind11.htmlhttps://developer.lsst.io/v/billglick-slurm-queues/coding/python_wrappers_for_cpp_with_pybind11.html" }, { "title": "加速NMS系列(一)", "url": "/posts/%E5%8A%A0%E9%80%9Fnms%E7%B3%BB%E5%88%97-%E4%B8%80/", "categories": "MLOps", "tags": "Cython, CuPy", "date": "2022-08-24 12:27:00 +0800", "snippet": " ElementwiseKernel 參考:https://blog.csdn.net/DragonProbiotics/article/details/102995885https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#network_python" }, { "title": "TensorRT系列(一)環境設定", "url": "/posts/tensorrt%E7%B3%BB%E5%88%97-%E4%B8%80-%E7%92%B0%E5%A2%83%E8%A8%AD%E5%AE%9A/", "categories": "MLOps", "tags": "TensorRT", "date": "2022-08-24 11:32:00 +0800", "snippet": "本文章版本資訊 TensorRT 8.6.1apt 安裝TensorRT的方法https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-861/install-guide/index.html#installing-debian利用Docker 建立TensorRT環境docker tensorrt的版本與tensorrt版本對應表https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.htmldocker run --gpus all -it --rm -v local_dir:container_dir nvcr.io/nvidia/tensorrt:22.07-py3其中local_dir換成自己電腦的某一個資料夾，他將與Docker container共用，container_dir換成container裡面的資料夾路徑參考:https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html#installhttps://github.com/wang-xinyu/tensorrtx#tutorials" }, { "title": "Python OpenCV圖片裁剪", "url": "/posts/python-opencv%E5%9C%96%E7%89%87%E8%A3%81%E5%89%AA/", "categories": "機器視覺", "tags": "opencv", "date": "2022-08-17 17:48:00 +0800", "snippet": "OpenCV 座標Python OpenCV 裁剪圖片OpenCV 的蒲覑本質上就是一個 numpy array， 因此可以利用numpy array提供的方法來完成裁剪圖片的功能crop_img = img[y:y+h, x:x+w] # x, y 為圖片的裁剪圖片的左上角座標，h, w 分別為裁剪圖片的高和寬參考:https://stackoverflow.com/a/15589825" }, { "title": "fastapi使用自己的openapi檔", "url": "/posts/fastapi-%E4%BD%BF%E7%94%A8%E8%87%AA%E5%B7%B1%E7%9A%84openapi-ymal%E6%AA%94/", "categories": "WebAPI開發", "tags": "fastapi", "date": "2022-08-14 17:46:00 +0800", "snippet": "步驟 參考官方離線版文件的說明 寫一個route可以回傳openapi的json 把openapi_url=app.openapi_url改型成 openapi_url=&lt;回傳openapi json 的route&gt; " }, { "title": "ssh連線設定", "url": "/posts/ssh%E9%80%A3%E7%B7%9A%E8%A8%AD%E5%AE%9A/", "categories": "環境設定與部屬", "tags": "ssh", "date": "2022-08-13 18:30:00 +0800", "snippet": "非對稱式加密 非對稱式加密有兩把key，一把只能加密，一把只能解密 非對稱式加密public key是公開給外界，作為解密專用key，只能解密用對應的private key加密的內容 非對稱式加密private key必須妥善保存，作為加密專用key，只被對應的public key解密public key像帳號，private key像密碼把自己的的public key提供給目標連線電腦，就像在那台帳號註冊帳號一樣ssh會把public key存在~/.ssh/authorized_keys這個檔案裡面 利用ssh-copy-id複製public key到ssh server主機 linux ssh-copy-id 192.168.122.7 # 指令為ssh-copy-id 遠端主機的ip windows在powershell中沒有ssh-copy-id這個指令，不過我們可以用下面指令達成相同目標 type $env:USERPROFILE\\.ssh\\id_rsa.pub | ssh {IP-ADDRESS-OR-FQDN} \"cat &gt;&gt; .ssh/authorized_keys\" 參考:https://kb.iu.edu/d/aewshttps://www.chrisjhart.com/Windows-10-ssh-copy-id/" }, { "title": "更改主機名稱後RabbitMQ無法啟動", "url": "/posts/%E6%9B%B4%E6%94%B9%E4%B8%BB%E6%A9%9F%E5%90%8D%E7%A8%B1%E5%BE%8Crabbitmq%E7%84%A1%E6%B3%95%E5%95%9F%E5%8B%95/", "categories": "環境設定與部屬", "tags": "rabbitmq", "date": "2022-08-11 12:00:00 +0800", "snippet": "作業系統: Windows10更改主機名稱後，會發現rabbitmq無法啟動，這時候要重新安裝Service。注意:需要備份的資料先備份起來 利用rabbitmq提供的bat(RabbitMQ Service - remove.bat)，並且以系統管理員執行 利用rabbitmq提供的bat(RabbitMQ Service - (re)install.bat)，並且以系統管理員執行重新安裝service 利用rabbitmq提供的bat(RabbitMQ Service - start.bat)，並且以系統管理員執行重新安裝service啟動服務 成功後會看到log資料夾出現新的log，rabbit@(新的主機名稱).log，代表成功了。參考: https://dennymichael.net/2014/06/16/rabbitmq-change-the-hostname/" }, { "title": "用vim作為Python IDE", "url": "/posts/%E7%94%A8vim%E4%BD%9C%E7%82%BApython-ide/", "categories": "IDE", "tags": "ide", "date": "2022-08-08 12:24:00 +0800", "snippet": "vim版本:8.2安裝套件管理員Vundle 下載Vundle plugin manager並且放到VIM套件資料夾 git clone https://github.com/gmarik/Vundle.vim.git ~/.vim/bundle/Vundle.vim 建立套件管理檔 touch ~/.vimrc 將下面指令複製到~/.vimrc檔案裡面```set nocompatible “ requiredfiletype off “ required” set the runtime path to include Vundle and initializeset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()” alternatively, pass a path where Vundle should install plugins“call vundle#begin(‘~/some/path/here’)” let Vundle manage Vundle, requiredPlugin ‘gmarik/Vundle.vim’” add all your plugins here (note older versions of Vundle“ used Bundle instead of Plugin)” …” All of your Plugins must be added before the following linecall vundle#end() “ requiredfiletype plugin indent on “ required``` 安裝套件 先開啟vim 輸入: PluginInstall 操作 分割畫面 .vimrc 加入下面幾行 \"split navigations nnoremap &lt;C-J&gt; &lt;C-W&gt;&lt;C-J&gt; nnoremap &lt;C-K&gt; &lt;C-W&gt;&lt;C-K&gt; nnoremap &lt;C-L&gt; &lt;C-W&gt;&lt;C-L&gt; nnoremap &lt;C-H&gt; &lt;C-W&gt;&lt;C-H&gt; ctrl加上vim的方向鍵(J下, K上, L右, H左)就可以移動到不同地方的split Buffers :ls可以看到buffer清單 可以在輸入:ls後直接:b ，就可以不用記下buffer number 程式碼收折 在.vimrc加入下面幾行 ``` “ Enable folding set foldmethod=indent set foldlevel=99 ” Enable folding with the spacebar nnoremap za * 之後就可用空白鍵收折程式碼 * 如果想要看到收折的程式碼的docstrings 可以在.vimrc加入這行 let g:SimpylFold_docstring_preview=1 ``` 參考:vim 快捷鍵 : http://stackoverflow.com/a/5400978/1799408https://www.openvim.com/https://realpython.com/vim-and-python-a-match-made-in-heaven/breakpoints : https://github.com/puremourning/vimspector" }, { "title": "Visual Studio + CMake製作Python Extension", "url": "/posts/%E8%A3%BD%E4%BD%9Cpython-extension/", "categories": "程式撰寫", "tags": "python_extension", "date": "2022-07-11 18:06:00 +0800", "snippet": "版本資訊Visual Studio 2019CMake 3.24Python3.8.10設定Opencv 編譯OpenCV 設定windows的環境變數 OpenCV_ROOT 到OpenCVConfig.cmake所在的資料夾(CMake 3.12之後的功能，文件 從編譯好的OpenCVConfig.cmake我們可以看OpenCV提供了那些CMake變數給我們使用，可以參考這裡 讓CMake複製dll文件 設定CMake尋找Python.hfind_package(Python 3 REQUIRED COMPONENTS Interpreter Development.Module NumPy) # New in cmake 3.19include_directories(${Python_INCLUDE_DIRS})link_directories(${Python_LIBRARY_DIRS})message(STATUS \"Python Location: ${Python_INCLUDE_DIRS}\")include_directories(${Python_NumPy_INCLUDE_DIRS})message(STATUS \"NumPy Location: ${Python_NumPy_INCLUDE_DIRS}\")find_package(OpenCV REQUIRED)if (OpenCV_FOUND) # If the package has been found, several variables will # be set, you can find the full list with descriptions # in the OpenCVConfig.cmake file. # Print some message showing some of them include_directories(${OpenCV_INCLUDE_DIRS}) link_libraries(${OpenCV_LIBRARIES}) message(STATUS \"OpenCV library status:\") message(STATUS \" version: ${OpenCV_VERSION}\") message(STATUS \" include path: ${OpenCV_INCLUDE_DIRS}\")else () message(FATAL_ERROR \"Could not locate OpenCV\")endif()原碼參考:參考:Python.h位置CMake尋找Python" }, { "title": "Windows下讓cmake找到OpenCV和Eigen", "url": "/posts/windows%E4%B8%8B%E8%AE%93cmake%E6%89%BE%E5%88%B0opencv/", "categories": "環境設定與部屬", "tags": "cmake", "date": "2022-07-08 16:16:00 +0800", "snippet": "OpenCV從(cmake 3.12)[https://cmake.org/cmake/help/v3.12/policy/CMP0074.html]之後，可以利用環境變數來告訴cmake套件的位置，在Windows下很方便，因為windows不像linux會把函式庫集中放在一起。設定方法就是利用設定環境變數&lt;PackageName&gt;_ROOT其中&lt;PackageName&gt;就是你的套件名稱，例如在這裡我們要設的環境變數就是OpenCV_ROOT，注意&lt;PackageName&gt;必須要和你寫在CMakeLists.txt裡面find_package(&lt;PackageName&gt;)大小寫都要一致設定完後會看到cmake輸出找到的路徑Environment variable OpenCV_ROOT is set to: D:\\lib\\build_opencv另外由於相容性的關係，cmake預設不會使用環境變數的OpenCV_ROOT，我們必須在CMakeLists.txt中設定打開這個功能cmake_policy(SET CMP0074 NEW)成功設定後可以看到cmake會有以下輸出-- Found OpenCV: D:/lib/build_opencv (found version \"4.6.0\")-- OpenCV library status:-- version: 4.6.0詳細寫法可以參考這個範例https://gist.github.com/jenhaoyang/924698b31f7e3baede14286c67d6059aEigen3.4.0使用find_package(Eigen3 REQUIRED)後需要get_target_property(EIGEN3_INCLUDE_DIR Eigen3::Eigen INTERFACE_INCLUDE_DIRECTORIES)，根據這個issue的寫法https://gitlab.com/libeigen/eigen/-/issues/2486參考:https://seanzhengw.github.io/blog/cmake/2018/04/23/cmake-find-package.htmlhttps://cmake.org/cmake/help/v3.12/policy/CMP0074.htmlhttps://stackoverflow.com/questions/21314893/what-is-the-default-search-path-for-find-package-in-windows-using-cmake" }, { "title": "馬可夫蒙地卡羅法", "url": "/posts/%E9%A6%AC%E5%8F%AF%E5%A4%AB%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%B3%95/", "categories": "機器學習", "tags": "mcmc", "date": "2022-07-03 23:15:00 +0800", "snippet": "參考:https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackershttps://www.youtube.com/playlist?list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZNhttps://xcelab.net/rm/statistical-rethinking/https://www.cnblogs.com/pinard/p/6638955.htmlhttps://www.reddit.com/r/statistics/comments/9p1d3i/any_detailed_stepbystep_tutorial_to_mcmc_theory/" }, { "title": "Ubuntu更新cmake", "url": "/posts/ubuntu%E6%9B%B4%E6%96%B0cmake/", "categories": "環境設定與部屬", "tags": "cmake", "date": "2022-06-28 17:31:00 +0800", "snippet": "前一陣子在windows上編譯Nvidia triton-inference-server發現他的編譯腳本有很多方便的的操作方法，升級cmake是其中之一，注意指令中有指定ubuntu版本cmake官方有關於apt下載的說明ENV DEBIAN_FRONTEND=noninteractiveRUN apt install software-properties-common -yRUN wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2&gt;/dev/null | \\ gpg --dearmor - | \\ tee /etc/apt/trusted.gpg.d/kitware.gpg &gt;/dev/null &amp;&amp; \\ apt-add-repository 'deb https://apt.kitware.com/ubuntu/ focal main' &amp;&amp; \\ apt-get update &amp;&amp; \\ apt-get install -y --no-install-recommends \\ cmake-data=3.21.1-0kitware1ubuntu20.04.1 cmake=3.21.1-0kitware1ubuntu20.04.1參考:https://github.com/triton-inference-server/server/blob/main/Dockerfile.QA#L65" }, { "title": "http上傳檔案", "url": "/posts/http%E4%B8%8A%E5%82%B3%E6%AA%94%E6%A1%88/", "categories": "網路運作原理", "tags": "http", "date": "2022-06-25 12:10:00 +0800", "snippet": "參考:https://stackoverflow.com/a/8660740" }, { "title": "ssh-copy-id指令", "url": "/posts/ssh-copy-id%E6%8C%87%E4%BB%A4/", "categories": "環境設定與部屬", "tags": "ssh", "date": "2022-06-24 23:12:00 +0800", "snippet": " ssh-copy-id linux windows在powershell中沒有ssh-copy-id這個指令，不過我們可以用下面指令達成相同目標 type $env:USERPROFILE\\.ssh\\id_rsa.pub | ssh {IP-ADDRESS-OR-FQDN} \"cat &gt;&gt; .ssh/authorized_keys\" 參考:https://www.chrisjhart.com/Windows-10-ssh-copy-id/" }, { "title": "7zip常用指令", "url": "/posts/7zip%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/", "categories": "", "tags": "", "date": "2022-06-24 18:22:00 +0800", "snippet": " 切割壓縮檔-v50m 表示每50MB切一包 7za.exe\" a -v50m \"Release4.zip\" \"*.xlsm\" 參考:https://www.vishalon.net/blog/commands-for-using-standalone-7-zip-to-split-and-combine-zip-filehttps://info.nrao.edu/computing/guide/file-access-and-archiving/7zip/7z-7za-command-line-guide#section-14https://documentation.help/7-Zip/syntax.htm" }, { "title": "Powershell呼叫7zip", "url": "/posts/powershell%E5%91%BC%E5%8F%AB7zip/", "categories": "環境設定與部屬", "tags": "7zip", "date": "2022-06-24 12:18:00 +0800", "snippet": "如果在powershell 發現找不到7z 指令，可以用下面的script替代$7zipPath = \"$env:ProgramFiles\\7-Zip\\7z.exe\"if (-not (Test-Path -Path $7zipPath -PathType Leaf)) { throw \"7 zip file '$7zipPath' not found\"}Set-Alias 7zip $7zipPath$Source = \"c:\\BackupFrom\\backMeUp.txt\"$Target = \"c:\\BackupFolder\\backup.zip\"7zip a -v50m -mx=9 $Target $Source #-v50m 代表將檔案分割成每50MB一包7-zip 指令參考參考:https://stackoverflow.com/a/25288780" }, { "title": "離線安裝python套件", "url": "/posts/%E9%9B%A2%E7%B7%9A%E5%AE%89%E8%A3%9Dpython%E5%A5%97%E4%BB%B6/", "categories": "環境設定與部屬", "tags": "python", "date": "2022-06-22 14:31:00 +0800", "snippet": "有時候要部署的伺服器是完全沒有對外網路的，這篇文章將說明如何在無網路狀態下升級pip並且安裝套件。 確認可以聯網的機器和無網路的機器pip 版本是一樣的，如果有用到venv，那就確定venv裡面的pip版本一樣 # 確認pip版本pip --version 如果不一樣可以到官網下載想要的pip版本參考資料:https://www.ibm.com/docs/en/siffs/2.0.3?topic=python-installing-packages-offline-mode" }, { "title": "編譯onnxruntime Tensorrt ExecutionProvider", "url": "/posts/%E7%B7%A8%E8%AD%AFonnxruntime/", "categories": "深度學習工具", "tags": "tensorrt", "date": "2022-06-21 17:28:00 +0800", "snippet": "1. 安裝CUDA、cuDNN、Tensorrt我的環境 Windows10 Visual Studio 2019(注意 先安裝visual studio 再安裝CUDA，因為CUDA包含給visual studio使用的原件) cmake: 3.24.0 CUDA: 11.4 cuDNN: 8.2 Tensorrt:8.2.3.02.下載onnxruntime github原始碼並且切換到想要的onnxruntime 版本git clone https://github.com/microsoft/onnxruntime.gitgit checkout v1.11.12. 編譯 不一定要機器上要插著顯卡才能編譯，沒顯卡的機器也可以編譯 為了保險起見我是用系統管理員權限執行cmd，沒試過普通的cmd可不可以 基本上官方提供的build.bat 沒特別做什麼事，只是幫你呼叫build.py而已，所以所有參數都可以直接看build.py需要什麼，如果直接下官方文件的指令下會出錯。 onnxrumtime 的github ci pipeline是很好的參考，可以用來作為build.py指令參數的參考例如windows onnxruntime tensorrt CUDA architectures查詢build.bat --parallel --config Release --build_shared_lib --build_wheel --skip_tests --cudnn_home \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\" --cuda_home \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\" --use_tensorrt --tensorrt_home C:\\TensorRT-8.2.3.0 --cuda_version 11.4 --cmake_extra_defines \"CMAKE_CUDA_ARCHITECTURES=80\" 如果編譯失敗請刪掉程式產生的onnxruntime\\build資料夾後再重下指令 從docker file我們可以發現如何安裝編譯好的onnx tensorrt pip install &lt;onnxruntime 資料夾&gt;/build/Windows/Release/Release/dist/onnxruntime_gpu-1.11.1-cp38-cp38-win_amd64.whl" } ]
